{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('arac_tahmin_veri_seti.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_yok = ['Manuel Klima','Döşeme: Kumaş', 'Radyo MP3 Uyumlu', '2 Araç Anahtarı Mevcut (Toplam)','Yokuş Kalkış Desteği', 'Yolcu Hava Yastığı', 'Yol Bilgisayarı','Uzaktan Kumandalı Merkezi Kilit', 'Sürücü Hava Yastığı','Motor Blokaj - İmmobilizer', 'Hidrolik Direksiyon','Elektronik Denge Programı - Esp', 'Elektrikli Ön Camlar','Elektrikli Ayna', 'Ayarlanabilir Direksiyon','Antipatinaj Sistemi - Asr Tcs', 'Abs', 'CD Çalarlı Radyo MP3 Uyumlu', '1 Araç Anahtarı Mevcut (Toplam)', 'Sis Farı', 'Koltuk Hava Yastığı',\n",
    "       'Hız Sabitleme Sistemi - Cruise Control', 'Fonksiyonel Direksiyon', 'Elektrikli Arka Camlar', 'Deri Direksiyon Simidi', 'Alışım Jant', 'Otomatik Klima', 'Start-stop', 'Park Sensörü', 'Metalik Boya','Far Yıkama', 'Ön Kol Dayama', 'Yağmur Sensörü', 'Otomatik Far Sistemi','Hava Perdeleri', 'Geri Görüş Kamerası', 'Sunroof', 'Isıtmalı Koltuk','Elektrikli Katlanabilen Aynalar', 'Cam Tavan - Sky Dome','Döşeme: Kumaş/Deri Kombinasyonu', 'Xenon Far',\n",
    "       'Elektrik Ayarlı Koltuk', 'Diz Hava Yastığı','Ok Gösterimli Navigasyon Cihazı', 'Döşeme: Deri', 'Hafızalı Koltuk','CD Çalarlı Radyo', 'Döşeme: Alcantara/Deri',\n",
    "       'Haritalı Navigasyon Cihazı', 'Alarm', '4 X 4', 'Park Asistanı', 'CD Değiştiricili Radyo', 'Vakumlu Kapı', '3 Araç Anahtarı Mevcut (Toplam)', 'Kapı Hava Yastığı','Radyo - Kasetçalar', 'Merkezi Kilit', 'Döşeme: Suni Deri']\n",
    "X_cols = ['Açılış fiyatı','Kpt', 'SLÖÇ', 'SLÖK', 'SLAK',\n",
    "       'SLAÇ', 'Bgj', 'SĞÖÇ', 'SĞÖK', 'SĞAK', 'SĞAÇ', 'Tvn', 'Marka', 'Model',\n",
    "       'Versiyon', 'Model Yılı', 'Renk', 'Vites Tipi', 'Yakıt Tipi',\n",
    "       'Motor Hacmi', 'Beygir Gücü', 'Otomobil Segmenti', 'Son Teslim KM', 'Manuel Klima',\n",
    "       'Döşeme: Kumaş', 'Radyo MP3 Uyumlu', '2 Araç Anahtarı Mevcut (Toplam)',\n",
    "       'Yokuş Kalkış Desteği', 'Yolcu Hava Yastığı', 'Yol Bilgisayarı',\n",
    "       'Uzaktan Kumandalı Merkezi Kilit', 'Sürücü Hava Yastığı',\n",
    "       'Motor Blokaj - İmmobilizer', 'Hidrolik Direksiyon',\n",
    "       'Elektronik Denge Programı - Esp', 'Elektrikli Ön Camlar',\n",
    "       'Elektrikli Ayna', 'Ayarlanabilir Direksiyon',\n",
    "       'Antipatinaj Sistemi - Asr Tcs', 'Abs', 'CD Çalarlı Radyo MP3 Uyumlu',\n",
    "       '1 Araç Anahtarı Mevcut (Toplam)', 'Sis Farı', 'Koltuk Hava Yastığı',\n",
    "       'Hız Sabitleme Sistemi - Cruise Control', 'Fonksiyonel Direksiyon',\n",
    "       'Elektrikli Arka Camlar', 'Deri Direksiyon Simidi', 'Alışım Jant',\n",
    "       'Otomatik Klima', 'Start-stop', 'Park Sensörü', 'Metalik Boya',\n",
    "       'Far Yıkama', 'Ön Kol Dayama', 'Yağmur Sensörü', 'Otomatik Far Sistemi',\n",
    "       'Hava Perdeleri', 'Geri Görüş Kamerası', 'Sunroof', 'Isıtmalı Koltuk',\n",
    "       'Elektrikli Katlanabilen Aynalar', 'Cam Tavan - Sky Dome',\n",
    "       'Döşeme: Kumaş/Deri Kombinasyonu', 'Xenon Far',\n",
    "       'Elektrik Ayarlı Koltuk', 'Diz Hava Yastığı',\n",
    "       'Ok Gösterimli Navigasyon Cihazı', 'Döşeme: Deri', 'Hafızalı Koltuk',\n",
    "       'CD Çalarlı Radyo', 'Döşeme: Alcantara/Deri',\n",
    "       'Haritalı Navigasyon Cihazı', 'Alarm', '4 X 4', 'Park Asistanı',\n",
    "       'CD Değiştiricili Radyo', 'Vakumlu Kapı',\n",
    "       '3 Araç Anahtarı Mevcut (Toplam)', 'Kapı Hava Yastığı',\n",
    "       'Radyo - Kasetçalar', 'Merkezi Kilit', 'Döşeme: Suni Deri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in var_yok:\n",
    "    df.loc[df[feat]=='VAR',feat]=1\n",
    "    df.loc[df[feat]=='YOK',feat]=0\n",
    "    \n",
    "    \n",
    "df0 = df[df['Kapanış fiyatı']!='TEKLİF YOK']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1765, 704)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = MinMaxScaler()\n",
    "X = pd.get_dummies(df0[X_cols])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, df0['Kapanış fiyatı'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bill\\AppData\\Local\\conda\\conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "scaled_X_train = scale.fit_transform(X_train)\n",
    "scaled_X_test = scale.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model =S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(352,input_shape=(704,)))\n",
    "model.add(Dense(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.01),'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Bill\\AppData\\Local\\conda\\conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1063 samples, validate on 119 samples\n",
      "Epoch 1/5000\n",
      "1063/1063 [==============================] - 25s 24ms/step - loss: 1031.8053 - val_loss: 359.0575\n",
      "Epoch 2/5000\n",
      "1063/1063 [==============================] - 0s 132us/step - loss: 158.8288 - val_loss: 165.1245\n",
      "Epoch 3/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 69.9368 - val_loss: 119.7397\n",
      "Epoch 4/5000\n",
      "1063/1063 [==============================] - 0s 127us/step - loss: 47.8186 - val_loss: 92.4495\n",
      "Epoch 5/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 35.7238 - val_loss: 84.0858\n",
      "Epoch 6/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 27.3049 - val_loss: 83.1211\n",
      "Epoch 7/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 21.5609 - val_loss: 75.1941\n",
      "Epoch 8/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 18.9736 - val_loss: 69.4458\n",
      "Epoch 9/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 16.1030 - val_loss: 80.5666\n",
      "Epoch 10/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 13.7002 - val_loss: 69.1237\n",
      "Epoch 11/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 13.0845 - val_loss: 66.7436\n",
      "Epoch 12/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 13.5897 - val_loss: 72.2564\n",
      "Epoch 13/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 11.4971 - val_loss: 74.1887\n",
      "Epoch 14/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 10.1311 - val_loss: 64.3792\n",
      "Epoch 15/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 9.9600 - val_loss: 61.0083\n",
      "Epoch 16/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 12.2631 - val_loss: 59.5821\n",
      "Epoch 17/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 10.1421 - val_loss: 62.9983\n",
      "Epoch 18/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 9.1851 - val_loss: 67.1066\n",
      "Epoch 19/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 8.9318 - val_loss: 59.4763\n",
      "Epoch 20/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 8.3672 - val_loss: 62.6726\n",
      "Epoch 21/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 9.0057 - val_loss: 59.9094\n",
      "Epoch 22/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 9.1523 - val_loss: 56.6045\n",
      "Epoch 23/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 8.6707 - val_loss: 63.8358\n",
      "Epoch 24/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 9.9806 - val_loss: 57.7341\n",
      "Epoch 25/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 11.1353 - val_loss: 66.1591\n",
      "Epoch 26/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 8.7733 - val_loss: 60.8546\n",
      "Epoch 27/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 7.9234 - val_loss: 62.8867\n",
      "Epoch 28/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 9.7621 - val_loss: 64.4422\n",
      "Epoch 29/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 8.5370 - val_loss: 63.2849\n",
      "Epoch 30/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 7.5953 - val_loss: 59.5977\n",
      "Epoch 31/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 8.9886 - val_loss: 58.8110\n",
      "Epoch 32/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 8.3986 - val_loss: 60.4615\n",
      "Epoch 33/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 8.8864 - val_loss: 69.9591\n",
      "Epoch 34/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 8.1019 - val_loss: 61.4802\n",
      "Epoch 35/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 8.5849 - val_loss: 52.4525\n",
      "Epoch 36/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 9.1962 - val_loss: 61.6687\n",
      "Epoch 37/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 8.6728 - val_loss: 62.0209\n",
      "Epoch 38/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 8.2619 - val_loss: 62.3180\n",
      "Epoch 39/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 7.2459 - val_loss: 73.6205\n",
      "Epoch 40/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 8.9663 - val_loss: 76.5554\n",
      "Epoch 41/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 7.8281 - val_loss: 60.4945\n",
      "Epoch 42/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 6.9316 - val_loss: 64.8159\n",
      "Epoch 43/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 6.9993 - val_loss: 79.3941\n",
      "Epoch 44/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 7.5558 - val_loss: 79.7682\n",
      "Epoch 45/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 10.8786 - val_loss: 73.8747\n",
      "Epoch 46/5000\n",
      "1063/1063 [==============================] - 0s 129us/step - loss: 12.6063 - val_loss: 59.3454\n",
      "Epoch 47/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 8.7478 - val_loss: 68.8413\n",
      "Epoch 48/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 7.0004 - val_loss: 61.4465\n",
      "Epoch 49/5000\n",
      "1063/1063 [==============================] - 0s 124us/step - loss: 6.9160 - val_loss: 82.3094\n",
      "Epoch 50/5000\n",
      "1063/1063 [==============================] - 0s 121us/step - loss: 8.3209 - val_loss: 55.8040\n",
      "Epoch 51/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 10.6788 - val_loss: 102.3389\n",
      "Epoch 52/5000\n",
      "1063/1063 [==============================] - 0s 120us/step - loss: 14.8581 - val_loss: 66.4705\n",
      "Epoch 53/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 10.2361 - val_loss: 63.5482\n",
      "Epoch 54/5000\n",
      "1063/1063 [==============================] - 0s 124us/step - loss: 8.7830 - val_loss: 72.9856\n",
      "Epoch 55/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 8.7622 - val_loss: 56.5773\n",
      "Epoch 56/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 8.1877 - val_loss: 80.5070\n",
      "Epoch 57/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 7.9124 - val_loss: 57.1951\n",
      "Epoch 58/5000\n",
      "1063/1063 [==============================] - 0s 128us/step - loss: 9.2933 - val_loss: 76.9483\n",
      "Epoch 59/5000\n",
      "1063/1063 [==============================] - 0s 127us/step - loss: 8.5980 - val_loss: 69.5009\n",
      "Epoch 60/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 6.6198 - val_loss: 70.2352\n",
      "Epoch 61/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 6.7155 - val_loss: 54.4665\n",
      "Epoch 62/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 6.6403 - val_loss: 65.4030\n",
      "Epoch 63/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 6.9943 - val_loss: 58.1835\n",
      "Epoch 64/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 7.1495 - val_loss: 58.9412\n",
      "Epoch 65/5000\n",
      "1063/1063 [==============================] - 0s 119us/step - loss: 6.8298 - val_loss: 70.4888\n",
      "Epoch 66/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 7.9585 - val_loss: 72.1678\n",
      "Epoch 67/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 8.8827 - val_loss: 66.3553\n",
      "Epoch 68/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 7.7095 - val_loss: 77.5008\n",
      "Epoch 69/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 8.5977 - val_loss: 58.2191\n",
      "Epoch 70/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 10.4361 - val_loss: 69.4697\n",
      "Epoch 71/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 7.4185 - val_loss: 62.9879\n",
      "Epoch 72/5000\n",
      "1063/1063 [==============================] - 0s 120us/step - loss: 6.5260 - val_loss: 62.8364\n",
      "Epoch 73/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 6.2599 - val_loss: 60.2178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 7.9732 - val_loss: 62.9375\n",
      "Epoch 75/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 7.1656 - val_loss: 66.3108\n",
      "Epoch 76/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 13.5263 - val_loss: 59.9434\n",
      "Epoch 77/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 14.4113 - val_loss: 57.1838\n",
      "Epoch 78/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 10.9010 - val_loss: 63.0750\n",
      "Epoch 79/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 7.5207 - val_loss: 64.9845\n",
      "Epoch 80/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 8.2172 - val_loss: 52.0553\n",
      "Epoch 81/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 10.3599 - val_loss: 101.5999\n",
      "Epoch 82/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 12.3356 - val_loss: 73.9169\n",
      "Epoch 83/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 8.7763 - val_loss: 70.3866\n",
      "Epoch 84/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 7.9967 - val_loss: 69.1193\n",
      "Epoch 85/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 6.5357 - val_loss: 66.6160\n",
      "Epoch 86/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 8.7716 - val_loss: 71.4468\n",
      "Epoch 87/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 7.4565 - val_loss: 64.1064\n",
      "Epoch 88/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 6.2437 - val_loss: 67.7847\n",
      "Epoch 89/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 6.7637 - val_loss: 64.0577\n",
      "Epoch 90/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 8.5943 - val_loss: 59.3257\n",
      "Epoch 91/5000\n",
      "1063/1063 [==============================] - 0s 120us/step - loss: 6.7955 - val_loss: 67.1404\n",
      "Epoch 92/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 6.0912 - val_loss: 66.2786\n",
      "Epoch 93/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 7.4295 - val_loss: 64.2565\n",
      "Epoch 94/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 7.0790 - val_loss: 76.5208\n",
      "Epoch 95/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 6.9797 - val_loss: 90.9681\n",
      "Epoch 96/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 7.5999 - val_loss: 67.2313\n",
      "Epoch 97/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 7.0796 - val_loss: 73.5756\n",
      "Epoch 98/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 9.0275 - val_loss: 57.5861\n",
      "Epoch 99/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 9.7655 - val_loss: 67.7337\n",
      "Epoch 100/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 9.0439 - val_loss: 65.3324\n",
      "Epoch 101/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 8.0391 - val_loss: 61.1622\n",
      "Epoch 102/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 9.2862 - val_loss: 68.0062\n",
      "Epoch 103/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 7.7943 - val_loss: 77.3922\n",
      "Epoch 104/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 8.4384 - val_loss: 60.9891\n",
      "Epoch 105/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 6.1346 - val_loss: 76.5006\n",
      "Epoch 106/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 6.4442 - val_loss: 54.7302\n",
      "Epoch 107/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 8.1771 - val_loss: 70.0325\n",
      "Epoch 108/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 6.7274 - val_loss: 88.7794\n",
      "Epoch 109/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 8.4541 - val_loss: 66.3121\n",
      "Epoch 110/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 7.1148 - val_loss: 77.3457\n",
      "Epoch 111/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 8.1463 - val_loss: 72.2520\n",
      "Epoch 112/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 6.7633 - val_loss: 70.5893\n",
      "Epoch 113/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 6.2919 - val_loss: 80.6646\n",
      "Epoch 114/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 6.3048 - val_loss: 73.5575\n",
      "Epoch 115/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 7.8252 - val_loss: 70.3562\n",
      "Epoch 116/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 6.6180 - val_loss: 56.6256\n",
      "Epoch 117/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 8.6739 - val_loss: 95.2270\n",
      "Epoch 118/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 7.7947 - val_loss: 67.7524\n",
      "Epoch 119/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 7.4344 - val_loss: 69.6815\n",
      "Epoch 120/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 7.8946 - val_loss: 98.6832\n",
      "Epoch 121/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 9.1739 - val_loss: 73.7744\n",
      "Epoch 122/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 11.0650 - val_loss: 64.6675\n",
      "Epoch 123/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 8.2381 - val_loss: 70.1770\n",
      "Epoch 124/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 7.6779 - val_loss: 63.0981\n",
      "Epoch 125/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 10.4916 - val_loss: 73.6458\n",
      "Epoch 126/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 9.1072 - val_loss: 64.2653\n",
      "Epoch 127/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 6.7317 - val_loss: 61.3424\n",
      "Epoch 128/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 6.5954 - val_loss: 72.9195\n",
      "Epoch 129/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 6.3726 - val_loss: 70.4401\n",
      "Epoch 130/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 6.1064 - val_loss: 72.8426\n",
      "Epoch 131/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 6.5334 - val_loss: 70.6843\n",
      "Epoch 132/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 6.2593 - val_loss: 63.1589\n",
      "Epoch 133/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.8880 - val_loss: 76.0451\n",
      "Epoch 134/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 6.5971 - val_loss: 92.7323\n",
      "Epoch 135/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 6.2556 - val_loss: 60.0618\n",
      "Epoch 136/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 6.3173 - val_loss: 70.5547\n",
      "Epoch 137/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 7.0247 - val_loss: 84.5674\n",
      "Epoch 138/5000\n",
      "1063/1063 [==============================] - 0s 120us/step - loss: 7.4717 - val_loss: 100.5986\n",
      "Epoch 139/5000\n",
      "1063/1063 [==============================] - 0s 122us/step - loss: 9.3050 - val_loss: 63.3045\n",
      "Epoch 140/5000\n",
      "1063/1063 [==============================] - 0s 126us/step - loss: 8.2526 - val_loss: 97.8514\n",
      "Epoch 141/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 10.9542 - val_loss: 66.9251\n",
      "Epoch 142/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 9.5609 - val_loss: 58.8662\n",
      "Epoch 143/5000\n",
      "1063/1063 [==============================] - 0s 132us/step - loss: 10.3534 - val_loss: 68.8076\n",
      "Epoch 144/5000\n",
      "1063/1063 [==============================] - 0s 134us/step - loss: 9.6738 - val_loss: 78.2347\n",
      "Epoch 145/5000\n",
      "1063/1063 [==============================] - 0s 121us/step - loss: 6.6231 - val_loss: 68.1107\n",
      "Epoch 146/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 9.9639 - val_loss: 111.7544\n",
      "Epoch 147/5000\n",
      "1063/1063 [==============================] - 0s 132us/step - loss: 9.6546 - val_loss: 81.4927\n",
      "Epoch 148/5000\n",
      "1063/1063 [==============================] - 0s 123us/step - loss: 10.4576 - val_loss: 57.2565\n",
      "Epoch 149/5000\n",
      "1063/1063 [==============================] - 0s 134us/step - loss: 7.9838 - val_loss: 62.6093\n",
      "Epoch 150/5000\n",
      "1063/1063 [==============================] - 0s 132us/step - loss: 5.9765 - val_loss: 87.1654\n",
      "Epoch 151/5000\n",
      "1063/1063 [==============================] - 0s 121us/step - loss: 6.1955 - val_loss: 78.4370\n",
      "Epoch 152/5000\n",
      "1063/1063 [==============================] - 0s 124us/step - loss: 6.5115 - val_loss: 61.8871\n",
      "Epoch 153/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 6.8764 - val_loss: 55.1391\n",
      "Epoch 154/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 7.2868 - val_loss: 74.5887\n",
      "Epoch 155/5000\n",
      "1063/1063 [==============================] - 0s 133us/step - loss: 7.0433 - val_loss: 69.9031\n",
      "Epoch 156/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 9.4194 - val_loss: 64.0206\n",
      "Epoch 157/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 6.5517 - val_loss: 63.2563\n",
      "Epoch 158/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 7.4923 - val_loss: 57.6619\n",
      "Epoch 159/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 10.5846 - val_loss: 78.6411\n",
      "Epoch 160/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 7.7710 - val_loss: 82.3380\n",
      "Epoch 161/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 6.9206 - val_loss: 57.5775\n",
      "Epoch 162/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 6.0654 - val_loss: 57.5879\n",
      "Epoch 163/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 6.5531 - val_loss: 67.0318\n",
      "Epoch 164/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 6.3579 - val_loss: 64.2251\n",
      "Epoch 165/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 7.4659 - val_loss: 76.8972\n",
      "Epoch 166/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 6.9035 - val_loss: 75.1794\n",
      "Epoch 167/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 6.0309 - val_loss: 61.0066\n",
      "Epoch 168/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 6.0720 - val_loss: 83.0342\n",
      "Epoch 169/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 11.3404 - val_loss: 96.5181\n",
      "Epoch 170/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 7.0979 - val_loss: 68.9662\n",
      "Epoch 171/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.4006 - val_loss: 74.9684\n",
      "Epoch 172/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.2711 - val_loss: 74.3741\n",
      "Epoch 173/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.9785 - val_loss: 78.6810\n",
      "Epoch 174/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 6.8038 - val_loss: 108.2066\n",
      "Epoch 175/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 9.6024 - val_loss: 65.2048\n",
      "Epoch 176/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.6831 - val_loss: 80.1230\n",
      "Epoch 177/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 6.1925 - val_loss: 70.2394\n",
      "Epoch 178/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.7486 - val_loss: 65.9777\n",
      "Epoch 179/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.9344 - val_loss: 62.9810\n",
      "Epoch 180/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.5160 - val_loss: 72.0048\n",
      "Epoch 181/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.9128 - val_loss: 63.2578\n",
      "Epoch 182/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.8979 - val_loss: 74.9980\n",
      "Epoch 183/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 6.1450 - val_loss: 57.6169\n",
      "Epoch 184/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 6.1125 - val_loss: 75.6144\n",
      "Epoch 185/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 7.8397 - val_loss: 64.3985\n",
      "Epoch 186/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 6.3804 - val_loss: 71.9535\n",
      "Epoch 187/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 7.9171 - val_loss: 71.5648\n",
      "Epoch 188/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 9.4160 - val_loss: 82.1321\n",
      "Epoch 189/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 6.5052 - val_loss: 83.6724\n",
      "Epoch 190/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 8.0568 - val_loss: 68.7956\n",
      "Epoch 191/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 6.1765 - val_loss: 76.3622\n",
      "Epoch 192/5000\n",
      "1063/1063 [==============================] - 0s 124us/step - loss: 6.1797 - val_loss: 73.0679\n",
      "Epoch 193/5000\n",
      "1063/1063 [==============================] - 0s 127us/step - loss: 6.3987 - val_loss: 68.5320\n",
      "Epoch 194/5000\n",
      "1063/1063 [==============================] - 0s 119us/step - loss: 5.5936 - val_loss: 80.0253\n",
      "Epoch 195/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 5.9940 - val_loss: 76.3124\n",
      "Epoch 196/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 5.8657 - val_loss: 61.9962\n",
      "Epoch 197/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 6.0819 - val_loss: 67.9398\n",
      "Epoch 198/5000\n",
      "1063/1063 [==============================] - 0s 130us/step - loss: 6.3753 - val_loss: 69.0511\n",
      "Epoch 199/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 6.0294 - val_loss: 87.3542\n",
      "Epoch 200/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 8.4951 - val_loss: 58.5108\n",
      "Epoch 201/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 8.0772 - val_loss: 75.8440\n",
      "Epoch 202/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 7.5922 - val_loss: 77.7038\n",
      "Epoch 203/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 6.9246 - val_loss: 78.9521\n",
      "Epoch 204/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 7.2207 - val_loss: 71.4542\n",
      "Epoch 205/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 6.3816 - val_loss: 70.9938\n",
      "Epoch 206/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 6.7955 - val_loss: 60.6809\n",
      "Epoch 207/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 6.7111 - val_loss: 60.8944\n",
      "Epoch 208/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 6.2862 - val_loss: 84.7722\n",
      "Epoch 209/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 7.0426 - val_loss: 86.1127\n",
      "Epoch 210/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 6.3652 - val_loss: 77.0172\n",
      "Epoch 211/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 6.6513 - val_loss: 93.3864\n",
      "Epoch 212/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 8.5900 - val_loss: 59.8974\n",
      "Epoch 213/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 8.0288 - val_loss: 65.8744\n",
      "Epoch 214/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 10.2035 - val_loss: 67.7619\n",
      "Epoch 215/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 7.4053 - val_loss: 67.1174\n",
      "Epoch 216/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 5.8012 - val_loss: 60.9112\n",
      "Epoch 217/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.8575 - val_loss: 80.6235\n",
      "Epoch 218/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 6.1376 - val_loss: 66.3540\n",
      "Epoch 219/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 8.6367 - val_loss: 64.8335\n",
      "Epoch 220/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 7.6494 - val_loss: 55.6902\n",
      "Epoch 221/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 6.3315 - val_loss: 79.2071\n",
      "Epoch 222/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 8.1102 - val_loss: 67.3430\n",
      "Epoch 223/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 9.0163 - val_loss: 63.4875\n",
      "Epoch 224/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.8570 - val_loss: 71.8671\n",
      "Epoch 225/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 7.9691 - val_loss: 71.8691\n",
      "Epoch 226/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 8.3549 - val_loss: 72.5281\n",
      "Epoch 227/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 6.9311 - val_loss: 78.2123\n",
      "Epoch 228/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 6.5810 - val_loss: 64.0016\n",
      "Epoch 229/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 5.6604 - val_loss: 58.1081\n",
      "Epoch 230/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 12.0485 - val_loss: 63.2772\n",
      "Epoch 231/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 6.0226 - val_loss: 65.9276\n",
      "Epoch 232/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.2421 - val_loss: 63.2903\n",
      "Epoch 233/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.2134 - val_loss: 65.3739\n",
      "Epoch 234/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.3851 - val_loss: 66.6406\n",
      "Epoch 235/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.8079 - val_loss: 101.6410\n",
      "Epoch 236/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 7.6256 - val_loss: 73.1824\n",
      "Epoch 237/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.1718 - val_loss: 67.7204\n",
      "Epoch 238/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 5.7893 - val_loss: 68.0444\n",
      "Epoch 239/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.3249 - val_loss: 79.7030\n",
      "Epoch 240/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 6.3391 - val_loss: 64.8988\n",
      "Epoch 241/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 5.3637 - val_loss: 74.0894\n",
      "Epoch 242/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 5.4811 - val_loss: 74.8289\n",
      "Epoch 243/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 6.3687 - val_loss: 73.2363\n",
      "Epoch 244/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 6.0158 - val_loss: 70.3205\n",
      "Epoch 245/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.5395 - val_loss: 80.5514\n",
      "Epoch 246/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 6.2147 - val_loss: 70.7721\n",
      "Epoch 247/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 6.0065 - val_loss: 84.9158\n",
      "Epoch 248/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 6.9110 - val_loss: 73.0409\n",
      "Epoch 249/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.6816 - val_loss: 72.7788\n",
      "Epoch 250/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 7.2575 - val_loss: 75.3995\n",
      "Epoch 251/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 7.1274 - val_loss: 66.5912\n",
      "Epoch 252/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.4484 - val_loss: 65.5219\n",
      "Epoch 253/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 6.7499 - val_loss: 70.0568\n",
      "Epoch 254/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 6.2322 - val_loss: 76.1945\n",
      "Epoch 255/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.7441 - val_loss: 93.3657\n",
      "Epoch 256/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 6.7668 - val_loss: 86.0157\n",
      "Epoch 257/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 6.0751 - val_loss: 74.9554\n",
      "Epoch 258/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.7389 - val_loss: 61.4143\n",
      "Epoch 259/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.4225 - val_loss: 70.3707\n",
      "Epoch 260/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.5582 - val_loss: 61.3253\n",
      "Epoch 261/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 8.3818 - val_loss: 76.0760\n",
      "Epoch 262/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 7.7180 - val_loss: 61.2838\n",
      "Epoch 263/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 6.1932 - val_loss: 76.8270\n",
      "Epoch 264/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 6.9912 - val_loss: 55.5623\n",
      "Epoch 265/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 7.4859 - val_loss: 88.9203\n",
      "Epoch 266/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 7.1084 - val_loss: 71.0628\n",
      "Epoch 267/5000\n",
      "1063/1063 [==============================] - 0s 136us/step - loss: 5.9480 - val_loss: 69.0733\n",
      "Epoch 268/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 5.9772 - val_loss: 67.5684\n",
      "Epoch 269/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 7.3204 - val_loss: 67.3590\n",
      "Epoch 270/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 6.6063 - val_loss: 60.1453\n",
      "Epoch 271/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.5942 - val_loss: 60.5157\n",
      "Epoch 272/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 6.4988 - val_loss: 71.6174\n",
      "Epoch 273/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.5379 - val_loss: 70.6811\n",
      "Epoch 274/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.7435 - val_loss: 65.7252\n",
      "Epoch 275/5000\n",
      "1063/1063 [==============================] - 0s 128us/step - loss: 6.9480 - val_loss: 81.6371\n",
      "Epoch 276/5000\n",
      "1063/1063 [==============================] - 0s 138us/step - loss: 6.7041 - val_loss: 81.4435\n",
      "Epoch 277/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 5.6831 - val_loss: 68.4556\n",
      "Epoch 278/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.6786 - val_loss: 59.1806\n",
      "Epoch 279/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 6.2603 - val_loss: 63.3878\n",
      "Epoch 280/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.5591 - val_loss: 62.4853\n",
      "Epoch 281/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 6.5738 - val_loss: 62.5018\n",
      "Epoch 282/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 6.6028 - val_loss: 96.2884\n",
      "Epoch 283/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 8.4120 - val_loss: 114.3911\n",
      "Epoch 284/5000\n",
      "1063/1063 [==============================] - 0s 148us/step - loss: 8.7753 - val_loss: 80.3535\n",
      "Epoch 285/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 6.4192 - val_loss: 80.9657\n",
      "Epoch 286/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.9346 - val_loss: 76.8821\n",
      "Epoch 287/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 5.9507 - val_loss: 74.9709\n",
      "Epoch 288/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 5.5496 - val_loss: 62.6843\n",
      "Epoch 289/5000\n",
      "1063/1063 [==============================] - 0s 121us/step - loss: 6.0473 - val_loss: 74.9975\n",
      "Epoch 290/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 5.5104 - val_loss: 66.0564\n",
      "Epoch 291/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.8670 - val_loss: 70.2844\n",
      "Epoch 292/5000\n",
      "1063/1063 [==============================] - 0s 129us/step - loss: 5.7185 - val_loss: 65.9173\n",
      "Epoch 293/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 7.8461 - val_loss: 70.8041\n",
      "Epoch 294/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 6.1062 - val_loss: 64.9041\n",
      "Epoch 295/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.2331 - val_loss: 74.7459\n",
      "Epoch 296/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 6.4013 - val_loss: 65.1567\n",
      "Epoch 297/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 6.2391 - val_loss: 58.8841\n",
      "Epoch 298/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 6.9689 - val_loss: 68.3899\n",
      "Epoch 299/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.5453 - val_loss: 63.2013\n",
      "Epoch 300/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.3927 - val_loss: 82.7925\n",
      "Epoch 301/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 7.3158 - val_loss: 72.1073\n",
      "Epoch 302/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 6.0690 - val_loss: 66.1491\n",
      "Epoch 303/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.4110 - val_loss: 66.4992\n",
      "Epoch 304/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.3631 - val_loss: 62.7533\n",
      "Epoch 305/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.7870 - val_loss: 62.1989\n",
      "Epoch 306/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 6.1123 - val_loss: 68.6897\n",
      "Epoch 307/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 7.1547 - val_loss: 77.4127\n",
      "Epoch 308/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 6.3187 - val_loss: 66.0232\n",
      "Epoch 309/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.9502 - val_loss: 78.6837\n",
      "Epoch 310/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 6.1131 - val_loss: 70.3217\n",
      "Epoch 311/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.7705 - val_loss: 58.7802\n",
      "Epoch 312/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 5.6506 - val_loss: 64.9789\n",
      "Epoch 313/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.3943 - val_loss: 67.9291\n",
      "Epoch 314/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 6.2095 - val_loss: 71.2136\n",
      "Epoch 315/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.2825 - val_loss: 67.7245\n",
      "Epoch 316/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.5407 - val_loss: 68.2572\n",
      "Epoch 317/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.1722 - val_loss: 62.1941\n",
      "Epoch 318/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.6028 - val_loss: 78.6880\n",
      "Epoch 319/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 6.4164 - val_loss: 66.7961\n",
      "Epoch 320/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.5116 - val_loss: 65.2037\n",
      "Epoch 321/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 6.5663 - val_loss: 61.5478\n",
      "Epoch 322/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 7.0958 - val_loss: 96.4420\n",
      "Epoch 323/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 9.1499 - val_loss: 61.8268\n",
      "Epoch 324/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 6.2731 - val_loss: 64.8758\n",
      "Epoch 325/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 6.4492 - val_loss: 78.6355\n",
      "Epoch 326/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 6.0720 - val_loss: 71.6549\n",
      "Epoch 327/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.6707 - val_loss: 67.9322\n",
      "Epoch 328/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.9573 - val_loss: 69.0074\n",
      "Epoch 329/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 6.0176 - val_loss: 74.5287\n",
      "Epoch 330/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 6.0061 - val_loss: 76.3603\n",
      "Epoch 331/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 6.8064 - val_loss: 65.9746\n",
      "Epoch 332/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 6.2523 - val_loss: 85.4807\n",
      "Epoch 333/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.7749 - val_loss: 72.6035\n",
      "Epoch 334/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.9582 - val_loss: 73.9519\n",
      "Epoch 335/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.2258 - val_loss: 63.3288\n",
      "Epoch 336/5000\n",
      "1063/1063 [==============================] - 0s 126us/step - loss: 5.4662 - val_loss: 70.6644\n",
      "Epoch 337/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.6698 - val_loss: 69.8030\n",
      "Epoch 338/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 6.0896 - val_loss: 71.6348\n",
      "Epoch 339/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 6.0173 - val_loss: 78.1769\n",
      "Epoch 340/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.7194 - val_loss: 89.2457\n",
      "Epoch 341/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.5567 - val_loss: 60.4395\n",
      "Epoch 342/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 6.1948 - val_loss: 64.3451\n",
      "Epoch 343/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.4744 - val_loss: 73.2252\n",
      "Epoch 344/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.7863 - val_loss: 79.9732\n",
      "Epoch 345/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.7527 - val_loss: 80.7528\n",
      "Epoch 346/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 6.3988 - val_loss: 68.8265\n",
      "Epoch 347/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.1065 - val_loss: 68.8939\n",
      "Epoch 348/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.3298 - val_loss: 63.6782\n",
      "Epoch 349/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.7920 - val_loss: 76.7135\n",
      "Epoch 350/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.3536 - val_loss: 57.3322\n",
      "Epoch 351/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.9198 - val_loss: 65.6529\n",
      "Epoch 352/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.7681 - val_loss: 69.7157\n",
      "Epoch 353/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.7528 - val_loss: 76.9881\n",
      "Epoch 354/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.8774 - val_loss: 62.4149\n",
      "Epoch 355/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 7.0018 - val_loss: 67.4418\n",
      "Epoch 356/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 6.0089 - val_loss: 74.4083\n",
      "Epoch 357/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.7602 - val_loss: 61.0436\n",
      "Epoch 358/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.3051 - val_loss: 85.2480\n",
      "Epoch 359/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 7.3513 - val_loss: 73.0066\n",
      "Epoch 360/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.9967 - val_loss: 67.8003\n",
      "Epoch 361/5000\n",
      "1063/1063 [==============================] - 0s 125us/step - loss: 5.3555 - val_loss: 65.5130\n",
      "Epoch 362/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.5912 - val_loss: 59.4055\n",
      "Epoch 363/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.9572 - val_loss: 66.1791\n",
      "Epoch 364/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.3088 - val_loss: 62.7344\n",
      "Epoch 365/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.7765 - val_loss: 69.3423\n",
      "Epoch 366/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 6.3723 - val_loss: 63.2316\n",
      "Epoch 367/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 5.7890 - val_loss: 60.0665\n",
      "Epoch 368/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 6.4544 - val_loss: 69.2638\n",
      "Epoch 369/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.4694 - val_loss: 62.4847\n",
      "Epoch 370/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.4501 - val_loss: 73.3844\n",
      "Epoch 371/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.4110 - val_loss: 65.5396\n",
      "Epoch 372/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.4831 - val_loss: 75.1502\n",
      "Epoch 373/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.8250 - val_loss: 75.5153\n",
      "Epoch 374/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.9993 - val_loss: 66.7967\n",
      "Epoch 375/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 5.9291 - val_loss: 60.7676\n",
      "Epoch 376/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 6.1595 - val_loss: 68.4641\n",
      "Epoch 377/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.8993 - val_loss: 64.7671\n",
      "Epoch 378/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 10.2936 - val_loss: 77.6270\n",
      "Epoch 379/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.7517 - val_loss: 86.2770\n",
      "Epoch 380/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.9243 - val_loss: 70.6225\n",
      "Epoch 381/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 6.0039 - val_loss: 62.7917\n",
      "Epoch 382/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.9223 - val_loss: 65.9586\n",
      "Epoch 383/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.3282 - val_loss: 66.0020\n",
      "Epoch 384/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.4501 - val_loss: 72.6313\n",
      "Epoch 385/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.2171 - val_loss: 70.2809\n",
      "Epoch 386/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.1414 - val_loss: 82.8626\n",
      "Epoch 387/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.5161 - val_loss: 72.6179\n",
      "Epoch 388/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.5446 - val_loss: 58.4226\n",
      "Epoch 389/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 6.9637 - val_loss: 68.4668\n",
      "Epoch 390/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.8595 - val_loss: 83.4854\n",
      "Epoch 391/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.8957 - val_loss: 73.3871\n",
      "Epoch 392/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 5.7274 - val_loss: 69.5828\n",
      "Epoch 393/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 6.5802 - val_loss: 82.2901\n",
      "Epoch 394/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 7.4314 - val_loss: 71.4379\n",
      "Epoch 395/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.6205 - val_loss: 67.8079\n",
      "Epoch 396/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 6.1686 - val_loss: 64.0169\n",
      "Epoch 397/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.7809 - val_loss: 62.5951\n",
      "Epoch 398/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 6.0518 - val_loss: 59.1528\n",
      "Epoch 399/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.5793 - val_loss: 65.9085\n",
      "Epoch 400/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 6.7772 - val_loss: 71.3261\n",
      "Epoch 401/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.5084 - val_loss: 73.2937\n",
      "Epoch 402/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.3900 - val_loss: 70.6923\n",
      "Epoch 403/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.0632 - val_loss: 58.9370\n",
      "Epoch 404/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 7.7591 - val_loss: 72.8756\n",
      "Epoch 405/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.3110 - val_loss: 73.9191\n",
      "Epoch 406/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.8684 - val_loss: 71.0963\n",
      "Epoch 407/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.4398 - val_loss: 65.5074\n",
      "Epoch 408/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.4186 - val_loss: 66.1188\n",
      "Epoch 409/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.4512 - val_loss: 66.3948\n",
      "Epoch 410/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 6.3967 - val_loss: 73.2535\n",
      "Epoch 411/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.9766 - val_loss: 67.2417\n",
      "Epoch 412/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.0316 - val_loss: 67.2991\n",
      "Epoch 413/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 5.0846 - val_loss: 65.3405\n",
      "Epoch 414/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.7917 - val_loss: 63.2342\n",
      "Epoch 415/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.5056 - val_loss: 67.3237\n",
      "Epoch 416/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.0985 - val_loss: 70.8982\n",
      "Epoch 417/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.0104 - val_loss: 75.3971\n",
      "Epoch 418/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 6.0616 - val_loss: 70.9994\n",
      "Epoch 419/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.3895 - val_loss: 59.5450\n",
      "Epoch 420/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 8.5048 - val_loss: 67.3514\n",
      "Epoch 421/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.4172 - val_loss: 74.2173\n",
      "Epoch 422/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9732 - val_loss: 63.8813\n",
      "Epoch 423/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.2165 - val_loss: 73.5340\n",
      "Epoch 424/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 6.1308 - val_loss: 76.3778\n",
      "Epoch 425/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 5.3048 - val_loss: 67.8593\n",
      "Epoch 426/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.3815 - val_loss: 66.0296\n",
      "Epoch 427/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.4094 - val_loss: 57.6459\n",
      "Epoch 428/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 5.5933 - val_loss: 63.6278\n",
      "Epoch 429/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 6.3008 - val_loss: 73.4213\n",
      "Epoch 430/5000\n",
      "1063/1063 [==============================] - 0s 119us/step - loss: 5.1241 - val_loss: 65.7197\n",
      "Epoch 431/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 6.4322 - val_loss: 61.0255\n",
      "Epoch 432/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 6.4104 - val_loss: 67.9400\n",
      "Epoch 433/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.6406 - val_loss: 60.8218\n",
      "Epoch 434/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 6.0065 - val_loss: 69.6642\n",
      "Epoch 435/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.5374 - val_loss: 64.5645\n",
      "Epoch 436/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 5.3224 - val_loss: 63.7116\n",
      "Epoch 437/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 5.2320 - val_loss: 73.0661\n",
      "Epoch 438/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 5.4719 - val_loss: 64.6010\n",
      "Epoch 439/5000\n",
      "1063/1063 [==============================] - 0s 123us/step - loss: 5.4460 - val_loss: 67.4821\n",
      "Epoch 440/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 6.3384 - val_loss: 74.3733\n",
      "Epoch 441/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 6.2087 - val_loss: 92.0509\n",
      "Epoch 442/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 7.3636 - val_loss: 75.6126\n",
      "Epoch 443/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 5.3893 - val_loss: 66.1784\n",
      "Epoch 444/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.6474 - val_loss: 64.5396\n",
      "Epoch 445/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.5128 - val_loss: 64.7198\n",
      "Epoch 446/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.3836 - val_loss: 70.7185\n",
      "Epoch 447/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.1218 - val_loss: 67.5636\n",
      "Epoch 448/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 5.4146 - val_loss: 67.9694\n",
      "Epoch 449/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.8720 - val_loss: 74.9354\n",
      "Epoch 450/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 6.7573 - val_loss: 82.4854\n",
      "Epoch 451/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 7.6822 - val_loss: 85.8437\n",
      "Epoch 452/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 6.2239 - val_loss: 70.1732\n",
      "Epoch 453/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.9493 - val_loss: 83.5957\n",
      "Epoch 454/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.3423 - val_loss: 77.6391\n",
      "Epoch 455/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.9521 - val_loss: 71.2593\n",
      "Epoch 456/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.5195 - val_loss: 68.9866\n",
      "Epoch 457/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 6.4182 - val_loss: 69.8776\n",
      "Epoch 458/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 6.2837 - val_loss: 67.3501\n",
      "Epoch 459/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.1045 - val_loss: 64.4275\n",
      "Epoch 460/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.2599 - val_loss: 70.4853\n",
      "Epoch 461/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.2570 - val_loss: 67.7840\n",
      "Epoch 462/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.7599 - val_loss: 61.7195\n",
      "Epoch 463/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 6.4857 - val_loss: 61.9934\n",
      "Epoch 464/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 6.2140 - val_loss: 63.1259\n",
      "Epoch 465/5000\n",
      "1063/1063 [==============================] - 0s 117us/step - loss: 5.4453 - val_loss: 71.8503\n",
      "Epoch 466/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.6274 - val_loss: 77.2878\n",
      "Epoch 467/5000\n",
      "1063/1063 [==============================] - 0s 120us/step - loss: 6.8344 - val_loss: 72.5266\n",
      "Epoch 468/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 5.6660 - val_loss: 69.9509\n",
      "Epoch 469/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.5639 - val_loss: 62.8672\n",
      "Epoch 470/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 6.2586 - val_loss: 70.9510\n",
      "Epoch 471/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 5.0967 - val_loss: 68.8952\n",
      "Epoch 472/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.3507 - val_loss: 86.8752\n",
      "Epoch 473/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.9035 - val_loss: 69.9299\n",
      "Epoch 474/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 5.6067 - val_loss: 70.3497\n",
      "Epoch 475/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 5.5750 - val_loss: 76.8278\n",
      "Epoch 476/5000\n",
      "1063/1063 [==============================] - 0s 122us/step - loss: 5.7976 - val_loss: 82.9201\n",
      "Epoch 477/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 6.0835 - val_loss: 73.4118\n",
      "Epoch 478/5000\n",
      "1063/1063 [==============================] - 0s 120us/step - loss: 5.5891 - val_loss: 69.5556\n",
      "Epoch 479/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.6164 - val_loss: 58.7484\n",
      "Epoch 480/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 6.0733 - val_loss: 72.7199\n",
      "Epoch 481/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 5.8260 - val_loss: 59.4915\n",
      "Epoch 482/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.1898 - val_loss: 71.8041\n",
      "Epoch 483/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.3246 - val_loss: 66.8688\n",
      "Epoch 484/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.5859 - val_loss: 77.2735\n",
      "Epoch 485/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.6060 - val_loss: 64.6097\n",
      "Epoch 486/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.5150 - val_loss: 71.5003\n",
      "Epoch 487/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.5667 - val_loss: 76.9464\n",
      "Epoch 488/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 6.7972 - val_loss: 68.0402\n",
      "Epoch 489/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.2748 - val_loss: 67.1534\n",
      "Epoch 490/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.8636 - val_loss: 60.0401\n",
      "Epoch 491/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.3996 - val_loss: 68.8201\n",
      "Epoch 492/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8781 - val_loss: 63.5217\n",
      "Epoch 493/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 5.1258 - val_loss: 66.6626\n",
      "Epoch 494/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.0787 - val_loss: 67.3432\n",
      "Epoch 495/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 5.4722 - val_loss: 60.6115\n",
      "Epoch 496/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.8988 - val_loss: 80.2041\n",
      "Epoch 497/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 6.0303 - val_loss: 71.2077\n",
      "Epoch 498/5000\n",
      "1063/1063 [==============================] - 0s 119us/step - loss: 5.7636 - val_loss: 75.8757\n",
      "Epoch 499/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 6.3695 - val_loss: 76.5818\n",
      "Epoch 500/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.2266 - val_loss: 80.9555\n",
      "Epoch 501/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 5.4444 - val_loss: 76.5132\n",
      "Epoch 502/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.6709 - val_loss: 64.0888\n",
      "Epoch 503/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.5450 - val_loss: 65.3185\n",
      "Epoch 504/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.0516 - val_loss: 74.9227\n",
      "Epoch 505/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 5.0087 - val_loss: 58.8264\n",
      "Epoch 506/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.8686 - val_loss: 65.5056\n",
      "Epoch 507/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 5.9814 - val_loss: 81.1606\n",
      "Epoch 508/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.6799 - val_loss: 66.2362\n",
      "Epoch 509/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.9443 - val_loss: 81.5079\n",
      "Epoch 510/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 7.6858 - val_loss: 73.8206\n",
      "Epoch 511/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 6.7286 - val_loss: 77.5797\n",
      "Epoch 512/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.6062 - val_loss: 67.8083\n",
      "Epoch 513/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.4034 - val_loss: 65.4805\n",
      "Epoch 514/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 5.4101 - val_loss: 66.6154\n",
      "Epoch 515/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 6.0496 - val_loss: 68.9407\n",
      "Epoch 516/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 7.2586 - val_loss: 63.0637\n",
      "Epoch 517/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 6.0511 - val_loss: 74.6932\n",
      "Epoch 518/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 6.0120 - val_loss: 73.1507\n",
      "Epoch 519/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 6.5773 - val_loss: 68.6298\n",
      "Epoch 520/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.3262 - val_loss: 64.6382\n",
      "Epoch 521/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.0834 - val_loss: 72.4016\n",
      "Epoch 522/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.1969 - val_loss: 66.9728\n",
      "Epoch 523/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.0470 - val_loss: 69.5323\n",
      "Epoch 524/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 108us/step - loss: 5.8773 - val_loss: 75.5485\n",
      "Epoch 525/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.6979 - val_loss: 60.2550\n",
      "Epoch 526/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.5244 - val_loss: 66.8192\n",
      "Epoch 527/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.1578 - val_loss: 69.6578\n",
      "Epoch 528/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.8544 - val_loss: 65.2179\n",
      "Epoch 529/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.1845 - val_loss: 67.9909\n",
      "Epoch 530/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9667 - val_loss: 68.6650\n",
      "Epoch 531/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.1229 - val_loss: 67.3727\n",
      "Epoch 532/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.6801 - val_loss: 70.8337\n",
      "Epoch 533/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.5115 - val_loss: 67.0627\n",
      "Epoch 534/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.6575 - val_loss: 72.7217\n",
      "Epoch 535/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 6.0412 - val_loss: 71.2303\n",
      "Epoch 536/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.4157 - val_loss: 79.7070\n",
      "Epoch 537/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.5055 - val_loss: 66.9963\n",
      "Epoch 538/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 6.1951 - val_loss: 63.9203\n",
      "Epoch 539/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.9631 - val_loss: 63.9677\n",
      "Epoch 540/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.6536 - val_loss: 69.2456\n",
      "Epoch 541/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.2845 - val_loss: 60.7390\n",
      "Epoch 542/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.6464 - val_loss: 71.5475\n",
      "Epoch 543/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.5238 - val_loss: 67.8426\n",
      "Epoch 544/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 5.1320 - val_loss: 77.0877\n",
      "Epoch 545/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.1688 - val_loss: 68.6310\n",
      "Epoch 546/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.2123 - val_loss: 87.3377\n",
      "Epoch 547/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 6.6581 - val_loss: 69.2180\n",
      "Epoch 548/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.4515 - val_loss: 75.0052\n",
      "Epoch 549/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.2332 - val_loss: 73.1298\n",
      "Epoch 550/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.5629 - val_loss: 81.3455\n",
      "Epoch 551/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 6.0014 - val_loss: 74.2686\n",
      "Epoch 552/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.9054 - val_loss: 59.1585\n",
      "Epoch 553/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.9719 - val_loss: 83.1530\n",
      "Epoch 554/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 6.3507 - val_loss: 73.4181\n",
      "Epoch 555/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.2814 - val_loss: 71.7202\n",
      "Epoch 556/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.3279 - val_loss: 72.0973\n",
      "Epoch 557/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 6.0481 - val_loss: 68.9323\n",
      "Epoch 558/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.2492 - val_loss: 65.6685\n",
      "Epoch 559/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.8965 - val_loss: 65.9073\n",
      "Epoch 560/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.5906 - val_loss: 63.6193\n",
      "Epoch 561/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.0608 - val_loss: 68.4796\n",
      "Epoch 562/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.2486 - val_loss: 71.8451\n",
      "Epoch 563/5000\n",
      "1063/1063 [==============================] - 0s 122us/step - loss: 5.5419 - val_loss: 72.5535\n",
      "Epoch 564/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.3335 - val_loss: 85.0804\n",
      "Epoch 565/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 6.8410 - val_loss: 60.4651\n",
      "Epoch 566/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.1204 - val_loss: 69.8811\n",
      "Epoch 567/5000\n",
      "1063/1063 [==============================] - 0s 122us/step - loss: 5.8479 - val_loss: 62.6484\n",
      "Epoch 568/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 6.1075 - val_loss: 70.0024\n",
      "Epoch 569/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.7895 - val_loss: 68.6083\n",
      "Epoch 570/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 6.1674 - val_loss: 64.2846\n",
      "Epoch 571/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.8678 - val_loss: 81.3867\n",
      "Epoch 572/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 5.6775 - val_loss: 64.4476\n",
      "Epoch 573/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 6.0282 - val_loss: 70.0911\n",
      "Epoch 574/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 5.2943 - val_loss: 65.5461\n",
      "Epoch 575/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 5.2721 - val_loss: 78.6729\n",
      "Epoch 576/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 6.0998 - val_loss: 68.9228\n",
      "Epoch 577/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.6139 - val_loss: 66.3048\n",
      "Epoch 578/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 5.2903 - val_loss: 62.5596\n",
      "Epoch 579/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.4886 - val_loss: 82.4434\n",
      "Epoch 580/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.0404 - val_loss: 81.8630\n",
      "Epoch 581/5000\n",
      "1063/1063 [==============================] - 0s 122us/step - loss: 6.3091 - val_loss: 70.4496\n",
      "Epoch 582/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 5.6113 - val_loss: 81.2804\n",
      "Epoch 583/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 5.5821 - val_loss: 68.4026\n",
      "Epoch 584/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 5.5804 - val_loss: 71.1709\n",
      "Epoch 585/5000\n",
      "1063/1063 [==============================] - 0s 119us/step - loss: 5.3066 - val_loss: 65.8299\n",
      "Epoch 586/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.9749 - val_loss: 67.4721\n",
      "Epoch 587/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.7613 - val_loss: 71.9887\n",
      "Epoch 588/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.6772 - val_loss: 64.0061\n",
      "Epoch 589/5000\n",
      "1063/1063 [==============================] - 0s 122us/step - loss: 4.9110 - val_loss: 68.7851\n",
      "Epoch 590/5000\n",
      "1063/1063 [==============================] - 0s 141us/step - loss: 5.2726 - val_loss: 65.0894\n",
      "Epoch 591/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.1510 - val_loss: 71.6486\n",
      "Epoch 592/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.4100 - val_loss: 71.6516\n",
      "Epoch 593/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 5.0111 - val_loss: 64.5109\n",
      "Epoch 594/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.1330 - val_loss: 88.6957\n",
      "Epoch 595/5000\n",
      "1063/1063 [==============================] - 0s 128us/step - loss: 5.7608 - val_loss: 61.4838\n",
      "Epoch 596/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.3261 - val_loss: 82.5145\n",
      "Epoch 597/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 5.2459 - val_loss: 79.8251\n",
      "Epoch 598/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.7605 - val_loss: 70.0828\n",
      "Epoch 599/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 5.0109 - val_loss: 71.0235\n",
      "Epoch 600/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.5336 - val_loss: 73.2464\n",
      "Epoch 601/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.3616 - val_loss: 67.7891\n",
      "Epoch 602/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 6.0704 - val_loss: 86.9401\n",
      "Epoch 603/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.0581 - val_loss: 72.4258\n",
      "Epoch 604/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9488 - val_loss: 70.7262\n",
      "Epoch 605/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 5.1185 - val_loss: 64.3749\n",
      "Epoch 606/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.4309 - val_loss: 69.8470\n",
      "Epoch 607/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.3139 - val_loss: 60.1406\n",
      "Epoch 608/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.2865 - val_loss: 73.7872\n",
      "Epoch 609/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.0643 - val_loss: 69.1556\n",
      "Epoch 610/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.0723 - val_loss: 69.0379\n",
      "Epoch 611/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.5469 - val_loss: 76.7143\n",
      "Epoch 612/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.7857 - val_loss: 62.8000\n",
      "Epoch 613/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.6003 - val_loss: 66.5326\n",
      "Epoch 614/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 6.6312 - val_loss: 80.8298\n",
      "Epoch 615/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.7943 - val_loss: 79.3685\n",
      "Epoch 616/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.9186 - val_loss: 80.0236\n",
      "Epoch 617/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.2791 - val_loss: 68.6560\n",
      "Epoch 618/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.1619 - val_loss: 64.7011\n",
      "Epoch 619/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 6.2513 - val_loss: 76.4812\n",
      "Epoch 620/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.7437 - val_loss: 76.1311\n",
      "Epoch 621/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.3229 - val_loss: 74.3796\n",
      "Epoch 622/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 6.7872 - val_loss: 70.3750\n",
      "Epoch 623/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.1769 - val_loss: 71.4790\n",
      "Epoch 624/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 6.1329 - val_loss: 68.1511\n",
      "Epoch 625/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 5.0251 - val_loss: 79.1698\n",
      "Epoch 626/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.9275 - val_loss: 74.6019\n",
      "Epoch 627/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.0431 - val_loss: 67.1283\n",
      "Epoch 628/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 5.7059 - val_loss: 75.2308\n",
      "Epoch 629/5000\n",
      "1063/1063 [==============================] - 0s 122us/step - loss: 5.4967 - val_loss: 70.1514\n",
      "Epoch 630/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.1886 - val_loss: 70.9616\n",
      "Epoch 631/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.6210 - val_loss: 71.6188\n",
      "Epoch 632/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.3893 - val_loss: 85.4255\n",
      "Epoch 633/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.1919 - val_loss: 76.0624\n",
      "Epoch 634/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.3686 - val_loss: 70.2370\n",
      "Epoch 635/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.1717 - val_loss: 75.5340\n",
      "Epoch 636/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.3944 - val_loss: 68.7755\n",
      "Epoch 637/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.3266 - val_loss: 73.6241\n",
      "Epoch 638/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.9645 - val_loss: 88.9525\n",
      "Epoch 639/5000\n",
      "1063/1063 [==============================] - ETA: 0s - loss: 6.063 - 0s 116us/step - loss: 6.1190 - val_loss: 64.1774\n",
      "Epoch 640/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 5.5614 - val_loss: 72.1958\n",
      "Epoch 641/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 5.0727 - val_loss: 67.2970\n",
      "Epoch 642/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9217 - val_loss: 79.0397\n",
      "Epoch 643/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9637 - val_loss: 76.0618\n",
      "Epoch 644/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.7255 - val_loss: 66.0048\n",
      "Epoch 645/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.5335 - val_loss: 59.7725\n",
      "Epoch 646/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.0942 - val_loss: 65.6891\n",
      "Epoch 647/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.1475 - val_loss: 61.1519\n",
      "Epoch 648/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.8217 - val_loss: 73.7978\n",
      "Epoch 649/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7844 - val_loss: 68.2906\n",
      "Epoch 650/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9799 - val_loss: 66.7548\n",
      "Epoch 651/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8748 - val_loss: 70.4370\n",
      "Epoch 652/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.0500 - val_loss: 75.5967\n",
      "Epoch 653/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.1193 - val_loss: 68.4648\n",
      "Epoch 654/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.9929 - val_loss: 82.0690\n",
      "Epoch 655/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.5739 - val_loss: 68.4096\n",
      "Epoch 656/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.2800 - val_loss: 74.4982\n",
      "Epoch 657/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.5256 - val_loss: 79.9789\n",
      "Epoch 658/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.0119 - val_loss: 74.6176\n",
      "Epoch 659/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.8947 - val_loss: 71.3908\n",
      "Epoch 660/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.0815 - val_loss: 66.2758\n",
      "Epoch 661/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.4065 - val_loss: 72.1900\n",
      "Epoch 662/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.2482 - val_loss: 68.3019\n",
      "Epoch 663/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.7453 - val_loss: 82.0008\n",
      "Epoch 664/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.8406 - val_loss: 68.0422\n",
      "Epoch 665/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.1298 - val_loss: 68.8889\n",
      "Epoch 666/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 5.3556 - val_loss: 75.1067\n",
      "Epoch 667/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.0066 - val_loss: 66.2764\n",
      "Epoch 668/5000\n",
      "1063/1063 [==============================] - 0s 132us/step - loss: 6.1264 - val_loss: 89.8196\n",
      "Epoch 669/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.6222 - val_loss: 66.0341\n",
      "Epoch 670/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.9071 - val_loss: 68.9215\n",
      "Epoch 671/5000\n",
      "1063/1063 [==============================] - 0s 120us/step - loss: 5.0941 - val_loss: 67.7326\n",
      "Epoch 672/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.6905 - val_loss: 74.9346\n",
      "Epoch 673/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.2636 - val_loss: 75.5390\n",
      "Epoch 674/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 97us/step - loss: 6.0663 - val_loss: 66.7915\n",
      "Epoch 675/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.1560 - val_loss: 68.5468\n",
      "Epoch 676/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.8873 - val_loss: 71.0298\n",
      "Epoch 677/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.4314 - val_loss: 75.0817\n",
      "Epoch 678/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.2518 - val_loss: 88.0315\n",
      "Epoch 679/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 6.0276 - val_loss: 72.4945\n",
      "Epoch 680/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.5298 - val_loss: 73.7408\n",
      "Epoch 681/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.0053 - val_loss: 71.1004\n",
      "Epoch 682/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 6.5122 - val_loss: 83.8907\n",
      "Epoch 683/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 6.2669 - val_loss: 69.8861\n",
      "Epoch 684/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.9585 - val_loss: 84.3882\n",
      "Epoch 685/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.4284 - val_loss: 73.7164\n",
      "Epoch 686/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.9941 - val_loss: 63.0619\n",
      "Epoch 687/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 5.4768 - val_loss: 78.1925\n",
      "Epoch 688/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 5.4030 - val_loss: 75.3936\n",
      "Epoch 689/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.1854 - val_loss: 64.9315\n",
      "Epoch 690/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9942 - val_loss: 68.1074\n",
      "Epoch 691/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.2141 - val_loss: 80.2255\n",
      "Epoch 692/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.0930 - val_loss: 59.4029\n",
      "Epoch 693/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 6.5950 - val_loss: 61.0073\n",
      "Epoch 694/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.8218 - val_loss: 69.0555\n",
      "Epoch 695/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.0850 - val_loss: 73.3518\n",
      "Epoch 696/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.9836 - val_loss: 61.3245\n",
      "Epoch 697/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 6.5957 - val_loss: 70.5071\n",
      "Epoch 698/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.3538 - val_loss: 66.0246\n",
      "Epoch 699/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.0212 - val_loss: 68.5142\n",
      "Epoch 700/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7200 - val_loss: 62.5329\n",
      "Epoch 701/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.3188 - val_loss: 72.9741\n",
      "Epoch 702/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.4598 - val_loss: 70.5618\n",
      "Epoch 703/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9789 - val_loss: 67.2384\n",
      "Epoch 704/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.7979 - val_loss: 64.1555\n",
      "Epoch 705/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 6.5611 - val_loss: 62.7480\n",
      "Epoch 706/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 5.7456 - val_loss: 72.6046\n",
      "Epoch 707/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.0537 - val_loss: 68.6627\n",
      "Epoch 708/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.7009 - val_loss: 90.3174\n",
      "Epoch 709/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.7196 - val_loss: 74.0896\n",
      "Epoch 710/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.0346 - val_loss: 73.9405\n",
      "Epoch 711/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.1157 - val_loss: 72.0946\n",
      "Epoch 712/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.2013 - val_loss: 74.9999\n",
      "Epoch 713/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.1097 - val_loss: 71.6083\n",
      "Epoch 714/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.0036 - val_loss: 78.9425\n",
      "Epoch 715/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.8879 - val_loss: 67.7841\n",
      "Epoch 716/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.8694 - val_loss: 74.0589\n",
      "Epoch 717/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.8770 - val_loss: 67.2825\n",
      "Epoch 718/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.4486 - val_loss: 68.4365\n",
      "Epoch 719/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.9347 - val_loss: 69.9069\n",
      "Epoch 720/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 5.6108 - val_loss: 69.5801\n",
      "Epoch 721/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 5.6049 - val_loss: 77.3898\n",
      "Epoch 722/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 6.0480 - val_loss: 75.3008\n",
      "Epoch 723/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.5656 - val_loss: 73.1005\n",
      "Epoch 724/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 6.6023 - val_loss: 68.6638\n",
      "Epoch 725/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.0607 - val_loss: 78.8007\n",
      "Epoch 726/5000\n",
      "1063/1063 [==============================] - 0s 121us/step - loss: 5.5884 - val_loss: 63.3231\n",
      "Epoch 727/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.7861 - val_loss: 63.9332\n",
      "Epoch 728/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.7561 - val_loss: 66.9454\n",
      "Epoch 729/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.3131 - val_loss: 92.2975\n",
      "Epoch 730/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.9487 - val_loss: 63.0981\n",
      "Epoch 731/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 5.2839 - val_loss: 76.2605\n",
      "Epoch 732/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 5.4956 - val_loss: 67.8646\n",
      "Epoch 733/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.6323 - val_loss: 74.1636\n",
      "Epoch 734/5000\n",
      "1063/1063 [==============================] - 0s 120us/step - loss: 5.2655 - val_loss: 72.1290\n",
      "Epoch 735/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 5.6554 - val_loss: 77.2518\n",
      "Epoch 736/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.3941 - val_loss: 75.4029\n",
      "Epoch 737/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 5.3967 - val_loss: 74.0504\n",
      "Epoch 738/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.0724 - val_loss: 69.5448\n",
      "Epoch 739/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7624 - val_loss: 62.8761\n",
      "Epoch 740/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.3466 - val_loss: 67.9817\n",
      "Epoch 741/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7715 - val_loss: 70.2001\n",
      "Epoch 742/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.1947 - val_loss: 75.6182\n",
      "Epoch 743/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.7352 - val_loss: 73.1743\n",
      "Epoch 744/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.9108 - val_loss: 66.2556\n",
      "Epoch 745/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8997 - val_loss: 70.3884\n",
      "Epoch 746/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.0716 - val_loss: 79.5063\n",
      "Epoch 747/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.9590 - val_loss: 76.0911\n",
      "Epoch 748/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.7266 - val_loss: 73.8938\n",
      "Epoch 749/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.9671 - val_loss: 63.7734\n",
      "Epoch 750/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.3573 - val_loss: 88.1485\n",
      "Epoch 751/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.6055 - val_loss: 71.2443\n",
      "Epoch 752/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.7627 - val_loss: 67.1766\n",
      "Epoch 753/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 5.3531 - val_loss: 61.9510\n",
      "Epoch 754/5000\n",
      "1063/1063 [==============================] - 0s 123us/step - loss: 5.8696 - val_loss: 66.7720\n",
      "Epoch 755/5000\n",
      "1063/1063 [==============================] - 0s 129us/step - loss: 4.8871 - val_loss: 65.3533\n",
      "Epoch 756/5000\n",
      "1063/1063 [==============================] - 0s 125us/step - loss: 5.1056 - val_loss: 69.8529\n",
      "Epoch 757/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 4.8365 - val_loss: 75.3552\n",
      "Epoch 758/5000\n",
      "1063/1063 [==============================] - 0s 138us/step - loss: 5.5236 - val_loss: 85.4537\n",
      "Epoch 759/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.5498 - val_loss: 71.0289\n",
      "Epoch 760/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.7385 - val_loss: 65.2636\n",
      "Epoch 761/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 6.4515 - val_loss: 76.0627\n",
      "Epoch 762/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 5.7497 - val_loss: 69.7209\n",
      "Epoch 763/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.5308 - val_loss: 69.3414\n",
      "Epoch 764/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.9760 - val_loss: 82.2993\n",
      "Epoch 765/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.2471 - val_loss: 69.6925\n",
      "Epoch 766/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.9328 - val_loss: 71.6080\n",
      "Epoch 767/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.1102 - val_loss: 71.5670\n",
      "Epoch 768/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.8647 - val_loss: 76.2944\n",
      "Epoch 769/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.9484 - val_loss: 65.3822\n",
      "Epoch 770/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.3937 - val_loss: 67.6739\n",
      "Epoch 771/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.8085 - val_loss: 68.3467\n",
      "Epoch 772/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.0304 - val_loss: 78.2888\n",
      "Epoch 773/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 6.0064 - val_loss: 76.2639\n",
      "Epoch 774/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.2652 - val_loss: 88.8181\n",
      "Epoch 775/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 6.1628 - val_loss: 62.0350\n",
      "Epoch 776/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 6.0771 - val_loss: 77.2476\n",
      "Epoch 777/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.3044 - val_loss: 70.8570\n",
      "Epoch 778/5000\n",
      "1063/1063 [==============================] - 0s 119us/step - loss: 4.7618 - val_loss: 73.0002\n",
      "Epoch 779/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.8095 - val_loss: 70.8039\n",
      "Epoch 780/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8785 - val_loss: 73.9821\n",
      "Epoch 781/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.6084 - val_loss: 74.4690\n",
      "Epoch 782/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.8042 - val_loss: 66.4474\n",
      "Epoch 783/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.3603 - val_loss: 65.2485\n",
      "Epoch 784/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.9392 - val_loss: 71.5756\n",
      "Epoch 785/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.0355 - val_loss: 60.9109\n",
      "Epoch 786/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.0449 - val_loss: 85.3099\n",
      "Epoch 787/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.2920 - val_loss: 72.0819\n",
      "Epoch 788/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.0029 - val_loss: 79.5206\n",
      "Epoch 789/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 5.3684 - val_loss: 76.2100\n",
      "Epoch 790/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.9544 - val_loss: 61.0150\n",
      "Epoch 791/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.1322 - val_loss: 70.1727\n",
      "Epoch 792/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.6772 - val_loss: 73.7069\n",
      "Epoch 793/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 5.2552 - val_loss: 63.5785\n",
      "Epoch 794/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.8519 - val_loss: 74.7478\n",
      "Epoch 795/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.8831 - val_loss: 80.5074\n",
      "Epoch 796/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.5017 - val_loss: 64.0487\n",
      "Epoch 797/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.5852 - val_loss: 77.5646\n",
      "Epoch 798/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.8304 - val_loss: 72.6359\n",
      "Epoch 799/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.6702 - val_loss: 69.4865\n",
      "Epoch 800/5000\n",
      "1063/1063 [==============================] - 0s 123us/step - loss: 5.0793 - val_loss: 65.1290\n",
      "Epoch 801/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.0628 - val_loss: 76.0206\n",
      "Epoch 802/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.3078 - val_loss: 70.6869\n",
      "Epoch 803/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.9436 - val_loss: 67.9524\n",
      "Epoch 804/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.1575 - val_loss: 76.6373\n",
      "Epoch 805/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.7896 - val_loss: 68.0526\n",
      "Epoch 806/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.3670 - val_loss: 70.8919\n",
      "Epoch 807/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.9082 - val_loss: 71.5436\n",
      "Epoch 808/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.1463 - val_loss: 81.3060\n",
      "Epoch 809/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.1396 - val_loss: 70.9133\n",
      "Epoch 810/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.9600 - val_loss: 59.7444\n",
      "Epoch 811/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.8848 - val_loss: 79.9453\n",
      "Epoch 812/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.6713 - val_loss: 70.0966\n",
      "Epoch 813/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.3749 - val_loss: 73.7858\n",
      "Epoch 814/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.8514 - val_loss: 62.2948\n",
      "Epoch 815/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.1978 - val_loss: 66.3081\n",
      "Epoch 816/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.0095 - val_loss: 65.2470\n",
      "Epoch 817/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.5193 - val_loss: 64.0958\n",
      "Epoch 818/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.2535 - val_loss: 73.8041\n",
      "Epoch 819/5000\n",
      "1063/1063 [==============================] - 0s 134us/step - loss: 5.2492 - val_loss: 62.2777\n",
      "Epoch 820/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.3635 - val_loss: 71.1050\n",
      "Epoch 821/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.6010 - val_loss: 76.5760\n",
      "Epoch 822/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 5.0188 - val_loss: 75.8644\n",
      "Epoch 823/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.8038 - val_loss: 79.5174\n",
      "Epoch 824/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.1069 - val_loss: 84.5267\n",
      "Epoch 825/5000\n",
      "1063/1063 [==============================] - 0s 125us/step - loss: 5.9815 - val_loss: 67.9304\n",
      "Epoch 826/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.9024 - val_loss: 70.4002\n",
      "Epoch 827/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.9567 - val_loss: 83.8732\n",
      "Epoch 828/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.8548 - val_loss: 65.1122\n",
      "Epoch 829/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.8423 - val_loss: 69.1138\n",
      "Epoch 830/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.0006 - val_loss: 78.9977\n",
      "Epoch 831/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.3275 - val_loss: 67.2751\n",
      "Epoch 832/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.9238 - val_loss: 62.7559\n",
      "Epoch 833/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.9242 - val_loss: 73.4844\n",
      "Epoch 834/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 5.4169 - val_loss: 71.0308\n",
      "Epoch 835/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 6.1849 - val_loss: 71.6838\n",
      "Epoch 836/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 6.0061 - val_loss: 75.2788\n",
      "Epoch 837/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.9361 - val_loss: 75.6888\n",
      "Epoch 838/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.7590 - val_loss: 73.0215\n",
      "Epoch 839/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5773 - val_loss: 65.9491\n",
      "Epoch 840/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.8456 - val_loss: 71.7677\n",
      "Epoch 841/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7867 - val_loss: 72.0178\n",
      "Epoch 842/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.5389 - val_loss: 69.4323\n",
      "Epoch 843/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.6389 - val_loss: 69.1696\n",
      "Epoch 844/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7398 - val_loss: 82.9847\n",
      "Epoch 845/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.7683 - val_loss: 68.1829\n",
      "Epoch 846/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.2340 - val_loss: 74.9438\n",
      "Epoch 847/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 5.1439 - val_loss: 78.6951\n",
      "Epoch 848/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.2120 - val_loss: 66.8775\n",
      "Epoch 849/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7311 - val_loss: 71.7263\n",
      "Epoch 850/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.7187 - val_loss: 68.7849\n",
      "Epoch 851/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.8486 - val_loss: 68.4692\n",
      "Epoch 852/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.0152 - val_loss: 73.2209\n",
      "Epoch 853/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.9249 - val_loss: 74.3062\n",
      "Epoch 854/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.7383 - val_loss: 84.6490\n",
      "Epoch 855/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 6.4602 - val_loss: 77.6952\n",
      "Epoch 856/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 5.8119 - val_loss: 79.7615\n",
      "Epoch 857/5000\n",
      "1063/1063 [==============================] - 0s 125us/step - loss: 5.8276 - val_loss: 68.2593\n",
      "Epoch 858/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.0623 - val_loss: 78.6715\n",
      "Epoch 859/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.0013 - val_loss: 63.8167\n",
      "Epoch 860/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.0568 - val_loss: 64.6434\n",
      "Epoch 861/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.5758 - val_loss: 65.8889\n",
      "Epoch 862/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8584 - val_loss: 66.6708\n",
      "Epoch 863/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 5.0120 - val_loss: 62.8287\n",
      "Epoch 864/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 5.1211 - val_loss: 72.7944\n",
      "Epoch 865/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.8011 - val_loss: 68.0654\n",
      "Epoch 866/5000\n",
      "1063/1063 [==============================] - 0s 128us/step - loss: 5.1312 - val_loss: 65.4731\n",
      "Epoch 867/5000\n",
      "1063/1063 [==============================] - 0s 124us/step - loss: 6.2875 - val_loss: 63.7798\n",
      "Epoch 868/5000\n",
      "1063/1063 [==============================] - 0s 121us/step - loss: 5.1579 - val_loss: 70.9413\n",
      "Epoch 869/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.7832 - val_loss: 68.0741\n",
      "Epoch 870/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.9506 - val_loss: 71.0656\n",
      "Epoch 871/5000\n",
      "1063/1063 [==============================] - 0s 117us/step - loss: 5.0984 - val_loss: 84.4678\n",
      "Epoch 872/5000\n",
      "1063/1063 [==============================] - 0s 143us/step - loss: 5.1305 - val_loss: 65.3215\n",
      "Epoch 873/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 6.0964 - val_loss: 59.7667\n",
      "Epoch 874/5000\n",
      "1063/1063 [==============================] - 0s 124us/step - loss: 5.3886 - val_loss: 71.4619\n",
      "Epoch 875/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.7746 - val_loss: 71.3399\n",
      "Epoch 876/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 5.3657 - val_loss: 69.2936\n",
      "Epoch 877/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.4302 - val_loss: 68.7421\n",
      "Epoch 878/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 5.9097 - val_loss: 75.1760\n",
      "Epoch 879/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 5.3299 - val_loss: 63.8739\n",
      "Epoch 880/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.9441 - val_loss: 69.4910\n",
      "Epoch 881/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 5.1981 - val_loss: 72.4734\n",
      "Epoch 882/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.0043 - val_loss: 68.8738\n",
      "Epoch 883/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 5.0649 - val_loss: 76.4188\n",
      "Epoch 884/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.6938 - val_loss: 85.6090\n",
      "Epoch 885/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.0168 - val_loss: 76.4142\n",
      "Epoch 886/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7384 - val_loss: 75.4100\n",
      "Epoch 887/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.6477 - val_loss: 74.7973\n",
      "Epoch 888/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8013 - val_loss: 80.9676\n",
      "Epoch 889/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.1106 - val_loss: 78.0336\n",
      "Epoch 890/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6561 - val_loss: 69.2801\n",
      "Epoch 891/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8315 - val_loss: 75.4789\n",
      "Epoch 892/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.8736 - val_loss: 75.5347\n",
      "Epoch 893/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.9992 - val_loss: 75.3734\n",
      "Epoch 894/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 6.0422 - val_loss: 68.1523\n",
      "Epoch 895/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 6.4377 - val_loss: 79.8100\n",
      "Epoch 896/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.9895 - val_loss: 65.7362\n",
      "Epoch 897/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.1005 - val_loss: 68.2003\n",
      "Epoch 898/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.1389 - val_loss: 77.6241\n",
      "Epoch 899/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.3140 - val_loss: 73.2310\n",
      "Epoch 900/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.9350 - val_loss: 68.1917\n",
      "Epoch 901/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5906 - val_loss: 76.0274\n",
      "Epoch 902/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.2568 - val_loss: 65.5959\n",
      "Epoch 903/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.0105 - val_loss: 64.8286\n",
      "Epoch 904/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.0789 - val_loss: 77.1274\n",
      "Epoch 905/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9245 - val_loss: 80.9918\n",
      "Epoch 906/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.0796 - val_loss: 66.6080\n",
      "Epoch 907/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.9880 - val_loss: 76.4476\n",
      "Epoch 908/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.1390 - val_loss: 64.8031\n",
      "Epoch 909/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 5.0806 - val_loss: 68.9951\n",
      "Epoch 910/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.4893 - val_loss: 72.5446\n",
      "Epoch 911/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.1024 - val_loss: 73.9783\n",
      "Epoch 912/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.4272 - val_loss: 81.8304\n",
      "Epoch 913/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 6.2918 - val_loss: 80.2392\n",
      "Epoch 914/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 5.1524 - val_loss: 67.4271\n",
      "Epoch 915/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7102 - val_loss: 75.9082\n",
      "Epoch 916/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.9444 - val_loss: 65.8125\n",
      "Epoch 917/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.9452 - val_loss: 76.8606\n",
      "Epoch 918/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.0840 - val_loss: 69.8673\n",
      "Epoch 919/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.4649 - val_loss: 79.6610\n",
      "Epoch 920/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5981 - val_loss: 66.0829\n",
      "Epoch 921/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 6.3048 - val_loss: 64.1146\n",
      "Epoch 922/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.0853 - val_loss: 66.9189\n",
      "Epoch 923/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 5.0135 - val_loss: 63.0840\n",
      "Epoch 924/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 6.6750 - val_loss: 69.9836\n",
      "Epoch 925/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7668 - val_loss: 74.5925\n",
      "Epoch 926/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.4658 - val_loss: 81.6483\n",
      "Epoch 927/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.1159 - val_loss: 71.7664\n",
      "Epoch 928/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7290 - val_loss: 67.6694\n",
      "Epoch 929/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.3062 - val_loss: 62.9743\n",
      "Epoch 930/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7868 - val_loss: 65.8933\n",
      "Epoch 931/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8542 - val_loss: 66.6839\n",
      "Epoch 932/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.2969 - val_loss: 73.8614\n",
      "Epoch 933/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.8961 - val_loss: 70.2470\n",
      "Epoch 934/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8091 - val_loss: 80.2021\n",
      "Epoch 935/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.2225 - val_loss: 70.4397\n",
      "Epoch 936/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.9317 - val_loss: 69.4547\n",
      "Epoch 937/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.0785 - val_loss: 78.7352\n",
      "Epoch 938/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.8623 - val_loss: 63.6133\n",
      "Epoch 939/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.8197 - val_loss: 73.7269\n",
      "Epoch 940/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.3457 - val_loss: 68.7372\n",
      "Epoch 941/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.5517 - val_loss: 71.2266\n",
      "Epoch 942/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8579 - val_loss: 77.0518\n",
      "Epoch 943/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.1681 - val_loss: 63.4781\n",
      "Epoch 944/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.5105 - val_loss: 77.0566\n",
      "Epoch 945/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.0180 - val_loss: 77.5946\n",
      "Epoch 946/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.9229 - val_loss: 72.9627\n",
      "Epoch 947/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.0747 - val_loss: 72.5202\n",
      "Epoch 948/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5993 - val_loss: 78.9588\n",
      "Epoch 949/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8872 - val_loss: 80.3238\n",
      "Epoch 950/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.2969 - val_loss: 69.3858\n",
      "Epoch 951/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.2640 - val_loss: 73.8608\n",
      "Epoch 952/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6350 - val_loss: 63.0949\n",
      "Epoch 953/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.1993 - val_loss: 67.5067\n",
      "Epoch 954/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.8257 - val_loss: 67.9324\n",
      "Epoch 955/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.0824 - val_loss: 81.8481\n",
      "Epoch 956/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.7483 - val_loss: 65.1605\n",
      "Epoch 957/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7061 - val_loss: 62.9121\n",
      "Epoch 958/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7416 - val_loss: 69.9205\n",
      "Epoch 959/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8211 - val_loss: 87.4475\n",
      "Epoch 960/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.8766 - val_loss: 66.9558\n",
      "Epoch 961/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.1237 - val_loss: 82.5929\n",
      "Epoch 962/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.8792 - val_loss: 69.7913\n",
      "Epoch 963/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.7957 - val_loss: 72.7695\n",
      "Epoch 964/5000\n",
      "1063/1063 [==============================] - 0s 121us/step - loss: 4.6861 - val_loss: 65.4492\n",
      "Epoch 965/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.7108 - val_loss: 66.8616\n",
      "Epoch 966/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.7020 - val_loss: 80.8476\n",
      "Epoch 967/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.0150 - val_loss: 69.3481\n",
      "Epoch 968/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.8270 - val_loss: 67.9913\n",
      "Epoch 969/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.9653 - val_loss: 69.3758\n",
      "Epoch 970/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 4.8854 - val_loss: 76.4021\n",
      "Epoch 971/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.6179 - val_loss: 74.0951\n",
      "Epoch 972/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.7626 - val_loss: 70.9132\n",
      "Epoch 973/5000\n",
      "1063/1063 [==============================] - 0s 121us/step - loss: 4.9772 - val_loss: 69.4755\n",
      "Epoch 974/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.6132 - val_loss: 68.6973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 975/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.9203 - val_loss: 68.9698\n",
      "Epoch 976/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.8998 - val_loss: 65.4236\n",
      "Epoch 977/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.0713 - val_loss: 74.1261\n",
      "Epoch 978/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.1344 - val_loss: 69.7609\n",
      "Epoch 979/5000\n",
      "1063/1063 [==============================] - 0s 140us/step - loss: 4.8535 - val_loss: 71.1709\n",
      "Epoch 980/5000\n",
      "1063/1063 [==============================] - 0s 158us/step - loss: 6.2819 - val_loss: 74.2276\n",
      "Epoch 981/5000\n",
      "1063/1063 [==============================] - 0s 135us/step - loss: 5.4865 - val_loss: 81.8159\n",
      "Epoch 982/5000\n",
      "1063/1063 [==============================] - 0s 153us/step - loss: 5.2984 - val_loss: 74.9591\n",
      "Epoch 983/5000\n",
      "1063/1063 [==============================] - 0s 144us/step - loss: 4.9374 - val_loss: 63.8649\n",
      "Epoch 984/5000\n",
      "1063/1063 [==============================] - 0s 183us/step - loss: 5.6853 - val_loss: 77.4179\n",
      "Epoch 985/5000\n",
      "1063/1063 [==============================] - 0s 131us/step - loss: 5.2801 - val_loss: 64.4570\n",
      "Epoch 986/5000\n",
      "1063/1063 [==============================] - 0s 161us/step - loss: 5.0557 - val_loss: 64.5007\n",
      "Epoch 987/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.8365 - val_loss: 85.3018\n",
      "Epoch 988/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 6.0632 - val_loss: 66.3509\n",
      "Epoch 989/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.0349 - val_loss: 63.4965\n",
      "Epoch 990/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.4361 - val_loss: 75.5165\n",
      "Epoch 991/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8782 - val_loss: 76.4259\n",
      "Epoch 992/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8977 - val_loss: 71.1391\n",
      "Epoch 993/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7326 - val_loss: 65.6906\n",
      "Epoch 994/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.0402 - val_loss: 73.2052\n",
      "Epoch 995/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.6158 - val_loss: 77.0761\n",
      "Epoch 996/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.2564 - val_loss: 67.3550\n",
      "Epoch 997/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 6.2940 - val_loss: 78.8310\n",
      "Epoch 998/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 6.8925 - val_loss: 69.1650\n",
      "Epoch 999/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 6.1888 - val_loss: 75.7996\n",
      "Epoch 1000/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 6.5328 - val_loss: 62.7520\n",
      "Epoch 1001/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.8819 - val_loss: 70.1097\n",
      "Epoch 1002/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.6105 - val_loss: 67.1034\n",
      "Epoch 1003/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 6.0152 - val_loss: 76.6911\n",
      "Epoch 1004/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.0353 - val_loss: 66.5461\n",
      "Epoch 1005/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.7163 - val_loss: 67.3254\n",
      "Epoch 1006/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.0305 - val_loss: 67.7402\n",
      "Epoch 1007/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.9832 - val_loss: 67.7883\n",
      "Epoch 1008/5000\n",
      "1063/1063 [==============================] - 0s 124us/step - loss: 4.8918 - val_loss: 61.6469\n",
      "Epoch 1009/5000\n",
      "1063/1063 [==============================] - 0s 134us/step - loss: 5.1818 - val_loss: 70.6924\n",
      "Epoch 1010/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.3865 - val_loss: 68.6639\n",
      "Epoch 1011/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.1528 - val_loss: 67.5452\n",
      "Epoch 1012/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.0814 - val_loss: 66.0989\n",
      "Epoch 1013/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.9966 - val_loss: 77.3985\n",
      "Epoch 1014/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.7805 - val_loss: 65.4295\n",
      "Epoch 1015/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.9550 - val_loss: 81.8751\n",
      "Epoch 1016/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.7935 - val_loss: 69.2456\n",
      "Epoch 1017/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.5019 - val_loss: 65.4300\n",
      "Epoch 1018/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 5.4101 - val_loss: 69.1373\n",
      "Epoch 1019/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.0685 - val_loss: 78.3145\n",
      "Epoch 1020/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.6800 - val_loss: 77.0329\n",
      "Epoch 1021/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.9445 - val_loss: 66.8929\n",
      "Epoch 1022/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.9348 - val_loss: 79.0804\n",
      "Epoch 1023/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.7889 - val_loss: 89.4487\n",
      "Epoch 1024/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.8363 - val_loss: 72.2903\n",
      "Epoch 1025/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.8673 - val_loss: 71.9172\n",
      "Epoch 1026/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.7753 - val_loss: 69.9512\n",
      "Epoch 1027/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.8646 - val_loss: 72.4573\n",
      "Epoch 1028/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 5.2049 - val_loss: 77.4855\n",
      "Epoch 1029/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.2501 - val_loss: 70.5930\n",
      "Epoch 1030/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.8033 - val_loss: 79.2289\n",
      "Epoch 1031/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9106 - val_loss: 64.8015\n",
      "Epoch 1032/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9419 - val_loss: 71.2793\n",
      "Epoch 1033/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6127 - val_loss: 66.7954\n",
      "Epoch 1034/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7398 - val_loss: 75.6305\n",
      "Epoch 1035/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.7736 - val_loss: 75.7568\n",
      "Epoch 1036/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.8311 - val_loss: 77.7282\n",
      "Epoch 1037/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.1053 - val_loss: 67.0929\n",
      "Epoch 1038/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4264 - val_loss: 64.7761\n",
      "Epoch 1039/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7167 - val_loss: 71.9199\n",
      "Epoch 1040/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.8150 - val_loss: 71.1402\n",
      "Epoch 1041/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7179 - val_loss: 65.8674\n",
      "Epoch 1042/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.1400 - val_loss: 79.3634\n",
      "Epoch 1043/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.8242 - val_loss: 80.4459\n",
      "Epoch 1044/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.2151 - val_loss: 61.8330\n",
      "Epoch 1045/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 5.0977 - val_loss: 65.6772\n",
      "Epoch 1046/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 4.8553 - val_loss: 79.1927\n",
      "Epoch 1047/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.8553 - val_loss: 70.8406\n",
      "Epoch 1048/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.7782 - val_loss: 66.8399\n",
      "Epoch 1049/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 6.0413 - val_loss: 70.6160\n",
      "Epoch 1050/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.9849 - val_loss: 70.8849\n",
      "Epoch 1051/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.4167 - val_loss: 66.4552\n",
      "Epoch 1052/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.7077 - val_loss: 66.8873\n",
      "Epoch 1053/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.8950 - val_loss: 71.9977\n",
      "Epoch 1054/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.7715 - val_loss: 69.9437\n",
      "Epoch 1055/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.7263 - val_loss: 67.9408\n",
      "Epoch 1056/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6748 - val_loss: 72.1885\n",
      "Epoch 1057/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7594 - val_loss: 61.4757\n",
      "Epoch 1058/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.6894 - val_loss: 63.9643\n",
      "Epoch 1059/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.4209 - val_loss: 70.4137\n",
      "Epoch 1060/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.6684 - val_loss: 76.9991\n",
      "Epoch 1061/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7421 - val_loss: 72.0957\n",
      "Epoch 1062/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.9464 - val_loss: 69.7354\n",
      "Epoch 1063/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8606 - val_loss: 64.5893\n",
      "Epoch 1064/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.6243 - val_loss: 83.0910\n",
      "Epoch 1065/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 5.0811 - val_loss: 66.2882\n",
      "Epoch 1066/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5154 - val_loss: 68.8746\n",
      "Epoch 1067/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9704 - val_loss: 76.9987\n",
      "Epoch 1068/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9350 - val_loss: 71.8775\n",
      "Epoch 1069/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6363 - val_loss: 78.3094\n",
      "Epoch 1070/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7004 - val_loss: 63.8766\n",
      "Epoch 1071/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.3219 - val_loss: 84.4559\n",
      "Epoch 1072/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.7737 - val_loss: 65.3507\n",
      "Epoch 1073/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.2467 - val_loss: 72.4128\n",
      "Epoch 1074/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6703 - val_loss: 70.5112\n",
      "Epoch 1075/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.7880 - val_loss: 70.6518\n",
      "Epoch 1076/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.7869 - val_loss: 75.1670\n",
      "Epoch 1077/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8397 - val_loss: 73.0047\n",
      "Epoch 1078/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.5054 - val_loss: 65.8094\n",
      "Epoch 1079/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.6101 - val_loss: 66.2398\n",
      "Epoch 1080/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9018 - val_loss: 67.9468\n",
      "Epoch 1081/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.3094 - val_loss: 73.3783\n",
      "Epoch 1082/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.0339 - val_loss: 68.9674\n",
      "Epoch 1083/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.1735 - val_loss: 78.9345\n",
      "Epoch 1084/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8800 - val_loss: 70.6826\n",
      "Epoch 1085/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.7212 - val_loss: 70.6584\n",
      "Epoch 1086/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.7832 - val_loss: 73.2633\n",
      "Epoch 1087/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8421 - val_loss: 74.6642\n",
      "Epoch 1088/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.5304 - val_loss: 75.3396\n",
      "Epoch 1089/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8520 - val_loss: 68.3766\n",
      "Epoch 1090/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.3219 - val_loss: 75.3658\n",
      "Epoch 1091/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.5952 - val_loss: 75.1757\n",
      "Epoch 1092/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9937 - val_loss: 72.2144\n",
      "Epoch 1093/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.2650 - val_loss: 71.1845\n",
      "Epoch 1094/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.0879 - val_loss: 75.7894\n",
      "Epoch 1095/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 5.3437 - val_loss: 82.8709\n",
      "Epoch 1096/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 6.1759 - val_loss: 68.2466\n",
      "Epoch 1097/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.8798 - val_loss: 74.3459\n",
      "Epoch 1098/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.0260 - val_loss: 67.4738\n",
      "Epoch 1099/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.7617 - val_loss: 70.3468\n",
      "Epoch 1100/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.8040 - val_loss: 69.6342\n",
      "Epoch 1101/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.7923 - val_loss: 84.8312\n",
      "Epoch 1102/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 5.2896 - val_loss: 76.6594\n",
      "Epoch 1103/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6250 - val_loss: 72.9886\n",
      "Epoch 1104/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6089 - val_loss: 69.9267\n",
      "Epoch 1105/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.8539 - val_loss: 68.0172\n",
      "Epoch 1106/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9128 - val_loss: 63.5019\n",
      "Epoch 1107/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.2317 - val_loss: 79.9167\n",
      "Epoch 1108/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.1356 - val_loss: 66.0843\n",
      "Epoch 1109/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5657 - val_loss: 72.8052\n",
      "Epoch 1110/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.0110 - val_loss: 78.1999\n",
      "Epoch 1111/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6495 - val_loss: 73.6180\n",
      "Epoch 1112/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.2878 - val_loss: 76.9897\n",
      "Epoch 1113/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6588 - val_loss: 70.3968\n",
      "Epoch 1114/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.8042 - val_loss: 64.4518\n",
      "Epoch 1115/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.9758 - val_loss: 80.2296\n",
      "Epoch 1116/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 6.6319 - val_loss: 71.4113\n",
      "Epoch 1117/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.3106 - val_loss: 74.5387\n",
      "Epoch 1118/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8603 - val_loss: 79.1192\n",
      "Epoch 1119/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7262 - val_loss: 76.9843\n",
      "Epoch 1120/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6485 - val_loss: 74.8340\n",
      "Epoch 1121/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9502 - val_loss: 71.5589\n",
      "Epoch 1122/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6709 - val_loss: 69.6398\n",
      "Epoch 1123/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7576 - val_loss: 73.5403\n",
      "Epoch 1124/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.0876 - val_loss: 75.7233\n",
      "Epoch 1125/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.6490 - val_loss: 76.3400\n",
      "Epoch 1126/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5540 - val_loss: 69.1272\n",
      "Epoch 1127/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5661 - val_loss: 66.1834\n",
      "Epoch 1128/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6821 - val_loss: 71.0685\n",
      "Epoch 1129/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.7550 - val_loss: 73.4911\n",
      "Epoch 1130/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.2940 - val_loss: 83.6080\n",
      "Epoch 1131/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.4067 - val_loss: 61.3704\n",
      "Epoch 1132/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.1216 - val_loss: 71.3730\n",
      "Epoch 1133/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8756 - val_loss: 73.8530\n",
      "Epoch 1134/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.9428 - val_loss: 67.7462\n",
      "Epoch 1135/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.2781 - val_loss: 72.8505\n",
      "Epoch 1136/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.9420 - val_loss: 70.5175\n",
      "Epoch 1137/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 5.7296 - val_loss: 68.4028\n",
      "Epoch 1138/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.1212 - val_loss: 83.6565\n",
      "Epoch 1139/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.9551 - val_loss: 68.7678\n",
      "Epoch 1140/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4295 - val_loss: 69.5967\n",
      "Epoch 1141/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.0157 - val_loss: 67.1028\n",
      "Epoch 1142/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.0609 - val_loss: 73.7792\n",
      "Epoch 1143/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5838 - val_loss: 63.4802\n",
      "Epoch 1144/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.9690 - val_loss: 68.2503\n",
      "Epoch 1145/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5251 - val_loss: 68.5055\n",
      "Epoch 1146/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.6216 - val_loss: 66.6293\n",
      "Epoch 1147/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.7539 - val_loss: 62.7979\n",
      "Epoch 1148/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.7294 - val_loss: 81.9025\n",
      "Epoch 1149/5000\n",
      "1063/1063 [==============================] - 0s 120us/step - loss: 5.4913 - val_loss: 83.3801\n",
      "Epoch 1150/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 5.5398 - val_loss: 70.7280\n",
      "Epoch 1151/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.9063 - val_loss: 68.0985\n",
      "Epoch 1152/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6888 - val_loss: 66.7993\n",
      "Epoch 1153/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7772 - val_loss: 70.1600\n",
      "Epoch 1154/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5863 - val_loss: 76.9612\n",
      "Epoch 1155/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.7041 - val_loss: 72.3807\n",
      "Epoch 1156/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7896 - val_loss: 67.5213\n",
      "Epoch 1157/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7658 - val_loss: 64.4909\n",
      "Epoch 1158/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7841 - val_loss: 72.3973\n",
      "Epoch 1159/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7076 - val_loss: 84.3875\n",
      "Epoch 1160/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.1455 - val_loss: 62.8452\n",
      "Epoch 1161/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.7559 - val_loss: 73.7011\n",
      "Epoch 1162/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.2084 - val_loss: 74.6229\n",
      "Epoch 1163/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5998 - val_loss: 71.2720\n",
      "Epoch 1164/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.9371 - val_loss: 76.8550\n",
      "Epoch 1165/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 5.0770 - val_loss: 79.9824\n",
      "Epoch 1166/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 5.1113 - val_loss: 79.5047\n",
      "Epoch 1167/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.0506 - val_loss: 72.8146\n",
      "Epoch 1168/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.8202 - val_loss: 67.3356\n",
      "Epoch 1169/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.8216 - val_loss: 69.6758\n",
      "Epoch 1170/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.1832 - val_loss: 78.5060\n",
      "Epoch 1171/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.2898 - val_loss: 73.7072\n",
      "Epoch 1172/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.7891 - val_loss: 64.3109\n",
      "Epoch 1173/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.0661 - val_loss: 76.9640\n",
      "Epoch 1174/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.6944 - val_loss: 73.0732\n",
      "Epoch 1175/5000\n",
      "1063/1063 [==============================] - 0s 126us/step - loss: 4.6424 - val_loss: 69.9366\n",
      "Epoch 1176/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.5128 - val_loss: 64.0586\n",
      "Epoch 1177/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.0532 - val_loss: 67.2905\n",
      "Epoch 1178/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.3086 - val_loss: 88.8957\n",
      "Epoch 1179/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.4992 - val_loss: 64.2962\n",
      "Epoch 1180/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 5.4576 - val_loss: 75.3553\n",
      "Epoch 1181/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.8605 - val_loss: 75.2063\n",
      "Epoch 1182/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8117 - val_loss: 73.1627\n",
      "Epoch 1183/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.1466 - val_loss: 67.8013\n",
      "Epoch 1184/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.7331 - val_loss: 67.9843\n",
      "Epoch 1185/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.8368 - val_loss: 70.6110\n",
      "Epoch 1186/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.4083 - val_loss: 71.5327\n",
      "Epoch 1187/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.7731 - val_loss: 84.1833\n",
      "Epoch 1188/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.9001 - val_loss: 77.5359\n",
      "Epoch 1189/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.6187 - val_loss: 73.8782\n",
      "Epoch 1190/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.9667 - val_loss: 72.2916\n",
      "Epoch 1191/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.8879 - val_loss: 68.6477\n",
      "Epoch 1192/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.7167 - val_loss: 74.7454\n",
      "Epoch 1193/5000\n",
      "1063/1063 [==============================] - 0s 133us/step - loss: 5.5199 - val_loss: 78.1535\n",
      "Epoch 1194/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.3159 - val_loss: 68.3810\n",
      "Epoch 1195/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.9494 - val_loss: 64.0375\n",
      "Epoch 1196/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4309 - val_loss: 71.2498\n",
      "Epoch 1197/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4827 - val_loss: 73.1753\n",
      "Epoch 1198/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.9884 - val_loss: 75.3037\n",
      "Epoch 1199/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.1868 - val_loss: 69.9978\n",
      "Epoch 1200/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.0022 - val_loss: 67.6262\n",
      "Epoch 1201/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.3785 - val_loss: 72.3745\n",
      "Epoch 1202/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.3023 - val_loss: 63.8882\n",
      "Epoch 1203/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.4271 - val_loss: 79.1386\n",
      "Epoch 1204/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7268 - val_loss: 66.1825\n",
      "Epoch 1205/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.1754 - val_loss: 71.7143\n",
      "Epoch 1206/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9922 - val_loss: 67.2046\n",
      "Epoch 1207/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.1456 - val_loss: 80.9162\n",
      "Epoch 1208/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 6.0688 - val_loss: 71.5325\n",
      "Epoch 1209/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.4662 - val_loss: 67.7583\n",
      "Epoch 1210/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.1487 - val_loss: 65.9734\n",
      "Epoch 1211/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5501 - val_loss: 66.4671\n",
      "Epoch 1212/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.5288 - val_loss: 80.1457\n",
      "Epoch 1213/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.4073 - val_loss: 68.2519\n",
      "Epoch 1214/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6437 - val_loss: 75.2546\n",
      "Epoch 1215/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7042 - val_loss: 69.1706\n",
      "Epoch 1216/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5879 - val_loss: 80.9060\n",
      "Epoch 1217/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.5503 - val_loss: 64.6666\n",
      "Epoch 1218/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6045 - val_loss: 72.7790\n",
      "Epoch 1219/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6762 - val_loss: 78.9540\n",
      "Epoch 1220/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8078 - val_loss: 68.0168\n",
      "Epoch 1221/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6609 - val_loss: 74.9754\n",
      "Epoch 1222/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.8090 - val_loss: 74.6316\n",
      "Epoch 1223/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5823 - val_loss: 72.6597\n",
      "Epoch 1224/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.0492 - val_loss: 68.7196\n",
      "Epoch 1225/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.3153 - val_loss: 73.1746\n",
      "Epoch 1226/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.1702 - val_loss: 73.6890\n",
      "Epoch 1227/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.9755 - val_loss: 77.1143\n",
      "Epoch 1228/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.4614 - val_loss: 64.7558\n",
      "Epoch 1229/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.1490 - val_loss: 93.9724\n",
      "Epoch 1230/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.8864 - val_loss: 66.9638\n",
      "Epoch 1231/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7335 - val_loss: 62.1583\n",
      "Epoch 1232/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7988 - val_loss: 77.6077\n",
      "Epoch 1233/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.0846 - val_loss: 69.6515\n",
      "Epoch 1234/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.5491 - val_loss: 69.7111\n",
      "Epoch 1235/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.5118 - val_loss: 71.4752\n",
      "Epoch 1236/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.8686 - val_loss: 73.5513\n",
      "Epoch 1237/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 5.4098 - val_loss: 78.8146\n",
      "Epoch 1238/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.8695 - val_loss: 70.8643\n",
      "Epoch 1239/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.0744 - val_loss: 72.5973\n",
      "Epoch 1240/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.3664 - val_loss: 75.4578\n",
      "Epoch 1241/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.7667 - val_loss: 70.0375\n",
      "Epoch 1242/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 5.1615 - val_loss: 73.8188\n",
      "Epoch 1243/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.0356 - val_loss: 66.4460\n",
      "Epoch 1244/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.2864 - val_loss: 71.3845\n",
      "Epoch 1245/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.1546 - val_loss: 74.1768\n",
      "Epoch 1246/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.1135 - val_loss: 73.2122\n",
      "Epoch 1247/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.8503 - val_loss: 70.3070\n",
      "Epoch 1248/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8662 - val_loss: 71.9758\n",
      "Epoch 1249/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.1006 - val_loss: 70.4547\n",
      "Epoch 1250/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.1829 - val_loss: 76.6390\n",
      "Epoch 1251/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.8186 - val_loss: 71.2509\n",
      "Epoch 1252/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7967 - val_loss: 69.8561\n",
      "Epoch 1253/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.9490 - val_loss: 72.8078\n",
      "Epoch 1254/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5793 - val_loss: 74.1420\n",
      "Epoch 1255/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.0359 - val_loss: 74.2815\n",
      "Epoch 1256/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.9733 - val_loss: 67.6015\n",
      "Epoch 1257/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.1002 - val_loss: 74.3777\n",
      "Epoch 1258/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.9222 - val_loss: 73.0849\n",
      "Epoch 1259/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.1294 - val_loss: 70.3930\n",
      "Epoch 1260/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.8134 - val_loss: 65.2632\n",
      "Epoch 1261/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.3669 - val_loss: 67.4742\n",
      "Epoch 1262/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.9880 - val_loss: 75.0939\n",
      "Epoch 1263/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.1279 - val_loss: 70.0938\n",
      "Epoch 1264/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.2779 - val_loss: 88.5838\n",
      "Epoch 1265/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 6.2382 - val_loss: 63.7290\n",
      "Epoch 1266/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.7702 - val_loss: 74.4365\n",
      "Epoch 1267/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.8316 - val_loss: 66.1256\n",
      "Epoch 1268/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 5.0360 - val_loss: 71.6599\n",
      "Epoch 1269/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.9882 - val_loss: 84.4488\n",
      "Epoch 1270/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.2292 - val_loss: 81.0728\n",
      "Epoch 1271/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.6745 - val_loss: 70.7068\n",
      "Epoch 1272/5000\n",
      "1063/1063 [==============================] - 0s 117us/step - loss: 4.8409 - val_loss: 76.7992\n",
      "Epoch 1273/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 5.2796 - val_loss: 64.8565\n",
      "Epoch 1274/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.8993 - val_loss: 79.0908\n",
      "Epoch 1275/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8798 - val_loss: 72.5199\n",
      "Epoch 1276/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 5.7333 - val_loss: 65.3620\n",
      "Epoch 1277/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.1987 - val_loss: 72.8911\n",
      "Epoch 1278/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.1433 - val_loss: 81.6194\n",
      "Epoch 1279/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.8138 - val_loss: 73.3562\n",
      "Epoch 1280/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.3724 - val_loss: 70.6616\n",
      "Epoch 1281/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8037 - val_loss: 72.6843\n",
      "Epoch 1282/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.8717 - val_loss: 73.6408\n",
      "Epoch 1283/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.6513 - val_loss: 67.9799\n",
      "Epoch 1284/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8421 - val_loss: 72.1497\n",
      "Epoch 1285/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.1363 - val_loss: 66.0318\n",
      "Epoch 1286/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.6661 - val_loss: 77.9494\n",
      "Epoch 1287/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.8273 - val_loss: 68.7437\n",
      "Epoch 1288/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.9633 - val_loss: 69.5468\n",
      "Epoch 1289/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.6056 - val_loss: 70.2234\n",
      "Epoch 1290/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.3310 - val_loss: 79.6723\n",
      "Epoch 1291/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 5.2729 - val_loss: 72.5177\n",
      "Epoch 1292/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.8417 - val_loss: 82.6342\n",
      "Epoch 1293/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 5.1387 - val_loss: 70.1973\n",
      "Epoch 1294/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.8123 - val_loss: 67.4780\n",
      "Epoch 1295/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.2080 - val_loss: 77.1694\n",
      "Epoch 1296/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8971 - val_loss: 65.8946\n",
      "Epoch 1297/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7794 - val_loss: 72.2805\n",
      "Epoch 1298/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7027 - val_loss: 76.7748\n",
      "Epoch 1299/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5642 - val_loss: 76.0203\n",
      "Epoch 1300/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7003 - val_loss: 70.5660\n",
      "Epoch 1301/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.0598 - val_loss: 66.7798\n",
      "Epoch 1302/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7382 - val_loss: 69.8505\n",
      "Epoch 1303/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.0793 - val_loss: 64.9142\n",
      "Epoch 1304/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6732 - val_loss: 72.7005\n",
      "Epoch 1305/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9967 - val_loss: 69.8367\n",
      "Epoch 1306/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9289 - val_loss: 66.9746\n",
      "Epoch 1307/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.4990 - val_loss: 68.4394\n",
      "Epoch 1308/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6340 - val_loss: 68.5807\n",
      "Epoch 1309/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7389 - val_loss: 68.4036\n",
      "Epoch 1310/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5318 - val_loss: 78.6438\n",
      "Epoch 1311/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.6413 - val_loss: 76.3733\n",
      "Epoch 1312/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.7901 - val_loss: 72.6514\n",
      "Epoch 1313/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.0192 - val_loss: 77.1015\n",
      "Epoch 1314/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.6922 - val_loss: 70.0616\n",
      "Epoch 1315/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.1400 - val_loss: 68.2094\n",
      "Epoch 1316/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 5.1377 - val_loss: 68.1645\n",
      "Epoch 1317/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.6968 - val_loss: 71.8778\n",
      "Epoch 1318/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.6885 - val_loss: 67.4218\n",
      "Epoch 1319/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.5444 - val_loss: 76.0122\n",
      "Epoch 1320/5000\n",
      "1063/1063 [==============================] - 0s 125us/step - loss: 5.0133 - val_loss: 68.1459\n",
      "Epoch 1321/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.9153 - val_loss: 71.8796\n",
      "Epoch 1322/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.6903 - val_loss: 70.3741\n",
      "Epoch 1323/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.7137 - val_loss: 68.3001\n",
      "Epoch 1324/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.6027 - val_loss: 73.7168\n",
      "Epoch 1325/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.7294 - val_loss: 67.3450\n",
      "Epoch 1326/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.6153 - val_loss: 73.1069\n",
      "Epoch 1327/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.0979 - val_loss: 73.5946\n",
      "Epoch 1328/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.5804 - val_loss: 74.0860\n",
      "Epoch 1329/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.8156 - val_loss: 67.9821\n",
      "Epoch 1330/5000\n",
      "1063/1063 [==============================] - 0s 123us/step - loss: 6.1100 - val_loss: 77.1064\n",
      "Epoch 1331/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.9894 - val_loss: 84.2879\n",
      "Epoch 1332/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.1690 - val_loss: 74.0021\n",
      "Epoch 1333/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.2578 - val_loss: 69.9308\n",
      "Epoch 1334/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.9168 - val_loss: 68.9325\n",
      "Epoch 1335/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7468 - val_loss: 60.9535\n",
      "Epoch 1336/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.2409 - val_loss: 78.1428\n",
      "Epoch 1337/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.5949 - val_loss: 70.9863\n",
      "Epoch 1338/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.4575 - val_loss: 72.8754\n",
      "Epoch 1339/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.7677 - val_loss: 73.8773\n",
      "Epoch 1340/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.1057 - val_loss: 76.0040\n",
      "Epoch 1341/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.6803 - val_loss: 83.4253\n",
      "Epoch 1342/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.2658 - val_loss: 60.8178\n",
      "Epoch 1343/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.2714 - val_loss: 85.9648\n",
      "Epoch 1344/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.9540 - val_loss: 77.2119\n",
      "Epoch 1345/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7618 - val_loss: 66.3188\n",
      "Epoch 1346/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.8033 - val_loss: 67.1210\n",
      "Epoch 1347/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.4292 - val_loss: 60.3172\n",
      "Epoch 1348/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 5.2838 - val_loss: 68.6471\n",
      "Epoch 1349/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 5.0136 - val_loss: 69.9548\n",
      "Epoch 1350/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.8425 - val_loss: 69.5416\n",
      "Epoch 1351/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5855 - val_loss: 69.7195\n",
      "Epoch 1352/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6796 - val_loss: 71.2158\n",
      "Epoch 1353/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6480 - val_loss: 77.2528\n",
      "Epoch 1354/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.1552 - val_loss: 69.6494\n",
      "Epoch 1355/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5727 - val_loss: 73.0492\n",
      "Epoch 1356/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6436 - val_loss: 66.6849\n",
      "Epoch 1357/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5406 - val_loss: 72.5499\n",
      "Epoch 1358/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9139 - val_loss: 77.1759\n",
      "Epoch 1359/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 5.3560 - val_loss: 71.5916\n",
      "Epoch 1360/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7594 - val_loss: 79.1574\n",
      "Epoch 1361/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.3872 - val_loss: 64.6799\n",
      "Epoch 1362/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9657 - val_loss: 69.8471\n",
      "Epoch 1363/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.2002 - val_loss: 63.6646\n",
      "Epoch 1364/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.2163 - val_loss: 72.7738\n",
      "Epoch 1365/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.0166 - val_loss: 74.6791\n",
      "Epoch 1366/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.0993 - val_loss: 77.4701\n",
      "Epoch 1367/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.6919 - val_loss: 71.0990\n",
      "Epoch 1368/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.4716 - val_loss: 73.8778\n",
      "Epoch 1369/5000\n",
      "1063/1063 [==============================] - 0s 119us/step - loss: 4.5202 - val_loss: 68.5414\n",
      "Epoch 1370/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.0336 - val_loss: 75.2600\n",
      "Epoch 1371/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.4034 - val_loss: 67.0027\n",
      "Epoch 1372/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5621 - val_loss: 67.3114\n",
      "Epoch 1373/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.8308 - val_loss: 65.6744\n",
      "Epoch 1374/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.1314 - val_loss: 74.4639\n",
      "Epoch 1375/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8720 - val_loss: 63.6244\n",
      "Epoch 1376/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8972 - val_loss: 66.5340\n",
      "Epoch 1377/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.8192 - val_loss: 70.2184\n",
      "Epoch 1378/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5575 - val_loss: 82.5000\n",
      "Epoch 1379/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.0168 - val_loss: 81.2333\n",
      "Epoch 1380/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9925 - val_loss: 80.3259\n",
      "Epoch 1381/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.1992 - val_loss: 66.7086\n",
      "Epoch 1382/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9192 - val_loss: 68.0620\n",
      "Epoch 1383/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9539 - val_loss: 65.6030\n",
      "Epoch 1384/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.0193 - val_loss: 65.8412\n",
      "Epoch 1385/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8122 - val_loss: 79.0984\n",
      "Epoch 1386/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.4754 - val_loss: 84.2143\n",
      "Epoch 1387/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7792 - val_loss: 74.9140\n",
      "Epoch 1388/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7280 - val_loss: 65.2231\n",
      "Epoch 1389/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.8871 - val_loss: 70.9896\n",
      "Epoch 1390/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.6131 - val_loss: 72.2820\n",
      "Epoch 1391/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6673 - val_loss: 74.3882\n",
      "Epoch 1392/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.0465 - val_loss: 72.7656\n",
      "Epoch 1393/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.8352 - val_loss: 70.7947\n",
      "Epoch 1394/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.7941 - val_loss: 71.7871\n",
      "Epoch 1395/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4766 - val_loss: 70.5088\n",
      "Epoch 1396/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.9786 - val_loss: 77.4842\n",
      "Epoch 1397/5000\n",
      "1063/1063 [==============================] - 0s 125us/step - loss: 4.5376 - val_loss: 77.9140\n",
      "Epoch 1398/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.8663 - val_loss: 61.7513\n",
      "Epoch 1399/5000\n",
      "1063/1063 [==============================] - 0s 122us/step - loss: 4.5619 - val_loss: 68.7669\n",
      "Epoch 1400/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.6282 - val_loss: 76.3922\n",
      "Epoch 1401/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.5841 - val_loss: 68.2677\n",
      "Epoch 1402/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.9476 - val_loss: 69.1344\n",
      "Epoch 1403/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.7698 - val_loss: 69.8745\n",
      "Epoch 1404/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.6434 - val_loss: 70.6600\n",
      "Epoch 1405/5000\n",
      "1063/1063 [==============================] - 0s 121us/step - loss: 5.4299 - val_loss: 67.2488\n",
      "Epoch 1406/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.7182 - val_loss: 77.9884\n",
      "Epoch 1407/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 5.1171 - val_loss: 63.7394\n",
      "Epoch 1408/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 6.3662 - val_loss: 78.1112\n",
      "Epoch 1409/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.6269 - val_loss: 68.9790\n",
      "Epoch 1410/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7283 - val_loss: 71.1318\n",
      "Epoch 1411/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6957 - val_loss: 63.6764\n",
      "Epoch 1412/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9256 - val_loss: 67.1659\n",
      "Epoch 1413/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.6048 - val_loss: 71.5662\n",
      "Epoch 1414/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.9241 - val_loss: 76.7819\n",
      "Epoch 1415/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.0385 - val_loss: 66.9062\n",
      "Epoch 1416/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.3981 - val_loss: 76.1311\n",
      "Epoch 1417/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.8392 - val_loss: 95.1721\n",
      "Epoch 1418/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 6.6292 - val_loss: 65.4192\n",
      "Epoch 1419/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.1413 - val_loss: 80.9227\n",
      "Epoch 1420/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8894 - val_loss: 67.9473\n",
      "Epoch 1421/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.4295 - val_loss: 82.9018\n",
      "Epoch 1422/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.1877 - val_loss: 64.9367\n",
      "Epoch 1423/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.8405 - val_loss: 75.8673\n",
      "Epoch 1424/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6764 - val_loss: 71.8276\n",
      "Epoch 1425/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.0018 - val_loss: 66.6947\n",
      "Epoch 1426/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6255 - val_loss: 73.3857\n",
      "Epoch 1427/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.7831 - val_loss: 68.9657\n",
      "Epoch 1428/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.8779 - val_loss: 69.0580\n",
      "Epoch 1429/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4807 - val_loss: 78.1510\n",
      "Epoch 1430/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9852 - val_loss: 70.1390\n",
      "Epoch 1431/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6372 - val_loss: 69.3762\n",
      "Epoch 1432/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.7659 - val_loss: 76.7430\n",
      "Epoch 1433/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.8128 - val_loss: 68.6828\n",
      "Epoch 1434/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7829 - val_loss: 71.7069\n",
      "Epoch 1435/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.9814 - val_loss: 62.5021\n",
      "Epoch 1436/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.8928 - val_loss: 81.5698\n",
      "Epoch 1437/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 5.0856 - val_loss: 69.0305\n",
      "Epoch 1438/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.7152 - val_loss: 72.0923\n",
      "Epoch 1439/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.7197 - val_loss: 75.4416\n",
      "Epoch 1440/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5885 - val_loss: 80.0955\n",
      "Epoch 1441/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.4036 - val_loss: 78.1617\n",
      "Epoch 1442/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.9860 - val_loss: 66.8923\n",
      "Epoch 1443/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.9364 - val_loss: 66.6587\n",
      "Epoch 1444/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.8545 - val_loss: 77.8830\n",
      "Epoch 1445/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.7139 - val_loss: 60.8021\n",
      "Epoch 1446/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.3730 - val_loss: 73.2784\n",
      "Epoch 1447/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.7820 - val_loss: 78.6143\n",
      "Epoch 1448/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.3111 - val_loss: 66.0338\n",
      "Epoch 1449/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5863 - val_loss: 72.9870\n",
      "Epoch 1450/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6553 - val_loss: 64.4963\n",
      "Epoch 1451/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.9789 - val_loss: 71.0179\n",
      "Epoch 1452/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.9449 - val_loss: 85.6409\n",
      "Epoch 1453/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8741 - val_loss: 58.4536\n",
      "Epoch 1454/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.9315 - val_loss: 68.9458\n",
      "Epoch 1455/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.5038 - val_loss: 62.5317\n",
      "Epoch 1456/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.9243 - val_loss: 73.9582\n",
      "Epoch 1457/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.6547 - val_loss: 67.9291\n",
      "Epoch 1458/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.8150 - val_loss: 77.1574\n",
      "Epoch 1459/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7192 - val_loss: 69.8397\n",
      "Epoch 1460/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.4087 - val_loss: 73.2030\n",
      "Epoch 1461/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.0139 - val_loss: 70.8996\n",
      "Epoch 1462/5000\n",
      "1063/1063 [==============================] - 0s 130us/step - loss: 4.9303 - val_loss: 78.3665\n",
      "Epoch 1463/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.7330 - val_loss: 77.6316\n",
      "Epoch 1464/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.9810 - val_loss: 66.3308\n",
      "Epoch 1465/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.8790 - val_loss: 73.5716\n",
      "Epoch 1466/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.4710 - val_loss: 71.5668\n",
      "Epoch 1467/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.8870 - val_loss: 72.7770\n",
      "Epoch 1468/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.1769 - val_loss: 68.6367\n",
      "Epoch 1469/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.4024 - val_loss: 78.1131\n",
      "Epoch 1470/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.8529 - val_loss: 69.3760\n",
      "Epoch 1471/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5720 - val_loss: 71.7645\n",
      "Epoch 1472/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.7284 - val_loss: 69.9281\n",
      "Epoch 1473/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6114 - val_loss: 69.3106\n",
      "Epoch 1474/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.7311 - val_loss: 66.9562\n",
      "Epoch 1475/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.4723 - val_loss: 76.7356\n",
      "Epoch 1476/5000\n",
      "1063/1063 [==============================] - 0s 117us/step - loss: 4.5517 - val_loss: 69.6489\n",
      "Epoch 1477/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.3823 - val_loss: 71.0050\n",
      "Epoch 1478/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.7234 - val_loss: 63.5082\n",
      "Epoch 1479/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.7922 - val_loss: 70.5123\n",
      "Epoch 1480/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.1292 - val_loss: 66.4185\n",
      "Epoch 1481/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.7115 - val_loss: 70.0622\n",
      "Epoch 1482/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.6054 - val_loss: 72.4832\n",
      "Epoch 1483/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 6.0567 - val_loss: 66.7176\n",
      "Epoch 1484/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.9344 - val_loss: 70.1131\n",
      "Epoch 1485/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 5.2108 - val_loss: 62.9295\n",
      "Epoch 1486/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 9.8430 - val_loss: 71.9822\n",
      "Epoch 1487/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9406 - val_loss: 65.9095\n",
      "Epoch 1488/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.9009 - val_loss: 69.5212\n",
      "Epoch 1489/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.6027 - val_loss: 77.4440\n",
      "Epoch 1490/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.7666 - val_loss: 74.2724\n",
      "Epoch 1491/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.8060 - val_loss: 76.1414\n",
      "Epoch 1492/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4762 - val_loss: 70.4914\n",
      "Epoch 1493/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5992 - val_loss: 72.3400\n",
      "Epoch 1494/5000\n",
      "1063/1063 [==============================] - 0s 135us/step - loss: 4.3673 - val_loss: 71.5341\n",
      "Epoch 1495/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.4033 - val_loss: 70.5810\n",
      "Epoch 1496/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4150 - val_loss: 72.4556\n",
      "Epoch 1497/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.6784 - val_loss: 66.6085\n",
      "Epoch 1498/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.6171 - val_loss: 84.3425\n",
      "Epoch 1499/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.9201 - val_loss: 73.8962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.0429 - val_loss: 82.9243\n",
      "Epoch 1501/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8839 - val_loss: 69.2688\n",
      "Epoch 1502/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.8406 - val_loss: 76.2973\n",
      "Epoch 1503/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9518 - val_loss: 71.8872\n",
      "Epoch 1504/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.7412 - val_loss: 70.7752\n",
      "Epoch 1505/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.7018 - val_loss: 72.4162\n",
      "Epoch 1506/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7560 - val_loss: 67.4640\n",
      "Epoch 1507/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7704 - val_loss: 70.7935\n",
      "Epoch 1508/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6931 - val_loss: 71.3051\n",
      "Epoch 1509/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.7476 - val_loss: 74.5630\n",
      "Epoch 1510/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.0539 - val_loss: 68.4242\n",
      "Epoch 1511/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.7037 - val_loss: 68.0169\n",
      "Epoch 1512/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5432 - val_loss: 66.4115\n",
      "Epoch 1513/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.1751 - val_loss: 70.8004\n",
      "Epoch 1514/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.0347 - val_loss: 71.9014\n",
      "Epoch 1515/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.8102 - val_loss: 67.7841\n",
      "Epoch 1516/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6136 - val_loss: 71.9074\n",
      "Epoch 1517/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.7075 - val_loss: 74.0659\n",
      "Epoch 1518/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5969 - val_loss: 66.9539\n",
      "Epoch 1519/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9004 - val_loss: 75.5329\n",
      "Epoch 1520/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.6175 - val_loss: 74.7512\n",
      "Epoch 1521/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5429 - val_loss: 75.6226\n",
      "Epoch 1522/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5454 - val_loss: 72.7427\n",
      "Epoch 1523/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.8065 - val_loss: 65.2478\n",
      "Epoch 1524/5000\n",
      "1063/1063 [==============================] - 0s 126us/step - loss: 5.0736 - val_loss: 68.8820\n",
      "Epoch 1525/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.9000 - val_loss: 76.7161\n",
      "Epoch 1526/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.5038 - val_loss: 61.3529\n",
      "Epoch 1527/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.0371 - val_loss: 62.9200\n",
      "Epoch 1528/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.0022 - val_loss: 69.9507\n",
      "Epoch 1529/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9404 - val_loss: 74.8633\n",
      "Epoch 1530/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.3944 - val_loss: 71.7178\n",
      "Epoch 1531/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.1815 - val_loss: 73.0491\n",
      "Epoch 1532/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6966 - val_loss: 75.5433\n",
      "Epoch 1533/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9767 - val_loss: 63.6922\n",
      "Epoch 1534/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6734 - val_loss: 75.5054\n",
      "Epoch 1535/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7518 - val_loss: 69.5498\n",
      "Epoch 1536/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.0999 - val_loss: 77.4314\n",
      "Epoch 1537/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8052 - val_loss: 68.1120\n",
      "Epoch 1538/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.8197 - val_loss: 69.3795\n",
      "Epoch 1539/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7637 - val_loss: 69.0209\n",
      "Epoch 1540/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 5.1230 - val_loss: 62.9548\n",
      "Epoch 1541/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.2451 - val_loss: 69.3558\n",
      "Epoch 1542/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.5490 - val_loss: 73.3727\n",
      "Epoch 1543/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7803 - val_loss: 69.8974\n",
      "Epoch 1544/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.7277 - val_loss: 63.5584\n",
      "Epoch 1545/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7567 - val_loss: 71.7977\n",
      "Epoch 1546/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.9258 - val_loss: 72.3747\n",
      "Epoch 1547/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6642 - val_loss: 65.4380\n",
      "Epoch 1548/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.0476 - val_loss: 63.2152\n",
      "Epoch 1549/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.9882 - val_loss: 85.0401\n",
      "Epoch 1550/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.1488 - val_loss: 75.2785\n",
      "Epoch 1551/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9046 - val_loss: 72.6864\n",
      "Epoch 1552/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6076 - val_loss: 71.9315\n",
      "Epoch 1553/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.9018 - val_loss: 75.3616\n",
      "Epoch 1554/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 5.2747 - val_loss: 67.8127\n",
      "Epoch 1555/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.1096 - val_loss: 70.7471\n",
      "Epoch 1556/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7807 - val_loss: 73.9766\n",
      "Epoch 1557/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9659 - val_loss: 75.7495\n",
      "Epoch 1558/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7824 - val_loss: 81.2475\n",
      "Epoch 1559/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.9945 - val_loss: 71.0244\n",
      "Epoch 1560/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6057 - val_loss: 76.1581\n",
      "Epoch 1561/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9213 - val_loss: 84.9733\n",
      "Epoch 1562/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8653 - val_loss: 70.8172\n",
      "Epoch 1563/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7225 - val_loss: 61.1418\n",
      "Epoch 1564/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.7654 - val_loss: 66.2338\n",
      "Epoch 1565/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.8698 - val_loss: 75.7503\n",
      "Epoch 1566/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5563 - val_loss: 67.4932\n",
      "Epoch 1567/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.0062 - val_loss: 70.3855\n",
      "Epoch 1568/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6440 - val_loss: 72.0038\n",
      "Epoch 1569/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.4831 - val_loss: 67.1449\n",
      "Epoch 1570/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.8630 - val_loss: 78.2641\n",
      "Epoch 1571/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6612 - val_loss: 67.9022\n",
      "Epoch 1572/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5628 - val_loss: 67.1323\n",
      "Epoch 1573/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.7061 - val_loss: 71.7474\n",
      "Epoch 1574/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.6590 - val_loss: 76.9505\n",
      "Epoch 1575/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 107us/step - loss: 5.3393 - val_loss: 68.2788\n",
      "Epoch 1576/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.5383 - val_loss: 79.1139\n",
      "Epoch 1577/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8989 - val_loss: 69.7825\n",
      "Epoch 1578/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7773 - val_loss: 69.7339\n",
      "Epoch 1579/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.4974 - val_loss: 71.3489\n",
      "Epoch 1580/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.3885 - val_loss: 76.4884\n",
      "Epoch 1581/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.8121 - val_loss: 69.5624\n",
      "Epoch 1582/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.9696 - val_loss: 67.8160\n",
      "Epoch 1583/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.3842 - val_loss: 69.1965\n",
      "Epoch 1584/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 5.6530 - val_loss: 76.1609\n",
      "Epoch 1585/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9829 - val_loss: 81.1773\n",
      "Epoch 1586/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.9358 - val_loss: 65.2203\n",
      "Epoch 1587/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9353 - val_loss: 71.3116\n",
      "Epoch 1588/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.1851 - val_loss: 66.2329\n",
      "Epoch 1589/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8521 - val_loss: 69.5198\n",
      "Epoch 1590/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6785 - val_loss: 72.5477\n",
      "Epoch 1591/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6003 - val_loss: 77.7400\n",
      "Epoch 1592/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9338 - val_loss: 70.3629\n",
      "Epoch 1593/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.9138 - val_loss: 70.4535\n",
      "Epoch 1594/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.9039 - val_loss: 72.5217\n",
      "Epoch 1595/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.0265 - val_loss: 73.3223\n",
      "Epoch 1596/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7439 - val_loss: 71.4377\n",
      "Epoch 1597/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5716 - val_loss: 63.1507\n",
      "Epoch 1598/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.0604 - val_loss: 71.0713\n",
      "Epoch 1599/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.9101 - val_loss: 67.0124\n",
      "Epoch 1600/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8968 - val_loss: 77.1039\n",
      "Epoch 1601/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.0934 - val_loss: 71.4739\n",
      "Epoch 1602/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5466 - val_loss: 66.1216\n",
      "Epoch 1603/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9888 - val_loss: 68.9180\n",
      "Epoch 1604/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.9770 - val_loss: 80.4442\n",
      "Epoch 1605/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 5.1762 - val_loss: 68.3721\n",
      "Epoch 1606/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8110 - val_loss: 67.3507\n",
      "Epoch 1607/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5718 - val_loss: 71.7252\n",
      "Epoch 1608/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5986 - val_loss: 71.0530\n",
      "Epoch 1609/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.6892 - val_loss: 68.3119\n",
      "Epoch 1610/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5305 - val_loss: 69.0100\n",
      "Epoch 1611/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9312 - val_loss: 70.8971\n",
      "Epoch 1612/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.6751 - val_loss: 69.0814\n",
      "Epoch 1613/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.4985 - val_loss: 70.7990\n",
      "Epoch 1614/5000\n",
      "1063/1063 [==============================] - 0s 125us/step - loss: 4.5877 - val_loss: 69.3287\n",
      "Epoch 1615/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.6091 - val_loss: 68.4941\n",
      "Epoch 1616/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.5854 - val_loss: 69.1763\n",
      "Epoch 1617/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.9234 - val_loss: 68.2886\n",
      "Epoch 1618/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.5716 - val_loss: 68.4447\n",
      "Epoch 1619/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.8839 - val_loss: 70.8047\n",
      "Epoch 1620/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.0375 - val_loss: 80.8867\n",
      "Epoch 1621/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 5.3218 - val_loss: 67.2196\n",
      "Epoch 1622/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 5.3796 - val_loss: 73.4750\n",
      "Epoch 1623/5000\n",
      "1063/1063 [==============================] - 0s 123us/step - loss: 4.7673 - val_loss: 75.1694\n",
      "Epoch 1624/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.9332 - val_loss: 82.4371\n",
      "Epoch 1625/5000\n",
      "1063/1063 [==============================] - 0s 128us/step - loss: 5.2940 - val_loss: 69.4058\n",
      "Epoch 1626/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.7324 - val_loss: 64.0238\n",
      "Epoch 1627/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.8350 - val_loss: 88.0846\n",
      "Epoch 1628/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 5.3116 - val_loss: 68.2884\n",
      "Epoch 1629/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.7345 - val_loss: 77.1379\n",
      "Epoch 1630/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.7570 - val_loss: 69.6440\n",
      "Epoch 1631/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.8465 - val_loss: 64.7545\n",
      "Epoch 1632/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.7680 - val_loss: 74.3892\n",
      "Epoch 1633/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.6059 - val_loss: 76.9433\n",
      "Epoch 1634/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.7833 - val_loss: 70.6437\n",
      "Epoch 1635/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.4430 - val_loss: 71.2402\n",
      "Epoch 1636/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.5990 - val_loss: 69.9858\n",
      "Epoch 1637/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.6879 - val_loss: 71.6589\n",
      "Epoch 1638/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4362 - val_loss: 72.6765\n",
      "Epoch 1639/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.3742 - val_loss: 71.4462\n",
      "Epoch 1640/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.6974 - val_loss: 79.4234\n",
      "Epoch 1641/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 5.0375 - val_loss: 64.8097\n",
      "Epoch 1642/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 6.0797 - val_loss: 70.4572\n",
      "Epoch 1643/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.8447 - val_loss: 77.0820\n",
      "Epoch 1644/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5334 - val_loss: 70.9736\n",
      "Epoch 1645/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.0075 - val_loss: 70.1376\n",
      "Epoch 1646/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5117 - val_loss: 68.8501\n",
      "Epoch 1647/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.9734 - val_loss: 70.1879\n",
      "Epoch 1648/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.1753 - val_loss: 80.2717\n",
      "Epoch 1649/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7735 - val_loss: 73.3750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1650/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7765 - val_loss: 70.4491\n",
      "Epoch 1651/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.7290 - val_loss: 71.8477\n",
      "Epoch 1652/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7544 - val_loss: 74.0157\n",
      "Epoch 1653/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9187 - val_loss: 67.0693\n",
      "Epoch 1654/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5043 - val_loss: 67.6285\n",
      "Epoch 1655/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.6435 - val_loss: 76.6399\n",
      "Epoch 1656/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6502 - val_loss: 77.6555\n",
      "Epoch 1657/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.7365 - val_loss: 68.9290\n",
      "Epoch 1658/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.8018 - val_loss: 74.7443\n",
      "Epoch 1659/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.1906 - val_loss: 70.6509\n",
      "Epoch 1660/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.9656 - val_loss: 75.2616\n",
      "Epoch 1661/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 5.1187 - val_loss: 61.6646\n",
      "Epoch 1662/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.5973 - val_loss: 76.6080\n",
      "Epoch 1663/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.9010 - val_loss: 72.1404\n",
      "Epoch 1664/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.0790 - val_loss: 72.6939\n",
      "Epoch 1665/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.9499 - val_loss: 61.7680\n",
      "Epoch 1666/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.1967 - val_loss: 69.0790\n",
      "Epoch 1667/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 5.0420 - val_loss: 81.6679\n",
      "Epoch 1668/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.7060 - val_loss: 73.2130\n",
      "Epoch 1669/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.9240 - val_loss: 74.6505\n",
      "Epoch 1670/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.4905 - val_loss: 64.7587\n",
      "Epoch 1671/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6339 - val_loss: 78.9563\n",
      "Epoch 1672/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.6873 - val_loss: 74.5871\n",
      "Epoch 1673/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.9977 - val_loss: 67.6876\n",
      "Epoch 1674/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.7193 - val_loss: 71.8312\n",
      "Epoch 1675/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.2603 - val_loss: 66.8177\n",
      "Epoch 1676/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.7953 - val_loss: 79.0907\n",
      "Epoch 1677/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 5.1381 - val_loss: 72.6796\n",
      "Epoch 1678/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.6276 - val_loss: 64.5016\n",
      "Epoch 1679/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.4954 - val_loss: 70.8504\n",
      "Epoch 1680/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.5703 - val_loss: 62.2230\n",
      "Epoch 1681/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9289 - val_loss: 70.5479\n",
      "Epoch 1682/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.6302 - val_loss: 71.1200\n",
      "Epoch 1683/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7753 - val_loss: 81.0672\n",
      "Epoch 1684/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8304 - val_loss: 70.5147\n",
      "Epoch 1685/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8280 - val_loss: 66.7776\n",
      "Epoch 1686/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6531 - val_loss: 77.4686\n",
      "Epoch 1687/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6954 - val_loss: 71.9641\n",
      "Epoch 1688/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4202 - val_loss: 66.8970\n",
      "Epoch 1689/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5826 - val_loss: 66.0342\n",
      "Epoch 1690/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 5.0044 - val_loss: 68.4904\n",
      "Epoch 1691/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.9843 - val_loss: 78.3584\n",
      "Epoch 1692/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5065 - val_loss: 65.4276\n",
      "Epoch 1693/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8086 - val_loss: 72.5024\n",
      "Epoch 1694/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6975 - val_loss: 76.1611\n",
      "Epoch 1695/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6707 - val_loss: 75.7309\n",
      "Epoch 1696/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.8311 - val_loss: 74.4703\n",
      "Epoch 1697/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 5.3483 - val_loss: 68.4165\n",
      "Epoch 1698/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6407 - val_loss: 77.6348\n",
      "Epoch 1699/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6186 - val_loss: 85.9099\n",
      "Epoch 1700/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.9194 - val_loss: 66.8527\n",
      "Epoch 1701/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5977 - val_loss: 79.3959\n",
      "Epoch 1702/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8285 - val_loss: 71.3420\n",
      "Epoch 1703/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5386 - val_loss: 73.2425\n",
      "Epoch 1704/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.9461 - val_loss: 67.1884\n",
      "Epoch 1705/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.9398 - val_loss: 69.8808\n",
      "Epoch 1706/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.8243 - val_loss: 71.8251\n",
      "Epoch 1707/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5961 - val_loss: 72.9409\n",
      "Epoch 1708/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5583 - val_loss: 70.4575\n",
      "Epoch 1709/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.9565 - val_loss: 70.4426\n",
      "Epoch 1710/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.7678 - val_loss: 77.9246\n",
      "Epoch 1711/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.8822 - val_loss: 60.1345\n",
      "Epoch 1712/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.6159 - val_loss: 76.8017\n",
      "Epoch 1713/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.5696 - val_loss: 67.5645\n",
      "Epoch 1714/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.9011 - val_loss: 68.3544\n",
      "Epoch 1715/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.0837 - val_loss: 77.3809\n",
      "Epoch 1716/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.7240 - val_loss: 68.4493\n",
      "Epoch 1717/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5704 - val_loss: 74.1739\n",
      "Epoch 1718/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6561 - val_loss: 64.1855\n",
      "Epoch 1719/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.8586 - val_loss: 74.7914\n",
      "Epoch 1720/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6971 - val_loss: 68.9978\n",
      "Epoch 1721/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7226 - val_loss: 68.7480\n",
      "Epoch 1722/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.9773 - val_loss: 70.5468\n",
      "Epoch 1723/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5148 - val_loss: 69.5460\n",
      "Epoch 1724/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7064 - val_loss: 70.5009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1725/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.8858 - val_loss: 66.0794\n",
      "Epoch 1726/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.3989 - val_loss: 75.3731\n",
      "Epoch 1727/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5930 - val_loss: 68.9044\n",
      "Epoch 1728/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7962 - val_loss: 73.9305\n",
      "Epoch 1729/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.0174 - val_loss: 63.9729\n",
      "Epoch 1730/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 5.1347 - val_loss: 70.3744\n",
      "Epoch 1731/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.8298 - val_loss: 82.5402\n",
      "Epoch 1732/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.9880 - val_loss: 62.4411\n",
      "Epoch 1733/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9339 - val_loss: 76.3698\n",
      "Epoch 1734/5000\n",
      "1063/1063 [==============================] - 0s 120us/step - loss: 4.7232 - val_loss: 68.2604\n",
      "Epoch 1735/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.6703 - val_loss: 68.4760\n",
      "Epoch 1736/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.6471 - val_loss: 70.7954\n",
      "Epoch 1737/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 5.0213 - val_loss: 79.7107\n",
      "Epoch 1738/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 5.0082 - val_loss: 67.1933\n",
      "Epoch 1739/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.2500 - val_loss: 82.8860\n",
      "Epoch 1740/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7801 - val_loss: 77.0186\n",
      "Epoch 1741/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.6928 - val_loss: 74.5098\n",
      "Epoch 1742/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8270 - val_loss: 71.5146\n",
      "Epoch 1743/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.9251 - val_loss: 69.8260\n",
      "Epoch 1744/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.2376 - val_loss: 74.4215\n",
      "Epoch 1745/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6239 - val_loss: 82.7533\n",
      "Epoch 1746/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6630 - val_loss: 67.0206\n",
      "Epoch 1747/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.4285 - val_loss: 70.3880\n",
      "Epoch 1748/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.1529 - val_loss: 79.8400\n",
      "Epoch 1749/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.9770 - val_loss: 75.7943\n",
      "Epoch 1750/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.7521 - val_loss: 69.0971\n",
      "Epoch 1751/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.7857 - val_loss: 77.5606\n",
      "Epoch 1752/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.1227 - val_loss: 73.3715\n",
      "Epoch 1753/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.7941 - val_loss: 74.0025\n",
      "Epoch 1754/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.3274 - val_loss: 53.2447\n",
      "Epoch 1755/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.9674 - val_loss: 65.6399\n",
      "Epoch 1756/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.8825 - val_loss: 67.7888\n",
      "Epoch 1757/5000\n",
      "1063/1063 [==============================] - 0s 117us/step - loss: 4.6927 - val_loss: 68.2617\n",
      "Epoch 1758/5000\n",
      "1063/1063 [==============================] - 0s 132us/step - loss: 4.6959 - val_loss: 70.2424\n",
      "Epoch 1759/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4734 - val_loss: 70.8716\n",
      "Epoch 1760/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.9715 - val_loss: 77.2526\n",
      "Epoch 1761/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.7410 - val_loss: 74.4296\n",
      "Epoch 1762/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.5817 - val_loss: 68.6227\n",
      "Epoch 1763/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.7882 - val_loss: 67.9587\n",
      "Epoch 1764/5000\n",
      "1063/1063 [==============================] - 0s 122us/step - loss: 4.8335 - val_loss: 85.9662\n",
      "Epoch 1765/5000\n",
      "1063/1063 [==============================] - 0s 144us/step - loss: 4.7864 - val_loss: 80.0464\n",
      "Epoch 1766/5000\n",
      "1063/1063 [==============================] - 0s 137us/step - loss: 4.5926 - val_loss: 69.0542\n",
      "Epoch 1767/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 5.0032 - val_loss: 67.9958\n",
      "Epoch 1768/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.7471 - val_loss: 67.5336\n",
      "Epoch 1769/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.3970 - val_loss: 67.9459\n",
      "Epoch 1770/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.9733 - val_loss: 65.4550\n",
      "Epoch 1771/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.8676 - val_loss: 75.8334\n",
      "Epoch 1772/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7036 - val_loss: 63.4929\n",
      "Epoch 1773/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.6943 - val_loss: 77.1083\n",
      "Epoch 1774/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.7377 - val_loss: 69.5718\n",
      "Epoch 1775/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.7490 - val_loss: 71.2732\n",
      "Epoch 1776/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.1216 - val_loss: 66.4346\n",
      "Epoch 1777/5000\n",
      "1063/1063 [==============================] - 0s 156us/step - loss: 5.1905 - val_loss: 74.6052\n",
      "Epoch 1778/5000\n",
      "1063/1063 [==============================] - 0s 132us/step - loss: 5.5073 - val_loss: 75.3730\n",
      "Epoch 1779/5000\n",
      "1063/1063 [==============================] - 0s 166us/step - loss: 5.3268 - val_loss: 66.0277\n",
      "Epoch 1780/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5894 - val_loss: 72.0423\n",
      "Epoch 1781/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.2276 - val_loss: 69.3517\n",
      "Epoch 1782/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.3179 - val_loss: 67.7503\n",
      "Epoch 1783/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6641 - val_loss: 89.4954\n",
      "Epoch 1784/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.3119 - val_loss: 70.5959\n",
      "Epoch 1785/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.8993 - val_loss: 72.6777\n",
      "Epoch 1786/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6389 - val_loss: 77.4137\n",
      "Epoch 1787/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5353 - val_loss: 74.2446\n",
      "Epoch 1788/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.4473 - val_loss: 72.7292\n",
      "Epoch 1789/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4521 - val_loss: 79.0563\n",
      "Epoch 1790/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9408 - val_loss: 74.0532\n",
      "Epoch 1791/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5111 - val_loss: 75.6869\n",
      "Epoch 1792/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8344 - val_loss: 74.8680\n",
      "Epoch 1793/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6824 - val_loss: 76.7356\n",
      "Epoch 1794/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.6299 - val_loss: 65.1457\n",
      "Epoch 1795/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.1158 - val_loss: 83.8517\n",
      "Epoch 1796/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.7768 - val_loss: 78.4924\n",
      "Epoch 1797/5000\n",
      "1063/1063 [==============================] - 0s 120us/step - loss: 4.8486 - val_loss: 74.7783\n",
      "Epoch 1798/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.8213 - val_loss: 84.7265\n",
      "Epoch 1799/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 5.2488 - val_loss: 66.8483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1800/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.7470 - val_loss: 73.9686\n",
      "Epoch 1801/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 4.6819 - val_loss: 80.4782\n",
      "Epoch 1802/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.9372 - val_loss: 72.8520\n",
      "Epoch 1803/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.6298 - val_loss: 70.4967\n",
      "Epoch 1804/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.6511 - val_loss: 72.9366\n",
      "Epoch 1805/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.9432 - val_loss: 72.6956\n",
      "Epoch 1806/5000\n",
      "1063/1063 [==============================] - 0s 125us/step - loss: 5.1927 - val_loss: 66.5275\n",
      "Epoch 1807/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 5.1333 - val_loss: 67.0993\n",
      "Epoch 1808/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.8673 - val_loss: 68.8209\n",
      "Epoch 1809/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5700 - val_loss: 72.3204\n",
      "Epoch 1810/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.3169 - val_loss: 68.3822\n",
      "Epoch 1811/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.2393 - val_loss: 72.0853\n",
      "Epoch 1812/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.9437 - val_loss: 74.5769\n",
      "Epoch 1813/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 5.4966 - val_loss: 81.2652\n",
      "Epoch 1814/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.5541 - val_loss: 64.9517\n",
      "Epoch 1815/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.7893 - val_loss: 64.8912\n",
      "Epoch 1816/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4069 - val_loss: 71.5487\n",
      "Epoch 1817/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8322 - val_loss: 78.4802\n",
      "Epoch 1818/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.7963 - val_loss: 74.7004\n",
      "Epoch 1819/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7105 - val_loss: 71.0183\n",
      "Epoch 1820/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.9289 - val_loss: 74.4380\n",
      "Epoch 1821/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6542 - val_loss: 71.3809\n",
      "Epoch 1822/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.5210 - val_loss: 69.0086\n",
      "Epoch 1823/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8031 - val_loss: 86.3919\n",
      "Epoch 1824/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.8650 - val_loss: 73.7578\n",
      "Epoch 1825/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.1260 - val_loss: 80.0565\n",
      "Epoch 1826/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9411 - val_loss: 73.2574\n",
      "Epoch 1827/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 5.3761 - val_loss: 71.1606\n",
      "Epoch 1828/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5012 - val_loss: 75.9290\n",
      "Epoch 1829/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.1539 - val_loss: 64.1976\n",
      "Epoch 1830/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.1374 - val_loss: 70.0071\n",
      "Epoch 1831/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7279 - val_loss: 73.7985\n",
      "Epoch 1832/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.4562 - val_loss: 82.4712\n",
      "Epoch 1833/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.8241 - val_loss: 78.8486\n",
      "Epoch 1834/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.8120 - val_loss: 76.2659\n",
      "Epoch 1835/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.6673 - val_loss: 64.3492\n",
      "Epoch 1836/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.2372 - val_loss: 72.2333\n",
      "Epoch 1837/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5006 - val_loss: 66.4522\n",
      "Epoch 1838/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6933 - val_loss: 73.2787\n",
      "Epoch 1839/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.3921 - val_loss: 77.3109\n",
      "Epoch 1840/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.7019 - val_loss: 64.4715\n",
      "Epoch 1841/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.2895 - val_loss: 65.3791\n",
      "Epoch 1842/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.4712 - val_loss: 72.6387\n",
      "Epoch 1843/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.8786 - val_loss: 64.5670\n",
      "Epoch 1844/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.8540 - val_loss: 68.2074\n",
      "Epoch 1845/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6977 - val_loss: 70.7757\n",
      "Epoch 1846/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.4969 - val_loss: 64.6083\n",
      "Epoch 1847/5000\n",
      "1063/1063 [==============================] - 0s 123us/step - loss: 4.9588 - val_loss: 80.7173\n",
      "Epoch 1848/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6501 - val_loss: 69.4809\n",
      "Epoch 1849/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.7814 - val_loss: 67.3057\n",
      "Epoch 1850/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7522 - val_loss: 86.9178\n",
      "Epoch 1851/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 5.8996 - val_loss: 75.5896\n",
      "Epoch 1852/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5558 - val_loss: 80.0645\n",
      "Epoch 1853/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8804 - val_loss: 74.4177\n",
      "Epoch 1854/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.8625 - val_loss: 66.2037\n",
      "Epoch 1855/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.6397 - val_loss: 68.5990\n",
      "Epoch 1856/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6517 - val_loss: 66.0777\n",
      "Epoch 1857/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.0806 - val_loss: 68.0262\n",
      "Epoch 1858/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4743 - val_loss: 79.2809\n",
      "Epoch 1859/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6788 - val_loss: 76.7080\n",
      "Epoch 1860/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.8345 - val_loss: 80.2674\n",
      "Epoch 1861/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.0616 - val_loss: 76.3168\n",
      "Epoch 1862/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5515 - val_loss: 80.5931\n",
      "Epoch 1863/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.4103 - val_loss: 75.4526\n",
      "Epoch 1864/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.7724 - val_loss: 69.6702\n",
      "Epoch 1865/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5887 - val_loss: 70.3327\n",
      "Epoch 1866/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.6093 - val_loss: 70.1082\n",
      "Epoch 1867/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.6686 - val_loss: 63.1656\n",
      "Epoch 1868/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7921 - val_loss: 75.2252\n",
      "Epoch 1869/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5927 - val_loss: 66.3757\n",
      "Epoch 1870/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8192 - val_loss: 71.2474\n",
      "Epoch 1871/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.5727 - val_loss: 67.3229\n",
      "Epoch 1872/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.7448 - val_loss: 87.8071\n",
      "Epoch 1873/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.4787 - val_loss: 76.1301\n",
      "Epoch 1874/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 6.7524 - val_loss: 69.3724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1875/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6542 - val_loss: 73.6104\n",
      "Epoch 1876/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9484 - val_loss: 73.2276\n",
      "Epoch 1877/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.2873 - val_loss: 73.1414\n",
      "Epoch 1878/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.9619 - val_loss: 68.3533\n",
      "Epoch 1879/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6813 - val_loss: 69.8196\n",
      "Epoch 1880/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5938 - val_loss: 80.2433\n",
      "Epoch 1881/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.9373 - val_loss: 67.6145\n",
      "Epoch 1882/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6303 - val_loss: 76.3664\n",
      "Epoch 1883/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.7462 - val_loss: 74.4980\n",
      "Epoch 1884/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.6411 - val_loss: 67.6651\n",
      "Epoch 1885/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.7452 - val_loss: 80.0076\n",
      "Epoch 1886/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.7588 - val_loss: 66.4623\n",
      "Epoch 1887/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.9594 - val_loss: 73.3828\n",
      "Epoch 1888/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9050 - val_loss: 81.3920\n",
      "Epoch 1889/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.7687 - val_loss: 73.9383\n",
      "Epoch 1890/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.6232 - val_loss: 73.4502\n",
      "Epoch 1891/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 5.6591 - val_loss: 88.0662\n",
      "Epoch 1892/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 5.8995 - val_loss: 68.2574\n",
      "Epoch 1893/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.5933 - val_loss: 85.0875\n",
      "Epoch 1894/5000\n",
      "1063/1063 [==============================] - 0s 127us/step - loss: 4.9498 - val_loss: 67.7832\n",
      "Epoch 1895/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.5883 - val_loss: 67.1448\n",
      "Epoch 1896/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.9413 - val_loss: 70.1626\n",
      "Epoch 1897/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 4.6520 - val_loss: 72.2744\n",
      "Epoch 1898/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.4440 - val_loss: 68.1683\n",
      "Epoch 1899/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9872 - val_loss: 67.2498\n",
      "Epoch 1900/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.5751 - val_loss: 81.6264\n",
      "Epoch 1901/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.6512 - val_loss: 77.9088\n",
      "Epoch 1902/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8452 - val_loss: 82.4212\n",
      "Epoch 1903/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.0173 - val_loss: 67.9395\n",
      "Epoch 1904/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6405 - val_loss: 63.2436\n",
      "Epoch 1905/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5711 - val_loss: 70.0572\n",
      "Epoch 1906/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.5300 - val_loss: 78.1154\n",
      "Epoch 1907/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.7888 - val_loss: 78.1126\n",
      "Epoch 1908/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5426 - val_loss: 67.1667\n",
      "Epoch 1909/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.8211 - val_loss: 72.9217\n",
      "Epoch 1910/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5967 - val_loss: 69.5536\n",
      "Epoch 1911/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.9977 - val_loss: 65.1665\n",
      "Epoch 1912/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.2805 - val_loss: 71.2478\n",
      "Epoch 1913/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.5357 - val_loss: 88.4518\n",
      "Epoch 1914/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.4188 - val_loss: 70.9314\n",
      "Epoch 1915/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5731 - val_loss: 73.2247\n",
      "Epoch 1916/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.7791 - val_loss: 76.1410\n",
      "Epoch 1917/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.5634 - val_loss: 75.6096\n",
      "Epoch 1918/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.3538 - val_loss: 67.2898\n",
      "Epoch 1919/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.5493 - val_loss: 72.9575\n",
      "Epoch 1920/5000\n",
      "1063/1063 [==============================] - 0s 126us/step - loss: 4.5498 - val_loss: 73.2022\n",
      "Epoch 1921/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.1633 - val_loss: 60.6511\n",
      "Epoch 1922/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.2052 - val_loss: 73.8669\n",
      "Epoch 1923/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.6654 - val_loss: 68.1306\n",
      "Epoch 1924/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.6652 - val_loss: 67.4715\n",
      "Epoch 1925/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.4519 - val_loss: 70.6607\n",
      "Epoch 1926/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.5134 - val_loss: 67.1222\n",
      "Epoch 1927/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.1463 - val_loss: 77.4395\n",
      "Epoch 1928/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.7948 - val_loss: 70.9581\n",
      "Epoch 1929/5000\n",
      "1063/1063 [==============================] - 0s 125us/step - loss: 4.5242 - val_loss: 69.2741\n",
      "Epoch 1930/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.8186 - val_loss: 71.2410\n",
      "Epoch 1931/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.0217 - val_loss: 66.2838\n",
      "Epoch 1932/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 6.4418 - val_loss: 72.7015\n",
      "Epoch 1933/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.0938 - val_loss: 76.7781\n",
      "Epoch 1934/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4924 - val_loss: 71.4321\n",
      "Epoch 1935/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.6088 - val_loss: 69.0022\n",
      "Epoch 1936/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.8478 - val_loss: 70.4890\n",
      "Epoch 1937/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4713 - val_loss: 73.2785\n",
      "Epoch 1938/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.4956 - val_loss: 73.8339\n",
      "Epoch 1939/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.4982 - val_loss: 67.8416\n",
      "Epoch 1940/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.6259 - val_loss: 69.6181\n",
      "Epoch 1941/5000\n",
      "1063/1063 [==============================] - 0s 145us/step - loss: 4.7362 - val_loss: 72.7509\n",
      "Epoch 1942/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.5527 - val_loss: 65.1224\n",
      "Epoch 1943/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6956 - val_loss: 69.9224\n",
      "Epoch 1944/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6017 - val_loss: 79.7457\n",
      "Epoch 1945/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4930 - val_loss: 69.7586\n",
      "Epoch 1946/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5051 - val_loss: 61.5053\n",
      "Epoch 1947/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.8371 - val_loss: 70.5567\n",
      "Epoch 1948/5000\n",
      "1063/1063 [==============================] - 0s 117us/step - loss: 4.9457 - val_loss: 69.3117\n",
      "Epoch 1949/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5814 - val_loss: 64.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1950/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.3370 - val_loss: 74.4174\n",
      "Epoch 1951/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6310 - val_loss: 67.4847\n",
      "Epoch 1952/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.1257 - val_loss: 68.2819\n",
      "Epoch 1953/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.8050 - val_loss: 75.7077\n",
      "Epoch 1954/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7833 - val_loss: 73.8314\n",
      "Epoch 1955/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.8046 - val_loss: 64.5278\n",
      "Epoch 1956/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.8182 - val_loss: 79.9275\n",
      "Epoch 1957/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6559 - val_loss: 67.8387\n",
      "Epoch 1958/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.7129 - val_loss: 67.9394\n",
      "Epoch 1959/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3340 - val_loss: 69.6037\n",
      "Epoch 1960/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5488 - val_loss: 74.2888\n",
      "Epoch 1961/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5923 - val_loss: 73.3735\n",
      "Epoch 1962/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4297 - val_loss: 73.3535\n",
      "Epoch 1963/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6221 - val_loss: 62.9909\n",
      "Epoch 1964/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6704 - val_loss: 67.5469\n",
      "Epoch 1965/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.8172 - val_loss: 70.7424\n",
      "Epoch 1966/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4949 - val_loss: 66.2279\n",
      "Epoch 1967/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7839 - val_loss: 70.1553\n",
      "Epoch 1968/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6886 - val_loss: 77.8493\n",
      "Epoch 1969/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7542 - val_loss: 71.3391\n",
      "Epoch 1970/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4597 - val_loss: 64.3799\n",
      "Epoch 1971/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8653 - val_loss: 66.9728\n",
      "Epoch 1972/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.8361 - val_loss: 73.6689\n",
      "Epoch 1973/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.3001 - val_loss: 66.9297\n",
      "Epoch 1974/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.2954 - val_loss: 83.6143\n",
      "Epoch 1975/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9331 - val_loss: 69.7658\n",
      "Epoch 1976/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 5.1455 - val_loss: 79.7468\n",
      "Epoch 1977/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.1552 - val_loss: 69.4379\n",
      "Epoch 1978/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6196 - val_loss: 71.1124\n",
      "Epoch 1979/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.6810 - val_loss: 64.5662\n",
      "Epoch 1980/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.9373 - val_loss: 79.5748\n",
      "Epoch 1981/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.8890 - val_loss: 73.1328\n",
      "Epoch 1982/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.9321 - val_loss: 74.6973\n",
      "Epoch 1983/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.8663 - val_loss: 71.2110\n",
      "Epoch 1984/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.7021 - val_loss: 68.4714\n",
      "Epoch 1985/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8516 - val_loss: 70.8372\n",
      "Epoch 1986/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5592 - val_loss: 69.0547\n",
      "Epoch 1987/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.9156 - val_loss: 71.8708\n",
      "Epoch 1988/5000\n",
      "1063/1063 [==============================] - 0s 124us/step - loss: 4.7685 - val_loss: 76.0255\n",
      "Epoch 1989/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.0017 - val_loss: 67.7278\n",
      "Epoch 1990/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5599 - val_loss: 74.4278\n",
      "Epoch 1991/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5631 - val_loss: 72.4427\n",
      "Epoch 1992/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5946 - val_loss: 74.9652\n",
      "Epoch 1993/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.5966 - val_loss: 73.1092\n",
      "Epoch 1994/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4653 - val_loss: 64.8226\n",
      "Epoch 1995/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5551 - val_loss: 63.1967\n",
      "Epoch 1996/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.2710 - val_loss: 78.8504\n",
      "Epoch 1997/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7549 - val_loss: 63.5919\n",
      "Epoch 1998/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.9174 - val_loss: 69.4650\n",
      "Epoch 1999/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.2031 - val_loss: 66.7461\n",
      "Epoch 2000/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7235 - val_loss: 71.0581\n",
      "Epoch 2001/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.1807 - val_loss: 66.4344\n",
      "Epoch 2002/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9200 - val_loss: 65.2203\n",
      "Epoch 2003/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.1428 - val_loss: 71.5162\n",
      "Epoch 2004/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4997 - val_loss: 77.9221\n",
      "Epoch 2005/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.3853 - val_loss: 65.5475\n",
      "Epoch 2006/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5377 - val_loss: 68.4976\n",
      "Epoch 2007/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.8213 - val_loss: 65.0669\n",
      "Epoch 2008/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5327 - val_loss: 77.0090\n",
      "Epoch 2009/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.4706 - val_loss: 71.3749\n",
      "Epoch 2010/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.7463 - val_loss: 72.4999\n",
      "Epoch 2011/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.7658 - val_loss: 74.1926\n",
      "Epoch 2012/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6325 - val_loss: 74.1361\n",
      "Epoch 2013/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5527 - val_loss: 68.8342\n",
      "Epoch 2014/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5508 - val_loss: 68.4172\n",
      "Epoch 2015/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 5.2662 - val_loss: 72.2400\n",
      "Epoch 2016/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 5.0011 - val_loss: 74.5621\n",
      "Epoch 2017/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.8471 - val_loss: 76.3336\n",
      "Epoch 2018/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6425 - val_loss: 67.8916\n",
      "Epoch 2019/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.6236 - val_loss: 67.5260\n",
      "Epoch 2020/5000\n",
      "1063/1063 [==============================] - 0s 86us/step - loss: 4.6828 - val_loss: 71.2816\n",
      "Epoch 2021/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.6118 - val_loss: 76.1585\n",
      "Epoch 2022/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 5.1177 - val_loss: 80.9683\n",
      "Epoch 2023/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4787 - val_loss: 80.0825\n",
      "Epoch 2024/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 5.4351 - val_loss: 77.7056\n",
      "Epoch 2025/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.8752 - val_loss: 71.8646\n",
      "Epoch 2026/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.7237 - val_loss: 67.8927\n",
      "Epoch 2027/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 5.5905 - val_loss: 76.4230\n",
      "Epoch 2028/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.7717 - val_loss: 70.3903\n",
      "Epoch 2029/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.6609 - val_loss: 68.2217\n",
      "Epoch 2030/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5413 - val_loss: 68.0033\n",
      "Epoch 2031/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4851 - val_loss: 70.6385\n",
      "Epoch 2032/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.6125 - val_loss: 71.1748\n",
      "Epoch 2033/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5088 - val_loss: 68.7198\n",
      "Epoch 2034/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5074 - val_loss: 72.0800\n",
      "Epoch 2035/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5839 - val_loss: 70.8310\n",
      "Epoch 2036/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.8365 - val_loss: 77.3042\n",
      "Epoch 2037/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4563 - val_loss: 74.1634\n",
      "Epoch 2038/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5607 - val_loss: 72.9450\n",
      "Epoch 2039/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.4321 - val_loss: 73.2588\n",
      "Epoch 2040/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 5.2948 - val_loss: 67.2420\n",
      "Epoch 2041/5000\n",
      "1063/1063 [==============================] - 0s 117us/step - loss: 4.9325 - val_loss: 80.0760\n",
      "Epoch 2042/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.1342 - val_loss: 83.6515\n",
      "Epoch 2043/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.0407 - val_loss: 71.0073\n",
      "Epoch 2044/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.9603 - val_loss: 69.8530\n",
      "Epoch 2045/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6978 - val_loss: 68.5346\n",
      "Epoch 2046/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8262 - val_loss: 70.4000\n",
      "Epoch 2047/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6596 - val_loss: 76.6590\n",
      "Epoch 2048/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6593 - val_loss: 75.5603\n",
      "Epoch 2049/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5575 - val_loss: 67.8811\n",
      "Epoch 2050/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.4817 - val_loss: 64.8971\n",
      "Epoch 2051/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.4165 - val_loss: 70.9971\n",
      "Epoch 2052/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5503 - val_loss: 73.4303\n",
      "Epoch 2053/5000\n",
      "1063/1063 [==============================] - 0s 120us/step - loss: 4.7026 - val_loss: 68.3492\n",
      "Epoch 2054/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.9992 - val_loss: 70.4630\n",
      "Epoch 2055/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4190 - val_loss: 68.2601\n",
      "Epoch 2056/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5009 - val_loss: 80.0233\n",
      "Epoch 2057/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5179 - val_loss: 67.9141\n",
      "Epoch 2058/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6547 - val_loss: 88.2658\n",
      "Epoch 2059/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 5.4873 - val_loss: 69.6211\n",
      "Epoch 2060/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.6063 - val_loss: 67.1936\n",
      "Epoch 2061/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.7443 - val_loss: 74.4419\n",
      "Epoch 2062/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.5125 - val_loss: 71.8163\n",
      "Epoch 2063/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.4735 - val_loss: 75.2615\n",
      "Epoch 2064/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.4789 - val_loss: 69.9146\n",
      "Epoch 2065/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6642 - val_loss: 70.7189\n",
      "Epoch 2066/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.8090 - val_loss: 71.6174\n",
      "Epoch 2067/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6928 - val_loss: 64.3148\n",
      "Epoch 2068/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 5.0616 - val_loss: 77.7446\n",
      "Epoch 2069/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.9730 - val_loss: 70.6171\n",
      "Epoch 2070/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4370 - val_loss: 67.3634\n",
      "Epoch 2071/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.3949 - val_loss: 76.5397\n",
      "Epoch 2072/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6419 - val_loss: 76.6689\n",
      "Epoch 2073/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.9462 - val_loss: 67.2103\n",
      "Epoch 2074/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.7772 - val_loss: 79.3651\n",
      "Epoch 2075/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.8753 - val_loss: 73.4973\n",
      "Epoch 2076/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.3649 - val_loss: 67.2632\n",
      "Epoch 2077/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.6001 - val_loss: 62.9624\n",
      "Epoch 2078/5000\n",
      "1063/1063 [==============================] - 0s 125us/step - loss: 5.0481 - val_loss: 69.1056\n",
      "Epoch 2079/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 4.8512 - val_loss: 71.6031\n",
      "Epoch 2080/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 5.0234 - val_loss: 74.3978\n",
      "Epoch 2081/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8378 - val_loss: 80.4829\n",
      "Epoch 2082/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4974 - val_loss: 68.4203\n",
      "Epoch 2083/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.7425 - val_loss: 67.4520\n",
      "Epoch 2084/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6091 - val_loss: 71.2261\n",
      "Epoch 2085/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.0847 - val_loss: 73.1141\n",
      "Epoch 2086/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 5.4209 - val_loss: 66.0282\n",
      "Epoch 2087/5000\n",
      "1063/1063 [==============================] - 0s 123us/step - loss: 4.7138 - val_loss: 68.0747\n",
      "Epoch 2088/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.5899 - val_loss: 70.4696\n",
      "Epoch 2089/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4846 - val_loss: 76.9323\n",
      "Epoch 2090/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5387 - val_loss: 71.8844\n",
      "Epoch 2091/5000\n",
      "1063/1063 [==============================] - 0s 121us/step - loss: 4.6418 - val_loss: 71.2683\n",
      "Epoch 2092/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.4873 - val_loss: 74.8804\n",
      "Epoch 2093/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.7584 - val_loss: 68.8205\n",
      "Epoch 2094/5000\n",
      "1063/1063 [==============================] - 0s 119us/step - loss: 5.2420 - val_loss: 64.5882\n",
      "Epoch 2095/5000\n",
      "1063/1063 [==============================] - 0s 120us/step - loss: 4.6746 - val_loss: 70.7821\n",
      "Epoch 2096/5000\n",
      "1063/1063 [==============================] - 0s 124us/step - loss: 4.4375 - val_loss: 82.9020\n",
      "Epoch 2097/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.2711 - val_loss: 71.6654\n",
      "Epoch 2098/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.0928 - val_loss: 69.2578\n",
      "Epoch 2099/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.6001 - val_loss: 69.4276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2100/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.4673 - val_loss: 69.9843\n",
      "Epoch 2101/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.0436 - val_loss: 75.9534\n",
      "Epoch 2102/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5377 - val_loss: 69.8590\n",
      "Epoch 2103/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4424 - val_loss: 65.3938\n",
      "Epoch 2104/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.8638 - val_loss: 70.2587\n",
      "Epoch 2105/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.5242 - val_loss: 75.9605\n",
      "Epoch 2106/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.3802 - val_loss: 68.5935\n",
      "Epoch 2107/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.1740 - val_loss: 70.8665\n",
      "Epoch 2108/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.7278 - val_loss: 76.4556\n",
      "Epoch 2109/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.6663 - val_loss: 66.8612\n",
      "Epoch 2110/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.8550 - val_loss: 78.4494\n",
      "Epoch 2111/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.0971 - val_loss: 81.4707\n",
      "Epoch 2112/5000\n",
      "1063/1063 [==============================] - 0s 145us/step - loss: 5.0442 - val_loss: 71.3366\n",
      "Epoch 2113/5000\n",
      "1063/1063 [==============================] - 0s 156us/step - loss: 4.5990 - val_loss: 70.0198\n",
      "Epoch 2114/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.8683 - val_loss: 72.8365\n",
      "Epoch 2115/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3062 - val_loss: 66.1214\n",
      "Epoch 2116/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5099 - val_loss: 83.3766\n",
      "Epoch 2117/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.0917 - val_loss: 67.3459\n",
      "Epoch 2118/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5110 - val_loss: 68.6929\n",
      "Epoch 2119/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4004 - val_loss: 81.2597\n",
      "Epoch 2120/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8998 - val_loss: 79.4667\n",
      "Epoch 2121/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7435 - val_loss: 69.8572\n",
      "Epoch 2122/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6114 - val_loss: 76.3655\n",
      "Epoch 2123/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.7556 - val_loss: 71.9691\n",
      "Epoch 2124/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.6299 - val_loss: 63.2469\n",
      "Epoch 2125/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.9796 - val_loss: 67.1941\n",
      "Epoch 2126/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5331 - val_loss: 67.2127\n",
      "Epoch 2127/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 5.2917 - val_loss: 68.5817\n",
      "Epoch 2128/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5702 - val_loss: 73.5062\n",
      "Epoch 2129/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.7285 - val_loss: 75.6399\n",
      "Epoch 2130/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.2432 - val_loss: 76.8347\n",
      "Epoch 2131/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.7369 - val_loss: 74.3106\n",
      "Epoch 2132/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7115 - val_loss: 73.1001\n",
      "Epoch 2133/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.4689 - val_loss: 72.8170\n",
      "Epoch 2134/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5055 - val_loss: 69.0708\n",
      "Epoch 2135/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5001 - val_loss: 68.1295\n",
      "Epoch 2136/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4224 - val_loss: 75.5612\n",
      "Epoch 2137/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4298 - val_loss: 71.7509\n",
      "Epoch 2138/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.6561 - val_loss: 73.1299\n",
      "Epoch 2139/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.8870 - val_loss: 67.5516\n",
      "Epoch 2140/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.7629 - val_loss: 74.1106\n",
      "Epoch 2141/5000\n",
      "1063/1063 [==============================] - 0s 124us/step - loss: 4.9383 - val_loss: 76.8700\n",
      "Epoch 2142/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.7435 - val_loss: 74.5928\n",
      "Epoch 2143/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.5728 - val_loss: 73.5825\n",
      "Epoch 2144/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.5743 - val_loss: 68.1231\n",
      "Epoch 2145/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.6093 - val_loss: 69.4135\n",
      "Epoch 2146/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7001 - val_loss: 74.9641\n",
      "Epoch 2147/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.1048 - val_loss: 66.0092\n",
      "Epoch 2148/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.9533 - val_loss: 75.5243\n",
      "Epoch 2149/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.6277 - val_loss: 75.4037\n",
      "Epoch 2150/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.7285 - val_loss: 73.6036\n",
      "Epoch 2151/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5393 - val_loss: 64.1588\n",
      "Epoch 2152/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6527 - val_loss: 67.8774\n",
      "Epoch 2153/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.8812 - val_loss: 70.2123\n",
      "Epoch 2154/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4401 - val_loss: 70.1547\n",
      "Epoch 2155/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6179 - val_loss: 68.1241\n",
      "Epoch 2156/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.2064 - val_loss: 69.7193\n",
      "Epoch 2157/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.9124 - val_loss: 78.1073\n",
      "Epoch 2158/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6165 - val_loss: 68.4735\n",
      "Epoch 2159/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4027 - val_loss: 79.7049\n",
      "Epoch 2160/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.9753 - val_loss: 73.0779\n",
      "Epoch 2161/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5915 - val_loss: 69.7864\n",
      "Epoch 2162/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.4406 - val_loss: 76.9472\n",
      "Epoch 2163/5000\n",
      "1063/1063 [==============================] - 0s 123us/step - loss: 4.8134 - val_loss: 70.9179\n",
      "Epoch 2164/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.8488 - val_loss: 80.9618\n",
      "Epoch 2165/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.0839 - val_loss: 66.3557\n",
      "Epoch 2166/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7964 - val_loss: 72.3822\n",
      "Epoch 2167/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6260 - val_loss: 67.6518\n",
      "Epoch 2168/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5079 - val_loss: 63.5324\n",
      "Epoch 2169/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.7589 - val_loss: 75.1040\n",
      "Epoch 2170/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.6964 - val_loss: 76.6864\n",
      "Epoch 2171/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6816 - val_loss: 73.4330\n",
      "Epoch 2172/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.3790 - val_loss: 73.7268\n",
      "Epoch 2173/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.7698 - val_loss: 75.9927\n",
      "Epoch 2174/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.0131 - val_loss: 80.1995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2175/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.6481 - val_loss: 69.7509\n",
      "Epoch 2176/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5841 - val_loss: 72.9241\n",
      "Epoch 2177/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.6390 - val_loss: 77.7010\n",
      "Epoch 2178/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.5172 - val_loss: 65.9137\n",
      "Epoch 2179/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.6620 - val_loss: 74.2555\n",
      "Epoch 2180/5000\n",
      "1063/1063 [==============================] - ETA: 0s - loss: 4.500 - 0s 109us/step - loss: 4.4955 - val_loss: 77.9775\n",
      "Epoch 2181/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.7948 - val_loss: 73.5066\n",
      "Epoch 2182/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.5122 - val_loss: 74.4700\n",
      "Epoch 2183/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6886 - val_loss: 69.2499\n",
      "Epoch 2184/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.3535 - val_loss: 73.7494\n",
      "Epoch 2185/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.2647 - val_loss: 76.0889\n",
      "Epoch 2186/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4515 - val_loss: 79.5829\n",
      "Epoch 2187/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5334 - val_loss: 67.3772\n",
      "Epoch 2188/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.7137 - val_loss: 63.9507\n",
      "Epoch 2189/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.6652 - val_loss: 71.0742\n",
      "Epoch 2190/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6991 - val_loss: 71.1290\n",
      "Epoch 2191/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3728 - val_loss: 74.5292\n",
      "Epoch 2192/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.6888 - val_loss: 71.2303\n",
      "Epoch 2193/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4624 - val_loss: 66.7421\n",
      "Epoch 2194/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.8317 - val_loss: 70.1112\n",
      "Epoch 2195/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.2623 - val_loss: 68.9192\n",
      "Epoch 2196/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5104 - val_loss: 69.9152\n",
      "Epoch 2197/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5521 - val_loss: 65.7856\n",
      "Epoch 2198/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.7588 - val_loss: 69.5958\n",
      "Epoch 2199/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4952 - val_loss: 71.9295\n",
      "Epoch 2200/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4497 - val_loss: 75.5672\n",
      "Epoch 2201/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.8244 - val_loss: 70.2678\n",
      "Epoch 2202/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.3491 - val_loss: 71.6846\n",
      "Epoch 2203/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.3923 - val_loss: 75.4874\n",
      "Epoch 2204/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5851 - val_loss: 70.9868\n",
      "Epoch 2205/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.1635 - val_loss: 82.1392\n",
      "Epoch 2206/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 5.0091 - val_loss: 70.6873\n",
      "Epoch 2207/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.9195 - val_loss: 67.4743\n",
      "Epoch 2208/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.2873 - val_loss: 71.4991\n",
      "Epoch 2209/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.7437 - val_loss: 63.4819\n",
      "Epoch 2210/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6668 - val_loss: 71.6084\n",
      "Epoch 2211/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.9551 - val_loss: 71.2824\n",
      "Epoch 2212/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.4339 - val_loss: 72.6261\n",
      "Epoch 2213/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.5212 - val_loss: 72.8146\n",
      "Epoch 2214/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.6215 - val_loss: 76.0988\n",
      "Epoch 2215/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.8490 - val_loss: 73.1425\n",
      "Epoch 2216/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.8436 - val_loss: 63.3016\n",
      "Epoch 2217/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5035 - val_loss: 72.1692\n",
      "Epoch 2218/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.2762 - val_loss: 71.6191\n",
      "Epoch 2219/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.9790 - val_loss: 72.7533\n",
      "Epoch 2220/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.4749 - val_loss: 65.0221\n",
      "Epoch 2221/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 4.6732 - val_loss: 72.5374\n",
      "Epoch 2222/5000\n",
      "1063/1063 [==============================] - 0s 124us/step - loss: 4.9153 - val_loss: 87.5972\n",
      "Epoch 2223/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.4427 - val_loss: 77.1315\n",
      "Epoch 2224/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.7239 - val_loss: 70.1303\n",
      "Epoch 2225/5000\n",
      "1063/1063 [==============================] - 0s 125us/step - loss: 4.7188 - val_loss: 72.4999\n",
      "Epoch 2226/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.6885 - val_loss: 72.7617\n",
      "Epoch 2227/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4752 - val_loss: 86.8341\n",
      "Epoch 2228/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.0072 - val_loss: 65.1126\n",
      "Epoch 2229/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.9164 - val_loss: 74.5520\n",
      "Epoch 2230/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.7179 - val_loss: 80.3077\n",
      "Epoch 2231/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.6349 - val_loss: 72.8077\n",
      "Epoch 2232/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5984 - val_loss: 73.6801\n",
      "Epoch 2233/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.3429 - val_loss: 71.9977\n",
      "Epoch 2234/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8323 - val_loss: 73.7822\n",
      "Epoch 2235/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 5.1999 - val_loss: 73.6103\n",
      "Epoch 2236/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8844 - val_loss: 69.2706\n",
      "Epoch 2237/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5667 - val_loss: 72.1087\n",
      "Epoch 2238/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8038 - val_loss: 66.8024\n",
      "Epoch 2239/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.5318 - val_loss: 72.9798\n",
      "Epoch 2240/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.3425 - val_loss: 66.8450\n",
      "Epoch 2241/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.4028 - val_loss: 67.9477\n",
      "Epoch 2242/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8475 - val_loss: 74.7072\n",
      "Epoch 2243/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4416 - val_loss: 70.0780\n",
      "Epoch 2244/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.4283 - val_loss: 78.6721\n",
      "Epoch 2245/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7859 - val_loss: 74.2388\n",
      "Epoch 2246/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.1137 - val_loss: 66.4000\n",
      "Epoch 2247/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5005 - val_loss: 68.9366\n",
      "Epoch 2248/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9707 - val_loss: 69.0675\n",
      "Epoch 2249/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9728 - val_loss: 62.8492\n",
      "Epoch 2250/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.0891 - val_loss: 68.4608\n",
      "Epoch 2251/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.6107 - val_loss: 82.1094\n",
      "Epoch 2252/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.7276 - val_loss: 72.2602\n",
      "Epoch 2253/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3759 - val_loss: 69.4148\n",
      "Epoch 2254/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.3331 - val_loss: 74.4056\n",
      "Epoch 2255/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5889 - val_loss: 66.0199\n",
      "Epoch 2256/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.7017 - val_loss: 79.2097\n",
      "Epoch 2257/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5980 - val_loss: 81.4798\n",
      "Epoch 2258/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5833 - val_loss: 75.7499\n",
      "Epoch 2259/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4815 - val_loss: 66.0490\n",
      "Epoch 2260/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.8466 - val_loss: 68.0425\n",
      "Epoch 2261/5000\n",
      "1063/1063 [==============================] - 0s 137us/step - loss: 4.9946 - val_loss: 76.5206\n",
      "Epoch 2262/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.7095 - val_loss: 74.5087\n",
      "Epoch 2263/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.6988 - val_loss: 84.9574\n",
      "Epoch 2264/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.0713 - val_loss: 66.9016\n",
      "Epoch 2265/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.9156 - val_loss: 71.9768\n",
      "Epoch 2266/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.2081 - val_loss: 73.2977\n",
      "Epoch 2267/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6612 - val_loss: 80.6690\n",
      "Epoch 2268/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 6.1763 - val_loss: 74.2054\n",
      "Epoch 2269/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8122 - val_loss: 62.8547\n",
      "Epoch 2270/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.8133 - val_loss: 66.6645\n",
      "Epoch 2271/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.0126 - val_loss: 72.1900\n",
      "Epoch 2272/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6340 - val_loss: 76.8850\n",
      "Epoch 2273/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5519 - val_loss: 65.9807\n",
      "Epoch 2274/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.3694 - val_loss: 77.6280\n",
      "Epoch 2275/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.6239 - val_loss: 69.9038\n",
      "Epoch 2276/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.8709 - val_loss: 68.0580\n",
      "Epoch 2277/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.8436 - val_loss: 67.7179\n",
      "Epoch 2278/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6612 - val_loss: 62.8702\n",
      "Epoch 2279/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7760 - val_loss: 70.6278\n",
      "Epoch 2280/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.4413 - val_loss: 73.6182\n",
      "Epoch 2281/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3545 - val_loss: 75.8298\n",
      "Epoch 2282/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.0100 - val_loss: 78.3723\n",
      "Epoch 2283/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.7112 - val_loss: 76.1596\n",
      "Epoch 2284/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.6267 - val_loss: 71.8775\n",
      "Epoch 2285/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4678 - val_loss: 68.0699\n",
      "Epoch 2286/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4926 - val_loss: 88.2246\n",
      "Epoch 2287/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.1199 - val_loss: 74.8851\n",
      "Epoch 2288/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8471 - val_loss: 72.4429\n",
      "Epoch 2289/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7222 - val_loss: 69.8029\n",
      "Epoch 2290/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.3872 - val_loss: 76.9457\n",
      "Epoch 2291/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5423 - val_loss: 70.3618\n",
      "Epoch 2292/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5608 - val_loss: 75.2324\n",
      "Epoch 2293/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6359 - val_loss: 74.5148\n",
      "Epoch 2294/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.6623 - val_loss: 68.9716\n",
      "Epoch 2295/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.3697 - val_loss: 76.0824\n",
      "Epoch 2296/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.6417 - val_loss: 72.3952\n",
      "Epoch 2297/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6089 - val_loss: 76.2897\n",
      "Epoch 2298/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4924 - val_loss: 64.0409\n",
      "Epoch 2299/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 5.0100 - val_loss: 69.5864\n",
      "Epoch 2300/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5542 - val_loss: 70.8418\n",
      "Epoch 2301/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4210 - val_loss: 78.4447\n",
      "Epoch 2302/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4141 - val_loss: 72.5835\n",
      "Epoch 2303/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.2271 - val_loss: 65.1967\n",
      "Epoch 2304/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5312 - val_loss: 70.0676\n",
      "Epoch 2305/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4369 - val_loss: 73.6961\n",
      "Epoch 2306/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4451 - val_loss: 70.8164\n",
      "Epoch 2307/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8455 - val_loss: 72.0092\n",
      "Epoch 2308/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5867 - val_loss: 71.8947\n",
      "Epoch 2309/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5034 - val_loss: 77.8778\n",
      "Epoch 2310/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7489 - val_loss: 71.8771\n",
      "Epoch 2311/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 5.0502 - val_loss: 71.4407\n",
      "Epoch 2312/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.2898 - val_loss: 72.6197\n",
      "Epoch 2313/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.8720 - val_loss: 83.1460\n",
      "Epoch 2314/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5739 - val_loss: 67.9524\n",
      "Epoch 2315/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4759 - val_loss: 71.4626\n",
      "Epoch 2316/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4666 - val_loss: 74.8110\n",
      "Epoch 2317/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6178 - val_loss: 67.0185\n",
      "Epoch 2318/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.2828 - val_loss: 76.3536\n",
      "Epoch 2319/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.4992 - val_loss: 82.9208\n",
      "Epoch 2320/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5805 - val_loss: 80.3872\n",
      "Epoch 2321/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6086 - val_loss: 79.3193\n",
      "Epoch 2322/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5723 - val_loss: 68.9214\n",
      "Epoch 2323/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7977 - val_loss: 75.3413\n",
      "Epoch 2324/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7706 - val_loss: 77.2851\n",
      "Epoch 2325/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5293 - val_loss: 75.0996\n",
      "Epoch 2326/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7414 - val_loss: 72.7517\n",
      "Epoch 2327/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8592 - val_loss: 62.8808\n",
      "Epoch 2328/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.1615 - val_loss: 70.0753\n",
      "Epoch 2329/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6937 - val_loss: 72.7702\n",
      "Epoch 2330/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5924 - val_loss: 71.3610\n",
      "Epoch 2331/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.8155 - val_loss: 65.2263\n",
      "Epoch 2332/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.0033 - val_loss: 66.2039\n",
      "Epoch 2333/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.2938 - val_loss: 65.7350\n",
      "Epoch 2334/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5683 - val_loss: 68.2511\n",
      "Epoch 2335/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.7540 - val_loss: 69.8440\n",
      "Epoch 2336/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6810 - val_loss: 70.3382\n",
      "Epoch 2337/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7393 - val_loss: 70.8120\n",
      "Epoch 2338/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.8381 - val_loss: 64.5418\n",
      "Epoch 2339/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6127 - val_loss: 73.4663\n",
      "Epoch 2340/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.9689 - val_loss: 70.1186\n",
      "Epoch 2341/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.4414 - val_loss: 70.2880\n",
      "Epoch 2342/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4968 - val_loss: 81.1899\n",
      "Epoch 2343/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.4661 - val_loss: 71.5931\n",
      "Epoch 2344/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.6091 - val_loss: 71.7173\n",
      "Epoch 2345/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.9848 - val_loss: 73.5686\n",
      "Epoch 2346/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3179 - val_loss: 76.4230\n",
      "Epoch 2347/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9260 - val_loss: 72.6968\n",
      "Epoch 2348/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6306 - val_loss: 72.3993\n",
      "Epoch 2349/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7775 - val_loss: 67.2041\n",
      "Epoch 2350/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8644 - val_loss: 66.2074\n",
      "Epoch 2351/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.9318 - val_loss: 65.7569\n",
      "Epoch 2352/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.6631 - val_loss: 69.6420\n",
      "Epoch 2353/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3436 - val_loss: 75.1984\n",
      "Epoch 2354/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6555 - val_loss: 74.3584\n",
      "Epoch 2355/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.7752 - val_loss: 68.7551\n",
      "Epoch 2356/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.4563 - val_loss: 68.1504\n",
      "Epoch 2357/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4785 - val_loss: 74.9436\n",
      "Epoch 2358/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.3974 - val_loss: 70.0390\n",
      "Epoch 2359/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 4.4555 - val_loss: 67.3424\n",
      "Epoch 2360/5000\n",
      "1063/1063 [==============================] - 0s 137us/step - loss: 4.8764 - val_loss: 75.9643\n",
      "Epoch 2361/5000\n",
      "1063/1063 [==============================] - 0s 119us/step - loss: 4.5088 - val_loss: 79.4630\n",
      "Epoch 2362/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.4876 - val_loss: 71.0955\n",
      "Epoch 2363/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.7004 - val_loss: 62.8527\n",
      "Epoch 2364/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.8761 - val_loss: 70.2630\n",
      "Epoch 2365/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 5.3032 - val_loss: 79.7020\n",
      "Epoch 2366/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.5813 - val_loss: 63.9389\n",
      "Epoch 2367/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4337 - val_loss: 61.9541\n",
      "Epoch 2368/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 6.3553 - val_loss: 72.4824\n",
      "Epoch 2369/5000\n",
      "1063/1063 [==============================] - 0s 119us/step - loss: 5.2897 - val_loss: 69.4231\n",
      "Epoch 2370/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.7539 - val_loss: 75.7040\n",
      "Epoch 2371/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.9335 - val_loss: 83.4725\n",
      "Epoch 2372/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.7290 - val_loss: 76.5368\n",
      "Epoch 2373/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.4437 - val_loss: 73.3681\n",
      "Epoch 2374/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.6955 - val_loss: 67.9654\n",
      "Epoch 2375/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.5668 - val_loss: 70.7099\n",
      "Epoch 2376/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.5171 - val_loss: 68.4628\n",
      "Epoch 2377/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.3830 - val_loss: 78.2995\n",
      "Epoch 2378/5000\n",
      "1063/1063 [==============================] - 0s 126us/step - loss: 5.0120 - val_loss: 70.1511\n",
      "Epoch 2379/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.5008 - val_loss: 80.7978\n",
      "Epoch 2380/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 5.2410 - val_loss: 72.7557\n",
      "Epoch 2381/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 5.1108 - val_loss: 76.4842\n",
      "Epoch 2382/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.5664 - val_loss: 81.6509\n",
      "Epoch 2383/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 5.0786 - val_loss: 65.7571\n",
      "Epoch 2384/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 5.1709 - val_loss: 68.6796\n",
      "Epoch 2385/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.7848 - val_loss: 61.5798\n",
      "Epoch 2386/5000\n",
      "1063/1063 [==============================] - 0s 135us/step - loss: 5.1191 - val_loss: 67.9941\n",
      "Epoch 2387/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.8225 - val_loss: 71.9470\n",
      "Epoch 2388/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 4.4469 - val_loss: 71.6279\n",
      "Epoch 2389/5000\n",
      "1063/1063 [==============================] - 0s 132us/step - loss: 4.6101 - val_loss: 71.4903\n",
      "Epoch 2390/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.6259 - val_loss: 81.6884\n",
      "Epoch 2391/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.5111 - val_loss: 68.9978\n",
      "Epoch 2392/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.0202 - val_loss: 64.6473\n",
      "Epoch 2393/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.2663 - val_loss: 74.8782\n",
      "Epoch 2394/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.7389 - val_loss: 73.0107\n",
      "Epoch 2395/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.6114 - val_loss: 72.9232\n",
      "Epoch 2396/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5094 - val_loss: 73.7199\n",
      "Epoch 2397/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5208 - val_loss: 73.7388\n",
      "Epoch 2398/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4785 - val_loss: 72.3792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2399/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6399 - val_loss: 72.7186\n",
      "Epoch 2400/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9151 - val_loss: 71.9061\n",
      "Epoch 2401/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7424 - val_loss: 73.5647\n",
      "Epoch 2402/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4765 - val_loss: 72.3674\n",
      "Epoch 2403/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5714 - val_loss: 75.9642\n",
      "Epoch 2404/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.7510 - val_loss: 72.4929\n",
      "Epoch 2405/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 4.4831 - val_loss: 82.2752\n",
      "Epoch 2406/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.2567 - val_loss: 75.3457\n",
      "Epoch 2407/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5213 - val_loss: 66.1075\n",
      "Epoch 2408/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.6405 - val_loss: 68.8148\n",
      "Epoch 2409/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.5790 - val_loss: 63.8343\n",
      "Epoch 2410/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.2175 - val_loss: 70.2941\n",
      "Epoch 2411/5000\n",
      "1063/1063 [==============================] - 0s 131us/step - loss: 4.5425 - val_loss: 69.1568\n",
      "Epoch 2412/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.5546 - val_loss: 70.3226\n",
      "Epoch 2413/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.5820 - val_loss: 69.3112\n",
      "Epoch 2414/5000\n",
      "1063/1063 [==============================] - 0s 119us/step - loss: 4.3832 - val_loss: 74.7694\n",
      "Epoch 2415/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.4922 - val_loss: 69.7334\n",
      "Epoch 2416/5000\n",
      "1063/1063 [==============================] - 0s 126us/step - loss: 4.7660 - val_loss: 77.7784\n",
      "Epoch 2417/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.3397 - val_loss: 69.6788\n",
      "Epoch 2418/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.1570 - val_loss: 73.7499\n",
      "Epoch 2419/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6683 - val_loss: 70.3586\n",
      "Epoch 2420/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5173 - val_loss: 69.1067\n",
      "Epoch 2421/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.6147 - val_loss: 73.2483\n",
      "Epoch 2422/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.1401 - val_loss: 71.6050\n",
      "Epoch 2423/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 5.2631 - val_loss: 84.3481\n",
      "Epoch 2424/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.8097 - val_loss: 67.8873\n",
      "Epoch 2425/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4756 - val_loss: 73.0202\n",
      "Epoch 2426/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.9284 - val_loss: 68.2102\n",
      "Epoch 2427/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.1705 - val_loss: 73.4651\n",
      "Epoch 2428/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.7604 - val_loss: 71.0876\n",
      "Epoch 2429/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.9384 - val_loss: 71.3358\n",
      "Epoch 2430/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 5.1304 - val_loss: 74.0836\n",
      "Epoch 2431/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.7307 - val_loss: 73.5626\n",
      "Epoch 2432/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.9224 - val_loss: 71.9441\n",
      "Epoch 2433/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.8143 - val_loss: 67.4424\n",
      "Epoch 2434/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.7357 - val_loss: 74.8923\n",
      "Epoch 2435/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.3049 - val_loss: 75.3480\n",
      "Epoch 2436/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.4961 - val_loss: 77.5999\n",
      "Epoch 2437/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.7005 - val_loss: 78.4795\n",
      "Epoch 2438/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.5124 - val_loss: 67.9244\n",
      "Epoch 2439/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7453 - val_loss: 67.1810\n",
      "Epoch 2440/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.7240 - val_loss: 74.9473\n",
      "Epoch 2441/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6372 - val_loss: 67.8569\n",
      "Epoch 2442/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.2312 - val_loss: 75.1656\n",
      "Epoch 2443/5000\n",
      "1063/1063 [==============================] - 0s 143us/step - loss: 4.5922 - val_loss: 69.0106\n",
      "Epoch 2444/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.4718 - val_loss: 67.3058\n",
      "Epoch 2445/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.7858 - val_loss: 69.5364\n",
      "Epoch 2446/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6568 - val_loss: 84.9956\n",
      "Epoch 2447/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.9506 - val_loss: 71.1033\n",
      "Epoch 2448/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.3667 - val_loss: 75.5308\n",
      "Epoch 2449/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7665 - val_loss: 72.6148\n",
      "Epoch 2450/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.1882 - val_loss: 69.5931\n",
      "Epoch 2451/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5924 - val_loss: 69.8524\n",
      "Epoch 2452/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 4.7617 - val_loss: 67.9923\n",
      "Epoch 2453/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.5765 - val_loss: 68.7173\n",
      "Epoch 2454/5000\n",
      "1063/1063 [==============================] - 0s 117us/step - loss: 4.4173 - val_loss: 72.3628\n",
      "Epoch 2455/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6738 - val_loss: 78.0509\n",
      "Epoch 2456/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3809 - val_loss: 74.5339\n",
      "Epoch 2457/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.4528 - val_loss: 69.6450\n",
      "Epoch 2458/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5643 - val_loss: 68.0749\n",
      "Epoch 2459/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.4899 - val_loss: 68.8004\n",
      "Epoch 2460/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.3391 - val_loss: 73.0786\n",
      "Epoch 2461/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.2882 - val_loss: 74.2984\n",
      "Epoch 2462/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.6408 - val_loss: 71.2218\n",
      "Epoch 2463/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5463 - val_loss: 68.7101\n",
      "Epoch 2464/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7217 - val_loss: 78.4549\n",
      "Epoch 2465/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8369 - val_loss: 65.8908\n",
      "Epoch 2466/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.7240 - val_loss: 74.0157\n",
      "Epoch 2467/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6627 - val_loss: 63.9574\n",
      "Epoch 2468/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.5605 - val_loss: 72.6451\n",
      "Epoch 2469/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.1936 - val_loss: 62.9014\n",
      "Epoch 2470/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.9260 - val_loss: 78.6290\n",
      "Epoch 2471/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.6866 - val_loss: 67.3088\n",
      "Epoch 2472/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.1940 - val_loss: 66.9631\n",
      "Epoch 2473/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.7018 - val_loss: 74.2690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2474/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.7778 - val_loss: 67.1855\n",
      "Epoch 2475/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5350 - val_loss: 68.0159\n",
      "Epoch 2476/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.6629 - val_loss: 70.7360\n",
      "Epoch 2477/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.4561 - val_loss: 70.7879\n",
      "Epoch 2478/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4276 - val_loss: 75.5417\n",
      "Epoch 2479/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.3556 - val_loss: 72.6186\n",
      "Epoch 2480/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5204 - val_loss: 71.0363\n",
      "Epoch 2481/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5628 - val_loss: 79.2274\n",
      "Epoch 2482/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7963 - val_loss: 73.7389\n",
      "Epoch 2483/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5575 - val_loss: 72.2241\n",
      "Epoch 2484/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4163 - val_loss: 66.5482\n",
      "Epoch 2485/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.3247 - val_loss: 72.2927\n",
      "Epoch 2486/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6624 - val_loss: 67.6659\n",
      "Epoch 2487/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.8653 - val_loss: 68.7555\n",
      "Epoch 2488/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7815 - val_loss: 72.1027\n",
      "Epoch 2489/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5096 - val_loss: 70.0330\n",
      "Epoch 2490/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.0069 - val_loss: 70.4537\n",
      "Epoch 2491/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.4199 - val_loss: 67.5395\n",
      "Epoch 2492/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.9606 - val_loss: 83.1111\n",
      "Epoch 2493/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8904 - val_loss: 86.5985\n",
      "Epoch 2494/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7672 - val_loss: 74.9532\n",
      "Epoch 2495/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.3563 - val_loss: 64.6869\n",
      "Epoch 2496/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5269 - val_loss: 72.2273\n",
      "Epoch 2497/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.8237 - val_loss: 72.6991\n",
      "Epoch 2498/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5630 - val_loss: 72.6946\n",
      "Epoch 2499/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6751 - val_loss: 77.7322\n",
      "Epoch 2500/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 6.0696 - val_loss: 67.9811\n",
      "Epoch 2501/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.8239 - val_loss: 72.2135\n",
      "Epoch 2502/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.6524 - val_loss: 82.0538\n",
      "Epoch 2503/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.8826 - val_loss: 69.9223\n",
      "Epoch 2504/5000\n",
      "1063/1063 [==============================] - 0s 126us/step - loss: 4.5330 - val_loss: 63.6715\n",
      "Epoch 2505/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.5067 - val_loss: 65.0131\n",
      "Epoch 2506/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.5729 - val_loss: 66.7422\n",
      "Epoch 2507/5000\n",
      "1063/1063 [==============================] - 0s 145us/step - loss: 4.5521 - val_loss: 78.0536\n",
      "Epoch 2508/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.6274 - val_loss: 70.2373\n",
      "Epoch 2509/5000\n",
      "1063/1063 [==============================] - 0s 121us/step - loss: 4.7369 - val_loss: 76.4991\n",
      "Epoch 2510/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5061 - val_loss: 67.1724\n",
      "Epoch 2511/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5733 - val_loss: 74.4628\n",
      "Epoch 2512/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.5369 - val_loss: 67.0674\n",
      "Epoch 2513/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.8940 - val_loss: 71.3292\n",
      "Epoch 2514/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.4480 - val_loss: 66.6855\n",
      "Epoch 2515/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.9785 - val_loss: 70.6192\n",
      "Epoch 2516/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.5837 - val_loss: 68.4092\n",
      "Epoch 2517/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.6475 - val_loss: 76.3661\n",
      "Epoch 2518/5000\n",
      "1063/1063 [==============================] - 0s 125us/step - loss: 4.4907 - val_loss: 72.4056\n",
      "Epoch 2519/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.4256 - val_loss: 72.4475\n",
      "Epoch 2520/5000\n",
      "1063/1063 [==============================] - 0s 117us/step - loss: 4.8247 - val_loss: 64.4408\n",
      "Epoch 2521/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.5561 - val_loss: 76.4793\n",
      "Epoch 2522/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.6430 - val_loss: 67.2253\n",
      "Epoch 2523/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5134 - val_loss: 67.0176\n",
      "Epoch 2524/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.9642 - val_loss: 75.0574\n",
      "Epoch 2525/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.9159 - val_loss: 72.1856\n",
      "Epoch 2526/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6249 - val_loss: 71.4378\n",
      "Epoch 2527/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5227 - val_loss: 77.7789\n",
      "Epoch 2528/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7293 - val_loss: 76.2541\n",
      "Epoch 2529/5000\n",
      "1063/1063 [==============================] - 0s 133us/step - loss: 4.5650 - val_loss: 77.6465\n",
      "Epoch 2530/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.7030 - val_loss: 79.6788\n",
      "Epoch 2531/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.4728 - val_loss: 69.8615\n",
      "Epoch 2532/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.6030 - val_loss: 69.6005\n",
      "Epoch 2533/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4312 - val_loss: 72.3495\n",
      "Epoch 2534/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4688 - val_loss: 70.9816\n",
      "Epoch 2535/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4535 - val_loss: 68.4208\n",
      "Epoch 2536/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.4552 - val_loss: 71.6245\n",
      "Epoch 2537/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.3818 - val_loss: 72.6378\n",
      "Epoch 2538/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.2813 - val_loss: 71.2905\n",
      "Epoch 2539/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.2515 - val_loss: 65.7339\n",
      "Epoch 2540/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.6249 - val_loss: 89.6825\n",
      "Epoch 2541/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.8691 - val_loss: 72.4341\n",
      "Epoch 2542/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8736 - val_loss: 73.4482\n",
      "Epoch 2543/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3719 - val_loss: 77.4719\n",
      "Epoch 2544/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.7547 - val_loss: 73.4378\n",
      "Epoch 2545/5000\n",
      "1063/1063 [==============================] - 0s 145us/step - loss: 4.3828 - val_loss: 83.3246\n",
      "Epoch 2546/5000\n",
      "1063/1063 [==============================] - 0s 170us/step - loss: 4.5844 - val_loss: 72.0730\n",
      "Epoch 2547/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.3799 - val_loss: 70.5416\n",
      "Epoch 2548/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.4364 - val_loss: 77.8145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2549/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.0562 - val_loss: 84.8860\n",
      "Epoch 2550/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.7986 - val_loss: 73.7506\n",
      "Epoch 2551/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.7585 - val_loss: 65.8239\n",
      "Epoch 2552/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6319 - val_loss: 80.4910\n",
      "Epoch 2553/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.7999 - val_loss: 85.9108\n",
      "Epoch 2554/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7090 - val_loss: 84.9553\n",
      "Epoch 2555/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.1721 - val_loss: 82.2402\n",
      "Epoch 2556/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5617 - val_loss: 73.9145\n",
      "Epoch 2557/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7689 - val_loss: 78.0967\n",
      "Epoch 2558/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.7151 - val_loss: 62.4423\n",
      "Epoch 2559/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.0733 - val_loss: 70.1258\n",
      "Epoch 2560/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.0612 - val_loss: 71.6313\n",
      "Epoch 2561/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.0445 - val_loss: 68.8945\n",
      "Epoch 2562/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.3948 - val_loss: 75.1510\n",
      "Epoch 2563/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5576 - val_loss: 66.5065\n",
      "Epoch 2564/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5720 - val_loss: 78.3814\n",
      "Epoch 2565/5000\n",
      "1063/1063 [==============================] - 0s 127us/step - loss: 4.6868 - val_loss: 79.1392\n",
      "Epoch 2566/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.6740 - val_loss: 73.4076\n",
      "Epoch 2567/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.4236 - val_loss: 76.7855\n",
      "Epoch 2568/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.3124 - val_loss: 69.2368\n",
      "Epoch 2569/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6911 - val_loss: 67.0551\n",
      "Epoch 2570/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9495 - val_loss: 68.9409\n",
      "Epoch 2571/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5151 - val_loss: 99.3345\n",
      "Epoch 2572/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 6.2480 - val_loss: 71.8670\n",
      "Epoch 2573/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.0862 - val_loss: 66.7845\n",
      "Epoch 2574/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5778 - val_loss: 63.0067\n",
      "Epoch 2575/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.5997 - val_loss: 66.2997\n",
      "Epoch 2576/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4426 - val_loss: 72.1517\n",
      "Epoch 2577/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.4847 - val_loss: 64.5633\n",
      "Epoch 2578/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6802 - val_loss: 66.6178\n",
      "Epoch 2579/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7322 - val_loss: 71.8370\n",
      "Epoch 2580/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.3506 - val_loss: 70.3718\n",
      "Epoch 2581/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4034 - val_loss: 70.0716\n",
      "Epoch 2582/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5857 - val_loss: 71.8170\n",
      "Epoch 2583/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4054 - val_loss: 65.6545\n",
      "Epoch 2584/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.5738 - val_loss: 73.3563\n",
      "Epoch 2585/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.4483 - val_loss: 74.9883\n",
      "Epoch 2586/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 5.0206 - val_loss: 67.3046\n",
      "Epoch 2587/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.5262 - val_loss: 73.6496\n",
      "Epoch 2588/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.9189 - val_loss: 68.6543\n",
      "Epoch 2589/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 6.2415 - val_loss: 68.2607\n",
      "Epoch 2590/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.8504 - val_loss: 64.4071\n",
      "Epoch 2591/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.6218 - val_loss: 76.7608\n",
      "Epoch 2592/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.9743 - val_loss: 75.4787\n",
      "Epoch 2593/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5209 - val_loss: 78.2812\n",
      "Epoch 2594/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.5003 - val_loss: 71.9961\n",
      "Epoch 2595/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6658 - val_loss: 71.5847\n",
      "Epoch 2596/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5345 - val_loss: 83.0740\n",
      "Epoch 2597/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7269 - val_loss: 84.9459\n",
      "Epoch 2598/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7000 - val_loss: 69.0913\n",
      "Epoch 2599/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5448 - val_loss: 74.5380\n",
      "Epoch 2600/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.3893 - val_loss: 67.8479\n",
      "Epoch 2601/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4786 - val_loss: 71.6316\n",
      "Epoch 2602/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.2981 - val_loss: 74.4891\n",
      "Epoch 2603/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7045 - val_loss: 70.3525\n",
      "Epoch 2604/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.5374 - val_loss: 78.2349\n",
      "Epoch 2605/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.3143 - val_loss: 76.3808\n",
      "Epoch 2606/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7011 - val_loss: 77.6359\n",
      "Epoch 2607/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.0252 - val_loss: 69.1048\n",
      "Epoch 2608/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4282 - val_loss: 66.9423\n",
      "Epoch 2609/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9607 - val_loss: 68.7548\n",
      "Epoch 2610/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.2154 - val_loss: 72.0007\n",
      "Epoch 2611/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.8300 - val_loss: 70.3392\n",
      "Epoch 2612/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4234 - val_loss: 69.9481\n",
      "Epoch 2613/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6957 - val_loss: 67.4618\n",
      "Epoch 2614/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.7053 - val_loss: 79.0938\n",
      "Epoch 2615/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6533 - val_loss: 67.7065\n",
      "Epoch 2616/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4645 - val_loss: 68.4532\n",
      "Epoch 2617/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5011 - val_loss: 68.4490\n",
      "Epoch 2618/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4308 - val_loss: 80.2615\n",
      "Epoch 2619/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6961 - val_loss: 65.5493\n",
      "Epoch 2620/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.9040 - val_loss: 68.1912\n",
      "Epoch 2621/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8956 - val_loss: 72.0852\n",
      "Epoch 2622/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8550 - val_loss: 74.4020\n",
      "Epoch 2623/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8662 - val_loss: 74.6942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2624/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4487 - val_loss: 68.0603\n",
      "Epoch 2625/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.4204 - val_loss: 74.8101\n",
      "Epoch 2626/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.2944 - val_loss: 70.0563\n",
      "Epoch 2627/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6885 - val_loss: 68.0875\n",
      "Epoch 2628/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.3801 - val_loss: 75.8629\n",
      "Epoch 2629/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5818 - val_loss: 70.4209\n",
      "Epoch 2630/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7400 - val_loss: 80.3083\n",
      "Epoch 2631/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.3341 - val_loss: 72.1562\n",
      "Epoch 2632/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.7506 - val_loss: 73.6280\n",
      "Epoch 2633/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.3861 - val_loss: 69.2958\n",
      "Epoch 2634/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.8785 - val_loss: 67.6003\n",
      "Epoch 2635/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.5985 - val_loss: 70.1961\n",
      "Epoch 2636/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6507 - val_loss: 72.1900\n",
      "Epoch 2637/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4289 - val_loss: 76.4400\n",
      "Epoch 2638/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5721 - val_loss: 75.1912\n",
      "Epoch 2639/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.6637 - val_loss: 70.4589\n",
      "Epoch 2640/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4448 - val_loss: 77.1181\n",
      "Epoch 2641/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7067 - val_loss: 69.1945\n",
      "Epoch 2642/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.6322 - val_loss: 78.0011\n",
      "Epoch 2643/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.8133 - val_loss: 67.2477\n",
      "Epoch 2644/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.4414 - val_loss: 71.9824\n",
      "Epoch 2645/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5700 - val_loss: 65.3160\n",
      "Epoch 2646/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7098 - val_loss: 70.5079\n",
      "Epoch 2647/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5590 - val_loss: 66.2710\n",
      "Epoch 2648/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6569 - val_loss: 71.9601\n",
      "Epoch 2649/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.3885 - val_loss: 73.1850\n",
      "Epoch 2650/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5540 - val_loss: 73.8063\n",
      "Epoch 2651/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.5716 - val_loss: 67.2178\n",
      "Epoch 2652/5000\n",
      "1063/1063 [==============================] - 0s 117us/step - loss: 5.2476 - val_loss: 75.0235\n",
      "Epoch 2653/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.9581 - val_loss: 71.2632\n",
      "Epoch 2654/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.6777 - val_loss: 71.6533\n",
      "Epoch 2655/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 5.0079 - val_loss: 72.7212\n",
      "Epoch 2656/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4852 - val_loss: 72.2423\n",
      "Epoch 2657/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.3895 - val_loss: 76.7145\n",
      "Epoch 2658/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.2813 - val_loss: 71.4978\n",
      "Epoch 2659/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.4266 - val_loss: 70.4932\n",
      "Epoch 2660/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.4281 - val_loss: 67.4645\n",
      "Epoch 2661/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5903 - val_loss: 67.7580\n",
      "Epoch 2662/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.7098 - val_loss: 70.7679\n",
      "Epoch 2663/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.4143 - val_loss: 73.6209\n",
      "Epoch 2664/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.6669 - val_loss: 71.1497\n",
      "Epoch 2665/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.8615 - val_loss: 73.7108\n",
      "Epoch 2666/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.5858 - val_loss: 73.2903\n",
      "Epoch 2667/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.4672 - val_loss: 68.9184\n",
      "Epoch 2668/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5790 - val_loss: 65.8979\n",
      "Epoch 2669/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.3359 - val_loss: 67.3150\n",
      "Epoch 2670/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.3965 - val_loss: 74.2826\n",
      "Epoch 2671/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.8444 - val_loss: 64.3161\n",
      "Epoch 2672/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.7972 - val_loss: 74.8020\n",
      "Epoch 2673/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.6944 - val_loss: 77.7164\n",
      "Epoch 2674/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.8993 - val_loss: 67.5904\n",
      "Epoch 2675/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.8450 - val_loss: 75.2637\n",
      "Epoch 2676/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.2179 - val_loss: 73.7060\n",
      "Epoch 2677/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.6563 - val_loss: 70.1002\n",
      "Epoch 2678/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.8927 - val_loss: 76.6510\n",
      "Epoch 2679/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.4065 - val_loss: 71.3778\n",
      "Epoch 2680/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.3313 - val_loss: 67.6187\n",
      "Epoch 2681/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.6290 - val_loss: 77.2921\n",
      "Epoch 2682/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.4579 - val_loss: 69.7848\n",
      "Epoch 2683/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.3484 - val_loss: 74.8212\n",
      "Epoch 2684/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4465 - val_loss: 72.7639\n",
      "Epoch 2685/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.2989 - val_loss: 69.5610\n",
      "Epoch 2686/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.0160 - val_loss: 72.5022\n",
      "Epoch 2687/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9474 - val_loss: 73.6238\n",
      "Epoch 2688/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.0490 - val_loss: 74.4016\n",
      "Epoch 2689/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.8503 - val_loss: 68.4941\n",
      "Epoch 2690/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.3641 - val_loss: 70.9604\n",
      "Epoch 2691/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5224 - val_loss: 80.2537\n",
      "Epoch 2692/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.6489 - val_loss: 82.0235\n",
      "Epoch 2693/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.1481 - val_loss: 71.4216\n",
      "Epoch 2694/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7675 - val_loss: 71.1827\n",
      "Epoch 2695/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.3991 - val_loss: 70.1759\n",
      "Epoch 2696/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.2809 - val_loss: 74.1910\n",
      "Epoch 2697/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6420 - val_loss: 89.8040\n",
      "Epoch 2698/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9216 - val_loss: 68.1134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2699/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.4490 - val_loss: 76.0672\n",
      "Epoch 2700/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.9039 - val_loss: 69.4841\n",
      "Epoch 2701/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.6361 - val_loss: 70.9835\n",
      "Epoch 2702/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.9151 - val_loss: 77.9669\n",
      "Epoch 2703/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.7917 - val_loss: 70.8993\n",
      "Epoch 2704/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4659 - val_loss: 74.1519\n",
      "Epoch 2705/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.5137 - val_loss: 74.4836\n",
      "Epoch 2706/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.3865 - val_loss: 74.5810\n",
      "Epoch 2707/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.6958 - val_loss: 69.1616\n",
      "Epoch 2708/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.4901 - val_loss: 72.6211\n",
      "Epoch 2709/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.3019 - val_loss: 70.3477\n",
      "Epoch 2710/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.5731 - val_loss: 65.0373\n",
      "Epoch 2711/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.8688 - val_loss: 74.4810\n",
      "Epoch 2712/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5941 - val_loss: 68.5468\n",
      "Epoch 2713/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.3403 - val_loss: 71.5162\n",
      "Epoch 2714/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3639 - val_loss: 80.8636\n",
      "Epoch 2715/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.7176 - val_loss: 75.9420\n",
      "Epoch 2716/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.2668 - val_loss: 83.5122\n",
      "Epoch 2717/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.7739 - val_loss: 68.4405\n",
      "Epoch 2718/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.3137 - val_loss: 73.2452\n",
      "Epoch 2719/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.8184 - val_loss: 70.6768\n",
      "Epoch 2720/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.5650 - val_loss: 70.6271\n",
      "Epoch 2721/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.0296 - val_loss: 81.6837\n",
      "Epoch 2722/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 5.3636 - val_loss: 69.4795\n",
      "Epoch 2723/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5169 - val_loss: 65.7786\n",
      "Epoch 2724/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.2066 - val_loss: 74.7991\n",
      "Epoch 2725/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.8191 - val_loss: 73.9891\n",
      "Epoch 2726/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.7909 - val_loss: 61.9706\n",
      "Epoch 2727/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.0001 - val_loss: 68.3642\n",
      "Epoch 2728/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.7049 - val_loss: 71.4162\n",
      "Epoch 2729/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4556 - val_loss: 67.6509\n",
      "Epoch 2730/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4220 - val_loss: 77.5935\n",
      "Epoch 2731/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.7870 - val_loss: 72.5390\n",
      "Epoch 2732/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4281 - val_loss: 78.7157\n",
      "Epoch 2733/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5085 - val_loss: 69.1149\n",
      "Epoch 2734/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6277 - val_loss: 69.3074\n",
      "Epoch 2735/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.3947 - val_loss: 75.2226\n",
      "Epoch 2736/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6925 - val_loss: 73.3241\n",
      "Epoch 2737/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.6368 - val_loss: 70.2116\n",
      "Epoch 2738/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5531 - val_loss: 71.6930\n",
      "Epoch 2739/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6312 - val_loss: 84.4870\n",
      "Epoch 2740/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.1357 - val_loss: 69.0288\n",
      "Epoch 2741/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.9986 - val_loss: 74.4718\n",
      "Epoch 2742/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.4329 - val_loss: 67.9769\n",
      "Epoch 2743/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.7007 - val_loss: 85.5368\n",
      "Epoch 2744/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.0713 - val_loss: 76.0715\n",
      "Epoch 2745/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.7661 - val_loss: 72.1800\n",
      "Epoch 2746/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5355 - val_loss: 73.2613\n",
      "Epoch 2747/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.4632 - val_loss: 69.4377\n",
      "Epoch 2748/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.3573 - val_loss: 71.8702\n",
      "Epoch 2749/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3139 - val_loss: 70.2831\n",
      "Epoch 2750/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.3098 - val_loss: 71.2321\n",
      "Epoch 2751/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.3502 - val_loss: 64.6081\n",
      "Epoch 2752/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.9095 - val_loss: 63.1385\n",
      "Epoch 2753/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.1423 - val_loss: 66.2474\n",
      "Epoch 2754/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.1523 - val_loss: 84.0839\n",
      "Epoch 2755/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.9498 - val_loss: 73.5765\n",
      "Epoch 2756/5000\n",
      "1063/1063 [==============================] - 0s 132us/step - loss: 4.7809 - val_loss: 73.4047\n",
      "Epoch 2757/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.4358 - val_loss: 67.3629\n",
      "Epoch 2758/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.7600 - val_loss: 68.3821\n",
      "Epoch 2759/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6236 - val_loss: 75.4218\n",
      "Epoch 2760/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4708 - val_loss: 71.4050\n",
      "Epoch 2761/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.7384 - val_loss: 67.9588\n",
      "Epoch 2762/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.5542 - val_loss: 65.0116\n",
      "Epoch 2763/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.9186 - val_loss: 69.5367\n",
      "Epoch 2764/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.6367 - val_loss: 76.5558\n",
      "Epoch 2765/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.5939 - val_loss: 82.9755\n",
      "Epoch 2766/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.8140 - val_loss: 79.8933\n",
      "Epoch 2767/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.7051 - val_loss: 72.2601\n",
      "Epoch 2768/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.5390 - val_loss: 77.3113\n",
      "Epoch 2769/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.4765 - val_loss: 71.1853\n",
      "Epoch 2770/5000\n",
      "1063/1063 [==============================] - 0s 119us/step - loss: 4.8201 - val_loss: 69.2272\n",
      "Epoch 2771/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.8225 - val_loss: 70.7708\n",
      "Epoch 2772/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.6703 - val_loss: 70.9842\n",
      "Epoch 2773/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.6417 - val_loss: 69.0650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2774/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.9298 - val_loss: 69.3350\n",
      "Epoch 2775/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.8470 - val_loss: 72.9786\n",
      "Epoch 2776/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.7718 - val_loss: 70.1622\n",
      "Epoch 2777/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.5015 - val_loss: 65.6839\n",
      "Epoch 2778/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.6086 - val_loss: 67.0369\n",
      "Epoch 2779/5000\n",
      "1063/1063 [==============================] - 0s 125us/step - loss: 4.5769 - val_loss: 71.6854\n",
      "Epoch 2780/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.4892 - val_loss: 72.1326\n",
      "Epoch 2781/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.3453 - val_loss: 70.8133\n",
      "Epoch 2782/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4453 - val_loss: 78.0949\n",
      "Epoch 2783/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.3307 - val_loss: 79.5556\n",
      "Epoch 2784/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.7862 - val_loss: 74.7975\n",
      "Epoch 2785/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3615 - val_loss: 75.4307\n",
      "Epoch 2786/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.7513 - val_loss: 75.5798\n",
      "Epoch 2787/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.3577 - val_loss: 68.4972\n",
      "Epoch 2788/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.4435 - val_loss: 70.3985\n",
      "Epoch 2789/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4344 - val_loss: 68.7478\n",
      "Epoch 2790/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.3560 - val_loss: 79.5055\n",
      "Epoch 2791/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.9136 - val_loss: 75.5149\n",
      "Epoch 2792/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6973 - val_loss: 70.2049\n",
      "Epoch 2793/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3967 - val_loss: 71.0919\n",
      "Epoch 2794/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.9088 - val_loss: 76.8282\n",
      "Epoch 2795/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4021 - val_loss: 73.7180\n",
      "Epoch 2796/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5582 - val_loss: 70.4421\n",
      "Epoch 2797/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.0747 - val_loss: 80.3384\n",
      "Epoch 2798/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.9995 - val_loss: 77.2246\n",
      "Epoch 2799/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.3174 - val_loss: 76.9368\n",
      "Epoch 2800/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.2767 - val_loss: 72.9800\n",
      "Epoch 2801/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.3508 - val_loss: 72.6392\n",
      "Epoch 2802/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.3634 - val_loss: 69.0999\n",
      "Epoch 2803/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.3944 - val_loss: 76.4262\n",
      "Epoch 2804/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.6196 - val_loss: 66.1004\n",
      "Epoch 2805/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.7431 - val_loss: 68.8792\n",
      "Epoch 2806/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5989 - val_loss: 79.8405\n",
      "Epoch 2807/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.6424 - val_loss: 74.7390\n",
      "Epoch 2808/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.5954 - val_loss: 74.9538\n",
      "Epoch 2809/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5991 - val_loss: 62.2791\n",
      "Epoch 2810/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4485 - val_loss: 66.5527\n",
      "Epoch 2811/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.7151 - val_loss: 70.3593\n",
      "Epoch 2812/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.5290 - val_loss: 77.1471\n",
      "Epoch 2813/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.0443 - val_loss: 76.5504\n",
      "Epoch 2814/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.3226 - val_loss: 77.9490\n",
      "Epoch 2815/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.4875 - val_loss: 71.6895\n",
      "Epoch 2816/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.7940 - val_loss: 76.4908\n",
      "Epoch 2817/5000\n",
      "1063/1063 [==============================] - 0s 121us/step - loss: 4.9143 - val_loss: 71.0235\n",
      "Epoch 2818/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.8222 - val_loss: 68.3757\n",
      "Epoch 2819/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 6.0630 - val_loss: 79.0673\n",
      "Epoch 2820/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 5.6318 - val_loss: 65.6880\n",
      "Epoch 2821/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.9322 - val_loss: 68.9047\n",
      "Epoch 2822/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.8234 - val_loss: 70.6862\n",
      "Epoch 2823/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5741 - val_loss: 68.8121\n",
      "Epoch 2824/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4006 - val_loss: 69.1341\n",
      "Epoch 2825/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7821 - val_loss: 84.2834\n",
      "Epoch 2826/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.4699 - val_loss: 71.1336\n",
      "Epoch 2827/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.5695 - val_loss: 71.4389\n",
      "Epoch 2828/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.4570 - val_loss: 78.9947\n",
      "Epoch 2829/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.4889 - val_loss: 72.2084\n",
      "Epoch 2830/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6121 - val_loss: 69.6089\n",
      "Epoch 2831/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.0253 - val_loss: 75.2999\n",
      "Epoch 2832/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7290 - val_loss: 74.5157\n",
      "Epoch 2833/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4926 - val_loss: 69.2331\n",
      "Epoch 2834/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3428 - val_loss: 82.8740\n",
      "Epoch 2835/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9625 - val_loss: 75.5334\n",
      "Epoch 2836/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4326 - val_loss: 67.7863\n",
      "Epoch 2837/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.9284 - val_loss: 81.3371\n",
      "Epoch 2838/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6464 - val_loss: 73.2077\n",
      "Epoch 2839/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5141 - val_loss: 80.0722\n",
      "Epoch 2840/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6843 - val_loss: 76.4195\n",
      "Epoch 2841/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7320 - val_loss: 75.0289\n",
      "Epoch 2842/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5215 - val_loss: 68.9902\n",
      "Epoch 2843/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6091 - val_loss: 72.3337\n",
      "Epoch 2844/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8334 - val_loss: 70.0071\n",
      "Epoch 2845/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6573 - val_loss: 74.8343\n",
      "Epoch 2846/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.3988 - val_loss: 78.3754\n",
      "Epoch 2847/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.8146 - val_loss: 73.0870\n",
      "Epoch 2848/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6406 - val_loss: 73.9097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2849/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8351 - val_loss: 72.6113\n",
      "Epoch 2850/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4189 - val_loss: 73.8784\n",
      "Epoch 2851/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 5.1567 - val_loss: 79.4203\n",
      "Epoch 2852/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4174 - val_loss: 75.6753\n",
      "Epoch 2853/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5817 - val_loss: 69.1234\n",
      "Epoch 2854/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6965 - val_loss: 71.1049\n",
      "Epoch 2855/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5936 - val_loss: 62.8779\n",
      "Epoch 2856/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.4720 - val_loss: 77.9286\n",
      "Epoch 2857/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.1831 - val_loss: 79.2458\n",
      "Epoch 2858/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.7506 - val_loss: 83.6707\n",
      "Epoch 2859/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.0235 - val_loss: 76.6985\n",
      "Epoch 2860/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.6128 - val_loss: 75.9158\n",
      "Epoch 2861/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6081 - val_loss: 71.9710\n",
      "Epoch 2862/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5019 - val_loss: 69.6529\n",
      "Epoch 2863/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6419 - val_loss: 69.6582\n",
      "Epoch 2864/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5130 - val_loss: 72.8692\n",
      "Epoch 2865/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7807 - val_loss: 74.6165\n",
      "Epoch 2866/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5654 - val_loss: 76.6318\n",
      "Epoch 2867/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.7208 - val_loss: 75.7353\n",
      "Epoch 2868/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.3631 - val_loss: 70.3434\n",
      "Epoch 2869/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.5714 - val_loss: 69.0488\n",
      "Epoch 2870/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4107 - val_loss: 78.8098\n",
      "Epoch 2871/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.2162 - val_loss: 66.6206\n",
      "Epoch 2872/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5204 - val_loss: 66.9309\n",
      "Epoch 2873/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6264 - val_loss: 68.1060\n",
      "Epoch 2874/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4504 - val_loss: 68.1115\n",
      "Epoch 2875/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.8745 - val_loss: 74.3301\n",
      "Epoch 2876/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8789 - val_loss: 72.1483\n",
      "Epoch 2877/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5056 - val_loss: 70.6541\n",
      "Epoch 2878/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.4086 - val_loss: 66.6266\n",
      "Epoch 2879/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6317 - val_loss: 77.5205\n",
      "Epoch 2880/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4952 - val_loss: 66.3336\n",
      "Epoch 2881/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8479 - val_loss: 71.9333\n",
      "Epoch 2882/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4273 - val_loss: 68.7779\n",
      "Epoch 2883/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6471 - val_loss: 73.9474\n",
      "Epoch 2884/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.1772 - val_loss: 79.7705\n",
      "Epoch 2885/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5315 - val_loss: 69.6934\n",
      "Epoch 2886/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4846 - val_loss: 77.6615\n",
      "Epoch 2887/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6917 - val_loss: 70.9725\n",
      "Epoch 2888/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.4466 - val_loss: 67.2174\n",
      "Epoch 2889/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7830 - val_loss: 65.1155\n",
      "Epoch 2890/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6547 - val_loss: 74.2236\n",
      "Epoch 2891/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 5.1690 - val_loss: 78.7189\n",
      "Epoch 2892/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.9335 - val_loss: 76.9676\n",
      "Epoch 2893/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.4135 - val_loss: 71.8858\n",
      "Epoch 2894/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3461 - val_loss: 64.2382\n",
      "Epoch 2895/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4061 - val_loss: 72.8533\n",
      "Epoch 2896/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5744 - val_loss: 78.5656\n",
      "Epoch 2897/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3842 - val_loss: 73.9449\n",
      "Epoch 2898/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4965 - val_loss: 71.3856\n",
      "Epoch 2899/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.4731 - val_loss: 65.9449\n",
      "Epoch 2900/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3741 - val_loss: 78.1149\n",
      "Epoch 2901/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 5.1878 - val_loss: 73.2201\n",
      "Epoch 2902/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.2161 - val_loss: 72.3581\n",
      "Epoch 2903/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5872 - val_loss: 66.4429\n",
      "Epoch 2904/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6833 - val_loss: 70.3739\n",
      "Epoch 2905/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5017 - val_loss: 67.0796\n",
      "Epoch 2906/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.1009 - val_loss: 64.2870\n",
      "Epoch 2907/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6672 - val_loss: 70.6011\n",
      "Epoch 2908/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.3053 - val_loss: 71.7631\n",
      "Epoch 2909/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.6301 - val_loss: 78.5558\n",
      "Epoch 2910/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4861 - val_loss: 69.6198\n",
      "Epoch 2911/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6954 - val_loss: 68.4509\n",
      "Epoch 2912/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6413 - val_loss: 70.2456\n",
      "Epoch 2913/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6705 - val_loss: 71.3543\n",
      "Epoch 2914/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5406 - val_loss: 66.9567\n",
      "Epoch 2915/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.8432 - val_loss: 66.0415\n",
      "Epoch 2916/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.7637 - val_loss: 68.8326\n",
      "Epoch 2917/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5139 - val_loss: 69.0354\n",
      "Epoch 2918/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.4317 - val_loss: 65.6656\n",
      "Epoch 2919/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 5.5528 - val_loss: 75.9348\n",
      "Epoch 2920/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.8924 - val_loss: 71.2996\n",
      "Epoch 2921/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.4158 - val_loss: 76.2737\n",
      "Epoch 2922/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.2876 - val_loss: 71.7451\n",
      "Epoch 2923/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.4074 - val_loss: 68.5254\n",
      "Epoch 2924/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.3774 - val_loss: 68.8577\n",
      "Epoch 2925/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4297 - val_loss: 74.0769\n",
      "Epoch 2926/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4657 - val_loss: 70.2352\n",
      "Epoch 2927/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.2851 - val_loss: 78.7857\n",
      "Epoch 2928/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.3280 - val_loss: 69.6346\n",
      "Epoch 2929/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.5401 - val_loss: 70.7570\n",
      "Epoch 2930/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7306 - val_loss: 66.2274\n",
      "Epoch 2931/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3299 - val_loss: 67.2191\n",
      "Epoch 2932/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9800 - val_loss: 68.9129\n",
      "Epoch 2933/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6443 - val_loss: 82.1507\n",
      "Epoch 2934/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9844 - val_loss: 71.0569\n",
      "Epoch 2935/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4028 - val_loss: 74.9612\n",
      "Epoch 2936/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3162 - val_loss: 73.8123\n",
      "Epoch 2937/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.2389 - val_loss: 70.7174\n",
      "Epoch 2938/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6528 - val_loss: 77.5779\n",
      "Epoch 2939/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.4500 - val_loss: 74.0393\n",
      "Epoch 2940/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6569 - val_loss: 71.8130\n",
      "Epoch 2941/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4238 - val_loss: 70.7075\n",
      "Epoch 2942/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5835 - val_loss: 72.2532\n",
      "Epoch 2943/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7014 - val_loss: 67.5611\n",
      "Epoch 2944/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8378 - val_loss: 78.6151\n",
      "Epoch 2945/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8416 - val_loss: 74.5508\n",
      "Epoch 2946/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5410 - val_loss: 72.7891\n",
      "Epoch 2947/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4155 - val_loss: 75.1611\n",
      "Epoch 2948/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7337 - val_loss: 69.4542\n",
      "Epoch 2949/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6433 - val_loss: 67.9331\n",
      "Epoch 2950/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6229 - val_loss: 67.8126\n",
      "Epoch 2951/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4423 - val_loss: 72.1628\n",
      "Epoch 2952/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5800 - val_loss: 68.7528\n",
      "Epoch 2953/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.3985 - val_loss: 71.6982\n",
      "Epoch 2954/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7300 - val_loss: 73.7852\n",
      "Epoch 2955/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6492 - val_loss: 64.6195\n",
      "Epoch 2956/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.7170 - val_loss: 75.6256\n",
      "Epoch 2957/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.2955 - val_loss: 71.9674\n",
      "Epoch 2958/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 5.1702 - val_loss: 69.0696\n",
      "Epoch 2959/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.7463 - val_loss: 79.9192\n",
      "Epoch 2960/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 5.3123 - val_loss: 77.8038\n",
      "Epoch 2961/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5252 - val_loss: 72.5157\n",
      "Epoch 2962/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.3336 - val_loss: 67.8152\n",
      "Epoch 2963/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.3439 - val_loss: 80.6077\n",
      "Epoch 2964/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.2901 - val_loss: 74.6005\n",
      "Epoch 2965/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.3971 - val_loss: 72.1809\n",
      "Epoch 2966/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.5051 - val_loss: 68.1226\n",
      "Epoch 2967/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.5502 - val_loss: 69.0713\n",
      "Epoch 2968/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.7317 - val_loss: 73.4524\n",
      "Epoch 2969/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 4.8471 - val_loss: 67.0358\n",
      "Epoch 2970/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.7117 - val_loss: 68.1006\n",
      "Epoch 2971/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.3868 - val_loss: 80.0553\n",
      "Epoch 2972/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.5404 - val_loss: 65.8187\n",
      "Epoch 2973/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6825 - val_loss: 74.0490\n",
      "Epoch 2974/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5911 - val_loss: 65.8358\n",
      "Epoch 2975/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.7031 - val_loss: 68.6673\n",
      "Epoch 2976/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.7159 - val_loss: 70.2600\n",
      "Epoch 2977/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6346 - val_loss: 70.9774\n",
      "Epoch 2978/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.4610 - val_loss: 76.5460\n",
      "Epoch 2979/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8907 - val_loss: 70.1090\n",
      "Epoch 2980/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4986 - val_loss: 72.9935\n",
      "Epoch 2981/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3347 - val_loss: 67.4012\n",
      "Epoch 2982/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.3619 - val_loss: 71.7214\n",
      "Epoch 2983/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6203 - val_loss: 71.3944\n",
      "Epoch 2984/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6141 - val_loss: 66.9248\n",
      "Epoch 2985/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5573 - val_loss: 68.4162\n",
      "Epoch 2986/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.7357 - val_loss: 66.2330\n",
      "Epoch 2987/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4651 - val_loss: 70.5023\n",
      "Epoch 2988/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.4980 - val_loss: 73.7710\n",
      "Epoch 2989/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3841 - val_loss: 78.0423\n",
      "Epoch 2990/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.6327 - val_loss: 71.4990\n",
      "Epoch 2991/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.2814 - val_loss: 68.4414\n",
      "Epoch 2992/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5844 - val_loss: 72.3944\n",
      "Epoch 2993/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5159 - val_loss: 66.4119\n",
      "Epoch 2994/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.2405 - val_loss: 69.2868\n",
      "Epoch 2995/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.2735 - val_loss: 65.7986\n",
      "Epoch 2996/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.7294 - val_loss: 69.9308\n",
      "Epoch 2997/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5809 - val_loss: 66.3218\n",
      "Epoch 2998/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4750 - val_loss: 71.4099\n",
      "Epoch 2999/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4245 - val_loss: 67.5373\n",
      "Epoch 3000/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8888 - val_loss: 72.9736\n",
      "Epoch 3001/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.1360 - val_loss: 70.3485\n",
      "Epoch 3002/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6789 - val_loss: 66.5229\n",
      "Epoch 3003/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.4995 - val_loss: 68.3773\n",
      "Epoch 3004/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7587 - val_loss: 84.6884\n",
      "Epoch 3005/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.7141 - val_loss: 69.4014\n",
      "Epoch 3006/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6256 - val_loss: 69.9214\n",
      "Epoch 3007/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.0250 - val_loss: 72.4516\n",
      "Epoch 3008/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.2556 - val_loss: 81.8682\n",
      "Epoch 3009/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.4922 - val_loss: 70.8990\n",
      "Epoch 3010/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5023 - val_loss: 73.0998\n",
      "Epoch 3011/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5070 - val_loss: 70.7973\n",
      "Epoch 3012/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.4508 - val_loss: 72.7882\n",
      "Epoch 3013/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4406 - val_loss: 75.7647\n",
      "Epoch 3014/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6229 - val_loss: 67.6569\n",
      "Epoch 3015/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5113 - val_loss: 69.6066\n",
      "Epoch 3016/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.3540 - val_loss: 66.2879\n",
      "Epoch 3017/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5526 - val_loss: 80.7160\n",
      "Epoch 3018/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.0182 - val_loss: 73.2957\n",
      "Epoch 3019/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.6115 - val_loss: 75.7444\n",
      "Epoch 3020/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.3024 - val_loss: 66.5111\n",
      "Epoch 3021/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7552 - val_loss: 64.8966\n",
      "Epoch 3022/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.4022 - val_loss: 69.3531\n",
      "Epoch 3023/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4809 - val_loss: 67.2663\n",
      "Epoch 3024/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.2981 - val_loss: 76.0106\n",
      "Epoch 3025/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.0148 - val_loss: 71.2628\n",
      "Epoch 3026/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5003 - val_loss: 71.0570\n",
      "Epoch 3027/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7512 - val_loss: 70.9846\n",
      "Epoch 3028/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7711 - val_loss: 69.3207\n",
      "Epoch 3029/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.3118 - val_loss: 67.0699\n",
      "Epoch 3030/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7313 - val_loss: 72.5631\n",
      "Epoch 3031/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7353 - val_loss: 78.2500\n",
      "Epoch 3032/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3526 - val_loss: 69.6565\n",
      "Epoch 3033/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6156 - val_loss: 66.3116\n",
      "Epoch 3034/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.1048 - val_loss: 63.1944\n",
      "Epoch 3035/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.0145 - val_loss: 79.7379\n",
      "Epoch 3036/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5464 - val_loss: 73.3266\n",
      "Epoch 3037/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3633 - val_loss: 64.0622\n",
      "Epoch 3038/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5043 - val_loss: 66.4202\n",
      "Epoch 3039/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.5895 - val_loss: 74.6611\n",
      "Epoch 3040/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5416 - val_loss: 71.3555\n",
      "Epoch 3041/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5549 - val_loss: 72.3368\n",
      "Epoch 3042/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5012 - val_loss: 71.3898\n",
      "Epoch 3043/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5535 - val_loss: 72.8204\n",
      "Epoch 3044/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3913 - val_loss: 65.4680\n",
      "Epoch 3045/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 5.2155 - val_loss: 71.4785\n",
      "Epoch 3046/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.7017 - val_loss: 76.6634\n",
      "Epoch 3047/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9920 - val_loss: 76.3582\n",
      "Epoch 3048/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4021 - val_loss: 73.2833\n",
      "Epoch 3049/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.6077 - val_loss: 70.8899\n",
      "Epoch 3050/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4322 - val_loss: 74.5267\n",
      "Epoch 3051/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.8058 - val_loss: 75.5153\n",
      "Epoch 3052/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.5831 - val_loss: 66.5178\n",
      "Epoch 3053/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6091 - val_loss: 78.3935\n",
      "Epoch 3054/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4327 - val_loss: 65.3701\n",
      "Epoch 3055/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6738 - val_loss: 71.5892\n",
      "Epoch 3056/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5221 - val_loss: 69.6659\n",
      "Epoch 3057/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5983 - val_loss: 66.7186\n",
      "Epoch 3058/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5422 - val_loss: 69.3940\n",
      "Epoch 3059/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.3331 - val_loss: 73.3474\n",
      "Epoch 3060/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.5779 - val_loss: 70.3973\n",
      "Epoch 3061/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7647 - val_loss: 80.2038\n",
      "Epoch 3062/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.4735 - val_loss: 69.8865\n",
      "Epoch 3063/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.3468 - val_loss: 77.4630\n",
      "Epoch 3064/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.5579 - val_loss: 69.4077\n",
      "Epoch 3065/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4073 - val_loss: 70.7840\n",
      "Epoch 3066/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4320 - val_loss: 80.8766\n",
      "Epoch 3067/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6758 - val_loss: 76.8276\n",
      "Epoch 3068/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5506 - val_loss: 75.7202\n",
      "Epoch 3069/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.5330 - val_loss: 73.3179\n",
      "Epoch 3070/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.1251 - val_loss: 71.8577\n",
      "Epoch 3071/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.9999 - val_loss: 71.0636\n",
      "Epoch 3072/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7960 - val_loss: 73.8096\n",
      "Epoch 3073/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8886 - val_loss: 72.2912\n",
      "Epoch 3074/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4654 - val_loss: 71.1168\n",
      "Epoch 3075/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.7706 - val_loss: 68.0844\n",
      "Epoch 3076/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7268 - val_loss: 64.4889\n",
      "Epoch 3077/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9242 - val_loss: 73.8107\n",
      "Epoch 3078/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7987 - val_loss: 69.8386\n",
      "Epoch 3079/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5188 - val_loss: 70.8242\n",
      "Epoch 3080/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.3711 - val_loss: 77.6679\n",
      "Epoch 3081/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5167 - val_loss: 68.4796\n",
      "Epoch 3082/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4772 - val_loss: 65.5612\n",
      "Epoch 3083/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.8084 - val_loss: 74.4070\n",
      "Epoch 3084/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6945 - val_loss: 66.5149\n",
      "Epoch 3085/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.4807 - val_loss: 69.0237\n",
      "Epoch 3086/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.3934 - val_loss: 71.4811\n",
      "Epoch 3087/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4672 - val_loss: 76.4703\n",
      "Epoch 3088/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5571 - val_loss: 66.3647\n",
      "Epoch 3089/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3532 - val_loss: 79.5345\n",
      "Epoch 3090/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.6953 - val_loss: 68.0023\n",
      "Epoch 3091/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5748 - val_loss: 76.8970\n",
      "Epoch 3092/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5556 - val_loss: 67.8774\n",
      "Epoch 3093/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5868 - val_loss: 70.0470\n",
      "Epoch 3094/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4026 - val_loss: 72.9519\n",
      "Epoch 3095/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3814 - val_loss: 69.2063\n",
      "Epoch 3096/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6152 - val_loss: 74.5954\n",
      "Epoch 3097/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4870 - val_loss: 71.9201\n",
      "Epoch 3098/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5129 - val_loss: 65.6385\n",
      "Epoch 3099/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4439 - val_loss: 75.7743\n",
      "Epoch 3100/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.3535 - val_loss: 69.3788\n",
      "Epoch 3101/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.2586 - val_loss: 74.6107\n",
      "Epoch 3102/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3229 - val_loss: 67.0307\n",
      "Epoch 3103/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.2242 - val_loss: 70.0569\n",
      "Epoch 3104/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.2881 - val_loss: 64.8609\n",
      "Epoch 3105/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.7420 - val_loss: 70.2762\n",
      "Epoch 3106/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.8170 - val_loss: 74.9997\n",
      "Epoch 3107/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5508 - val_loss: 68.7967\n",
      "Epoch 3108/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5902 - val_loss: 68.7116\n",
      "Epoch 3109/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5944 - val_loss: 61.8180\n",
      "Epoch 3110/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.0275 - val_loss: 74.0016\n",
      "Epoch 3111/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.0487 - val_loss: 79.9112\n",
      "Epoch 3112/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5300 - val_loss: 71.4896\n",
      "Epoch 3113/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.5205 - val_loss: 76.0609\n",
      "Epoch 3114/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.5611 - val_loss: 74.8389\n",
      "Epoch 3115/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.3201 - val_loss: 71.2972\n",
      "Epoch 3116/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.3814 - val_loss: 68.1471\n",
      "Epoch 3117/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.5550 - val_loss: 71.8487\n",
      "Epoch 3118/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 4.3935 - val_loss: 79.5642\n",
      "Epoch 3119/5000\n",
      "1063/1063 [==============================] - 0s 134us/step - loss: 4.4519 - val_loss: 72.1539\n",
      "Epoch 3120/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.4293 - val_loss: 71.2736\n",
      "Epoch 3121/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.4297 - val_loss: 74.5190\n",
      "Epoch 3122/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.7682 - val_loss: 76.2687\n",
      "Epoch 3123/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.3994 - val_loss: 66.9159\n",
      "Epoch 3124/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5548 - val_loss: 69.5584\n",
      "Epoch 3125/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.4808 - val_loss: 75.8174\n",
      "Epoch 3126/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.0032 - val_loss: 84.9528\n",
      "Epoch 3127/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9989 - val_loss: 74.3712\n",
      "Epoch 3128/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.2659 - val_loss: 72.6098\n",
      "Epoch 3129/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.5265 - val_loss: 73.8351\n",
      "Epoch 3130/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6388 - val_loss: 66.5663\n",
      "Epoch 3131/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.3263 - val_loss: 69.1161\n",
      "Epoch 3132/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6731 - val_loss: 64.1766\n",
      "Epoch 3133/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.2031 - val_loss: 71.8006\n",
      "Epoch 3134/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7611 - val_loss: 80.1337\n",
      "Epoch 3135/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9075 - val_loss: 76.0335\n",
      "Epoch 3136/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4783 - val_loss: 78.5040\n",
      "Epoch 3137/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.4496 - val_loss: 66.7909\n",
      "Epoch 3138/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4342 - val_loss: 71.8293\n",
      "Epoch 3139/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5996 - val_loss: 65.0193\n",
      "Epoch 3140/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7398 - val_loss: 75.3063\n",
      "Epoch 3141/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4038 - val_loss: 68.4181\n",
      "Epoch 3142/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.7638 - val_loss: 69.9638\n",
      "Epoch 3143/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6876 - val_loss: 77.3096\n",
      "Epoch 3144/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6395 - val_loss: 67.1167\n",
      "Epoch 3145/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5587 - val_loss: 71.9572\n",
      "Epoch 3146/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6395 - val_loss: 72.9129\n",
      "Epoch 3147/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7045 - val_loss: 71.3772\n",
      "Epoch 3148/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.2960 - val_loss: 69.1083\n",
      "Epoch 3149/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.5673 - val_loss: 69.4897\n",
      "Epoch 3150/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.3863 - val_loss: 71.2565\n",
      "Epoch 3151/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4842 - val_loss: 72.5385\n",
      "Epoch 3152/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.2174 - val_loss: 81.6176\n",
      "Epoch 3153/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5207 - val_loss: 73.8395\n",
      "Epoch 3154/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3700 - val_loss: 75.9593\n",
      "Epoch 3155/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.4878 - val_loss: 78.4249\n",
      "Epoch 3156/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5751 - val_loss: 65.5247\n",
      "Epoch 3157/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.4069 - val_loss: 65.8820\n",
      "Epoch 3158/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.3060 - val_loss: 72.6588\n",
      "Epoch 3159/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.7776 - val_loss: 69.6753\n",
      "Epoch 3160/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.4877 - val_loss: 70.2256\n",
      "Epoch 3161/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.1578 - val_loss: 73.3498\n",
      "Epoch 3162/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4738 - val_loss: 70.8247\n",
      "Epoch 3163/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7314 - val_loss: 69.1463\n",
      "Epoch 3164/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.7669 - val_loss: 82.6327\n",
      "Epoch 3165/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.6423 - val_loss: 69.7574\n",
      "Epoch 3166/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.2477 - val_loss: 71.2563\n",
      "Epoch 3167/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6337 - val_loss: 70.3824\n",
      "Epoch 3168/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.4541 - val_loss: 69.3224\n",
      "Epoch 3169/5000\n",
      "1063/1063 [==============================] - 0s 121us/step - loss: 4.6234 - val_loss: 67.2010\n",
      "Epoch 3170/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5140 - val_loss: 71.0535\n",
      "Epoch 3171/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.9877 - val_loss: 68.6231\n",
      "Epoch 3172/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4412 - val_loss: 68.6031\n",
      "Epoch 3173/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5398 - val_loss: 69.2472\n",
      "Epoch 3174/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.7212 - val_loss: 85.0031\n",
      "Epoch 3175/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.8136 - val_loss: 82.0343\n",
      "Epoch 3176/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5156 - val_loss: 71.5883\n",
      "Epoch 3177/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6665 - val_loss: 68.5157\n",
      "Epoch 3178/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4916 - val_loss: 70.2902\n",
      "Epoch 3179/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.4250 - val_loss: 75.4253\n",
      "Epoch 3180/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4822 - val_loss: 76.2992\n",
      "Epoch 3181/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.1933 - val_loss: 69.7527\n",
      "Epoch 3182/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5915 - val_loss: 78.1886\n",
      "Epoch 3183/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6087 - val_loss: 65.2563\n",
      "Epoch 3184/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.8875 - val_loss: 85.7084\n",
      "Epoch 3185/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.1630 - val_loss: 79.7670\n",
      "Epoch 3186/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.0081 - val_loss: 67.4369\n",
      "Epoch 3187/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3833 - val_loss: 64.2332\n",
      "Epoch 3188/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7818 - val_loss: 66.9746\n",
      "Epoch 3189/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.4372 - val_loss: 66.9436\n",
      "Epoch 3190/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5263 - val_loss: 73.5884\n",
      "Epoch 3191/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.0013 - val_loss: 71.2130\n",
      "Epoch 3192/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.3937 - val_loss: 68.6814\n",
      "Epoch 3193/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.3482 - val_loss: 70.8424\n",
      "Epoch 3194/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.8134 - val_loss: 70.1403\n",
      "Epoch 3195/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5254 - val_loss: 75.7023\n",
      "Epoch 3196/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.0380 - val_loss: 77.8378\n",
      "Epoch 3197/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7646 - val_loss: 73.8367\n",
      "Epoch 3198/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.7830 - val_loss: 66.2915\n",
      "Epoch 3199/5000\n",
      "1063/1063 [==============================] - 0s 130us/step - loss: 4.9296 - val_loss: 71.7820\n",
      "Epoch 3200/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.5572 - val_loss: 80.1945\n",
      "Epoch 3201/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.4251 - val_loss: 77.6865\n",
      "Epoch 3202/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7234 - val_loss: 80.5602\n",
      "Epoch 3203/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.8259 - val_loss: 71.3532\n",
      "Epoch 3204/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.6975 - val_loss: 81.4723\n",
      "Epoch 3205/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4390 - val_loss: 70.6181\n",
      "Epoch 3206/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.3962 - val_loss: 69.3096\n",
      "Epoch 3207/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.5839 - val_loss: 73.6112\n",
      "Epoch 3208/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 4.5197 - val_loss: 72.4764\n",
      "Epoch 3209/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.2772 - val_loss: 72.1841\n",
      "Epoch 3210/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.1004 - val_loss: 65.0547\n",
      "Epoch 3211/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.8241 - val_loss: 75.9637\n",
      "Epoch 3212/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.3594 - val_loss: 78.3940\n",
      "Epoch 3213/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.6174 - val_loss: 73.2287\n",
      "Epoch 3214/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5103 - val_loss: 81.0097\n",
      "Epoch 3215/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6710 - val_loss: 72.5789\n",
      "Epoch 3216/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.2615 - val_loss: 75.1865\n",
      "Epoch 3217/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3433 - val_loss: 78.4253\n",
      "Epoch 3218/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.7590 - val_loss: 69.6396\n",
      "Epoch 3219/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.1702 - val_loss: 71.0197\n",
      "Epoch 3220/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 5.0266 - val_loss: 69.9939\n",
      "Epoch 3221/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.1447 - val_loss: 78.3157\n",
      "Epoch 3222/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5649 - val_loss: 72.0981\n",
      "Epoch 3223/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6253 - val_loss: 71.2113\n",
      "Epoch 3224/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4525 - val_loss: 72.0200\n",
      "Epoch 3225/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.3568 - val_loss: 71.0000\n",
      "Epoch 3226/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.3174 - val_loss: 77.1990\n",
      "Epoch 3227/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5241 - val_loss: 73.5504\n",
      "Epoch 3228/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.5214 - val_loss: 72.9326\n",
      "Epoch 3229/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.8035 - val_loss: 71.8331\n",
      "Epoch 3230/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.3030 - val_loss: 70.1110\n",
      "Epoch 3231/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.2339 - val_loss: 70.2347\n",
      "Epoch 3232/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5471 - val_loss: 81.0599\n",
      "Epoch 3233/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 5.3381 - val_loss: 60.5696\n",
      "Epoch 3234/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.8779 - val_loss: 75.6745\n",
      "Epoch 3235/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.3536 - val_loss: 69.1511\n",
      "Epoch 3236/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.9110 - val_loss: 81.2601\n",
      "Epoch 3237/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 4.5373 - val_loss: 71.8129\n",
      "Epoch 3238/5000\n",
      "1063/1063 [==============================] - 0s 122us/step - loss: 4.7021 - val_loss: 78.6644\n",
      "Epoch 3239/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.6078 - val_loss: 69.2667\n",
      "Epoch 3240/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.4959 - val_loss: 69.8233\n",
      "Epoch 3241/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.6479 - val_loss: 76.3856\n",
      "Epoch 3242/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.2991 - val_loss: 68.6744\n",
      "Epoch 3243/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.5624 - val_loss: 69.9978\n",
      "Epoch 3244/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.5735 - val_loss: 70.0580\n",
      "Epoch 3245/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.5117 - val_loss: 74.1772\n",
      "Epoch 3246/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.5531 - val_loss: 68.9124\n",
      "Epoch 3247/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.2044 - val_loss: 67.3269\n",
      "Epoch 3248/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.2325 - val_loss: 76.5485\n",
      "Epoch 3249/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.4264 - val_loss: 80.7043\n",
      "Epoch 3250/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.7961 - val_loss: 75.2841\n",
      "Epoch 3251/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.5401 - val_loss: 65.4032\n",
      "Epoch 3252/5000\n",
      "1063/1063 [==============================] - 0s 126us/step - loss: 4.8066 - val_loss: 70.3290\n",
      "Epoch 3253/5000\n",
      "1063/1063 [==============================] - 0s 130us/step - loss: 4.5350 - val_loss: 83.9418\n",
      "Epoch 3254/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.8229 - val_loss: 78.6189\n",
      "Epoch 3255/5000\n",
      "1063/1063 [==============================] - 0s 132us/step - loss: 4.6438 - val_loss: 75.5676\n",
      "Epoch 3256/5000\n",
      "1063/1063 [==============================] - 0s 122us/step - loss: 4.7733 - val_loss: 74.6771\n",
      "Epoch 3257/5000\n",
      "1063/1063 [==============================] - 0s 161us/step - loss: 4.7310 - val_loss: 69.8487\n",
      "Epoch 3258/5000\n",
      "1063/1063 [==============================] - 0s 127us/step - loss: 4.5637 - val_loss: 70.0853\n",
      "Epoch 3259/5000\n",
      "1063/1063 [==============================] - 0s 126us/step - loss: 4.4426 - val_loss: 69.8076\n",
      "Epoch 3260/5000\n",
      "1063/1063 [==============================] - 0s 169us/step - loss: 4.6206 - val_loss: 77.8721\n",
      "Epoch 3261/5000\n",
      "1063/1063 [==============================] - 0s 134us/step - loss: 4.4747 - val_loss: 70.4365\n",
      "Epoch 3262/5000\n",
      "1063/1063 [==============================] - 0s 172us/step - loss: 4.4747 - val_loss: 68.8450\n",
      "Epoch 3263/5000\n",
      "1063/1063 [==============================] - 0s 120us/step - loss: 4.7090 - val_loss: 74.6879\n",
      "Epoch 3264/5000\n",
      "1063/1063 [==============================] - 0s 135us/step - loss: 4.5522 - val_loss: 70.7813\n",
      "Epoch 3265/5000\n",
      "1063/1063 [==============================] - 0s 150us/step - loss: 4.4200 - val_loss: 71.5927\n",
      "Epoch 3266/5000\n",
      "1063/1063 [==============================] - 0s 150us/step - loss: 4.7231 - val_loss: 79.3466\n",
      "Epoch 3267/5000\n",
      "1063/1063 [==============================] - 0s 123us/step - loss: 4.5167 - val_loss: 81.9850\n",
      "Epoch 3268/5000\n",
      "1063/1063 [==============================] - 0s 142us/step - loss: 4.9876 - val_loss: 70.4439\n",
      "Epoch 3269/5000\n",
      "1063/1063 [==============================] - 0s 164us/step - loss: 4.4047 - val_loss: 77.2320\n",
      "Epoch 3270/5000\n",
      "1063/1063 [==============================] - 0s 138us/step - loss: 4.5160 - val_loss: 84.7297\n",
      "Epoch 3271/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 5.1594 - val_loss: 72.9210\n",
      "Epoch 3272/5000\n",
      "1063/1063 [==============================] - 0s 138us/step - loss: 4.5073 - val_loss: 82.5959\n",
      "Epoch 3273/5000\n",
      "1063/1063 [==============================] - 0s 152us/step - loss: 4.6130 - val_loss: 67.9176\n",
      "Epoch 3274/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 4.3239 - val_loss: 71.6459\n",
      "Epoch 3275/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.4874 - val_loss: 67.3221\n",
      "Epoch 3276/5000\n",
      "1063/1063 [==============================] - 0s 135us/step - loss: 5.3123 - val_loss: 73.3920\n",
      "Epoch 3277/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.7155 - val_loss: 66.9680\n",
      "Epoch 3278/5000\n",
      "1063/1063 [==============================] - 0s 129us/step - loss: 5.0092 - val_loss: 78.2798\n",
      "Epoch 3279/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.5237 - val_loss: 76.9715\n",
      "Epoch 3280/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.7315 - val_loss: 73.4436\n",
      "Epoch 3281/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.5722 - val_loss: 67.4455\n",
      "Epoch 3282/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.8341 - val_loss: 74.9380\n",
      "Epoch 3283/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.5400 - val_loss: 80.3166\n",
      "Epoch 3284/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.6654 - val_loss: 71.6911\n",
      "Epoch 3285/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 4.8324 - val_loss: 68.0369\n",
      "Epoch 3286/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.7791 - val_loss: 64.9431\n",
      "Epoch 3287/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.6523 - val_loss: 71.7069\n",
      "Epoch 3288/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.4125 - val_loss: 74.1394\n",
      "Epoch 3289/5000\n",
      "1063/1063 [==============================] - 0s 117us/step - loss: 4.9478 - val_loss: 78.5299\n",
      "Epoch 3290/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.6404 - val_loss: 70.1708\n",
      "Epoch 3291/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.3674 - val_loss: 72.1631\n",
      "Epoch 3292/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5304 - val_loss: 80.0664\n",
      "Epoch 3293/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 4.3385 - val_loss: 69.1912\n",
      "Epoch 3294/5000\n",
      "1063/1063 [==============================] - 0s 129us/step - loss: 4.6199 - val_loss: 72.6966\n",
      "Epoch 3295/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.5896 - val_loss: 73.5049\n",
      "Epoch 3296/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.7774 - val_loss: 76.3959\n",
      "Epoch 3297/5000\n",
      "1063/1063 [==============================] - 0s 117us/step - loss: 4.5276 - val_loss: 74.5710\n",
      "Epoch 3298/5000\n",
      "1063/1063 [==============================] - 0s 134us/step - loss: 4.2893 - val_loss: 70.9886\n",
      "Epoch 3299/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.2932 - val_loss: 78.2930\n",
      "Epoch 3300/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.3786 - val_loss: 77.6726\n",
      "Epoch 3301/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.2860 - val_loss: 70.4333\n",
      "Epoch 3302/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.7503 - val_loss: 72.7564\n",
      "Epoch 3303/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.4474 - val_loss: 71.8653\n",
      "Epoch 3304/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.6822 - val_loss: 75.9642\n",
      "Epoch 3305/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.6334 - val_loss: 63.5947\n",
      "Epoch 3306/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.8337 - val_loss: 69.8690\n",
      "Epoch 3307/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.6812 - val_loss: 71.9136\n",
      "Epoch 3308/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.6116 - val_loss: 75.3936\n",
      "Epoch 3309/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.6242 - val_loss: 73.2849\n",
      "Epoch 3310/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.4411 - val_loss: 66.1578\n",
      "Epoch 3311/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.3933 - val_loss: 75.1532\n",
      "Epoch 3312/5000\n",
      "1063/1063 [==============================] - 0s 120us/step - loss: 4.4758 - val_loss: 81.8784\n",
      "Epoch 3313/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.7717 - val_loss: 70.9510\n",
      "Epoch 3314/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.5689 - val_loss: 73.6657\n",
      "Epoch 3315/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8086 - val_loss: 80.9413\n",
      "Epoch 3316/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6954 - val_loss: 68.1435\n",
      "Epoch 3317/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.6848 - val_loss: 76.2151\n",
      "Epoch 3318/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.4666 - val_loss: 71.6449\n",
      "Epoch 3319/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.4155 - val_loss: 69.7037\n",
      "Epoch 3320/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.8849 - val_loss: 69.4950\n",
      "Epoch 3321/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.7302 - val_loss: 68.4101\n",
      "Epoch 3322/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.6812 - val_loss: 72.8999\n",
      "Epoch 3323/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.2605 - val_loss: 75.1955\n",
      "Epoch 3324/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.8208 - val_loss: 71.8533\n",
      "Epoch 3325/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6235 - val_loss: 65.6735\n",
      "Epoch 3326/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7182 - val_loss: 75.7894\n",
      "Epoch 3327/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.6401 - val_loss: 80.3486\n",
      "Epoch 3328/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5110 - val_loss: 78.9392\n",
      "Epoch 3329/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5532 - val_loss: 68.8815\n",
      "Epoch 3330/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5364 - val_loss: 66.7151\n",
      "Epoch 3331/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 5.1114 - val_loss: 74.3522\n",
      "Epoch 3332/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.7391 - val_loss: 71.3020\n",
      "Epoch 3333/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 4.1933 - val_loss: 71.6847\n",
      "Epoch 3334/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.3023 - val_loss: 85.6762\n",
      "Epoch 3335/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.6362 - val_loss: 73.3875\n",
      "Epoch 3336/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.7877 - val_loss: 68.7897\n",
      "Epoch 3337/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.4383 - val_loss: 69.2378\n",
      "Epoch 3338/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.8543 - val_loss: 75.1456\n",
      "Epoch 3339/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.9183 - val_loss: 73.7891\n",
      "Epoch 3340/5000\n",
      "1063/1063 [==============================] - 0s 132us/step - loss: 4.3942 - val_loss: 63.9822\n",
      "Epoch 3341/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4636 - val_loss: 71.8498\n",
      "Epoch 3342/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4765 - val_loss: 70.3653\n",
      "Epoch 3343/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5118 - val_loss: 68.2763\n",
      "Epoch 3344/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.0789 - val_loss: 67.5977\n",
      "Epoch 3345/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.8154 - val_loss: 71.1073\n",
      "Epoch 3346/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.7898 - val_loss: 73.6411\n",
      "Epoch 3347/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4600 - val_loss: 70.7144\n",
      "Epoch 3348/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.3934 - val_loss: 69.5080\n",
      "Epoch 3349/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 5.1834 - val_loss: 69.3489\n",
      "Epoch 3350/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.6535 - val_loss: 64.5308\n",
      "Epoch 3351/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.3364 - val_loss: 71.9671\n",
      "Epoch 3352/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.3816 - val_loss: 67.2881\n",
      "Epoch 3353/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6860 - val_loss: 67.7174\n",
      "Epoch 3354/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.3227 - val_loss: 68.1455\n",
      "Epoch 3355/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 6.0323 - val_loss: 78.3974\n",
      "Epoch 3356/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5070 - val_loss: 69.7079\n",
      "Epoch 3357/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.7795 - val_loss: 77.7116\n",
      "Epoch 3358/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4590 - val_loss: 74.1892\n",
      "Epoch 3359/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.5934 - val_loss: 73.3791\n",
      "Epoch 3360/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.5206 - val_loss: 69.8384\n",
      "Epoch 3361/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6463 - val_loss: 74.5097\n",
      "Epoch 3362/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6496 - val_loss: 74.0836\n",
      "Epoch 3363/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.3059 - val_loss: 69.0825\n",
      "Epoch 3364/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5134 - val_loss: 72.6025\n",
      "Epoch 3365/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5366 - val_loss: 81.2688\n",
      "Epoch 3366/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8632 - val_loss: 72.8238\n",
      "Epoch 3367/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5332 - val_loss: 71.0554\n",
      "Epoch 3368/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6170 - val_loss: 70.4023\n",
      "Epoch 3369/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.5096 - val_loss: 72.7719\n",
      "Epoch 3370/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.5624 - val_loss: 86.2559\n",
      "Epoch 3371/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.1253 - val_loss: 78.4231\n",
      "Epoch 3372/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.3221 - val_loss: 64.9102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3373/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.9013 - val_loss: 69.2175\n",
      "Epoch 3374/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.8607 - val_loss: 81.6466\n",
      "Epoch 3375/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5575 - val_loss: 68.9211\n",
      "Epoch 3376/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7063 - val_loss: 73.7980\n",
      "Epoch 3377/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5474 - val_loss: 66.6756\n",
      "Epoch 3378/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5345 - val_loss: 78.7562\n",
      "Epoch 3379/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.7474 - val_loss: 69.1713\n",
      "Epoch 3380/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.2928 - val_loss: 74.6797\n",
      "Epoch 3381/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.3939 - val_loss: 71.9378\n",
      "Epoch 3382/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.6802 - val_loss: 69.4617\n",
      "Epoch 3383/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5126 - val_loss: 84.4832\n",
      "Epoch 3384/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.8885 - val_loss: 75.3522\n",
      "Epoch 3385/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.9745 - val_loss: 69.7779\n",
      "Epoch 3386/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.9553 - val_loss: 69.3954\n",
      "Epoch 3387/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.3348 - val_loss: 73.0243\n",
      "Epoch 3388/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.2870 - val_loss: 67.2460\n",
      "Epoch 3389/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.5901 - val_loss: 73.5726\n",
      "Epoch 3390/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.6906 - val_loss: 66.5228\n",
      "Epoch 3391/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.3997 - val_loss: 71.8830\n",
      "Epoch 3392/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.5507 - val_loss: 72.5894\n",
      "Epoch 3393/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.3470 - val_loss: 69.1023\n",
      "Epoch 3394/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.9389 - val_loss: 74.5256\n",
      "Epoch 3395/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.5891 - val_loss: 75.8377\n",
      "Epoch 3396/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.7432 - val_loss: 70.1776\n",
      "Epoch 3397/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.4405 - val_loss: 72.1001\n",
      "Epoch 3398/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.9834 - val_loss: 72.6644\n",
      "Epoch 3399/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.5215 - val_loss: 73.7798\n",
      "Epoch 3400/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5862 - val_loss: 66.5162\n",
      "Epoch 3401/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.9564 - val_loss: 60.5029\n",
      "Epoch 3402/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.6842 - val_loss: 70.2469\n",
      "Epoch 3403/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.5062 - val_loss: 65.4722\n",
      "Epoch 3404/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.3966 - val_loss: 76.2086\n",
      "Epoch 3405/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.4446 - val_loss: 78.9508\n",
      "Epoch 3406/5000\n",
      "1063/1063 [==============================] - 0s 131us/step - loss: 4.7244 - val_loss: 70.2273\n",
      "Epoch 3407/5000\n",
      "1063/1063 [==============================] - 0s 117us/step - loss: 4.5089 - val_loss: 68.7823\n",
      "Epoch 3408/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.6025 - val_loss: 73.7808\n",
      "Epoch 3409/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.4036 - val_loss: 74.2347\n",
      "Epoch 3410/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.5092 - val_loss: 71.1463\n",
      "Epoch 3411/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.6864 - val_loss: 70.1679\n",
      "Epoch 3412/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.6951 - val_loss: 69.3103\n",
      "Epoch 3413/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.4835 - val_loss: 76.0789\n",
      "Epoch 3414/5000\n",
      "1063/1063 [==============================] - 0s 119us/step - loss: 4.2931 - val_loss: 81.8583\n",
      "Epoch 3415/5000\n",
      "1063/1063 [==============================] - 0s 136us/step - loss: 4.7667 - val_loss: 69.0721\n",
      "Epoch 3416/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.2346 - val_loss: 71.4050\n",
      "Epoch 3417/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.3867 - val_loss: 81.4791\n",
      "Epoch 3418/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.6922 - val_loss: 71.2412\n",
      "Epoch 3419/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4020 - val_loss: 70.4689\n",
      "Epoch 3420/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.2611 - val_loss: 77.1392\n",
      "Epoch 3421/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.4826 - val_loss: 67.9495\n",
      "Epoch 3422/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.8736 - val_loss: 69.7466\n",
      "Epoch 3423/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.7604 - val_loss: 68.3186\n",
      "Epoch 3424/5000\n",
      "1063/1063 [==============================] - 0s 135us/step - loss: 4.2717 - val_loss: 68.0647\n",
      "Epoch 3425/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.5647 - val_loss: 74.3248\n",
      "Epoch 3426/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.7177 - val_loss: 60.4722\n",
      "Epoch 3427/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.7979 - val_loss: 69.3511\n",
      "Epoch 3428/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5323 - val_loss: 78.9389\n",
      "Epoch 3429/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6183 - val_loss: 67.7054\n",
      "Epoch 3430/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8017 - val_loss: 70.0920\n",
      "Epoch 3431/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4843 - val_loss: 74.1158\n",
      "Epoch 3432/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.6233 - val_loss: 83.8607\n",
      "Epoch 3433/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.8008 - val_loss: 72.9617\n",
      "Epoch 3434/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.7246 - val_loss: 78.6535\n",
      "Epoch 3435/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.2464 - val_loss: 66.8586\n",
      "Epoch 3436/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.3355 - val_loss: 63.8911\n",
      "Epoch 3437/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 5.5468 - val_loss: 71.1645\n",
      "Epoch 3438/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6888 - val_loss: 71.1684\n",
      "Epoch 3439/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6571 - val_loss: 71.2639\n",
      "Epoch 3440/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6370 - val_loss: 67.6018\n",
      "Epoch 3441/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.3828 - val_loss: 76.9853\n",
      "Epoch 3442/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5727 - val_loss: 69.9101\n",
      "Epoch 3443/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5516 - val_loss: 69.3990\n",
      "Epoch 3444/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5129 - val_loss: 69.9364\n",
      "Epoch 3445/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.1925 - val_loss: 68.1493\n",
      "Epoch 3446/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.8279 - val_loss: 67.8866\n",
      "Epoch 3447/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5311 - val_loss: 69.8914\n",
      "Epoch 3448/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4224 - val_loss: 80.6558\n",
      "Epoch 3449/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8900 - val_loss: 65.1127\n",
      "Epoch 3450/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6840 - val_loss: 72.3474\n",
      "Epoch 3451/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4572 - val_loss: 61.7987\n",
      "Epoch 3452/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.9353 - val_loss: 69.2790\n",
      "Epoch 3453/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5613 - val_loss: 84.6238\n",
      "Epoch 3454/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.9254 - val_loss: 72.4621\n",
      "Epoch 3455/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3577 - val_loss: 72.5699\n",
      "Epoch 3456/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9021 - val_loss: 67.8090\n",
      "Epoch 3457/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9078 - val_loss: 66.2195\n",
      "Epoch 3458/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6782 - val_loss: 71.9018\n",
      "Epoch 3459/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5744 - val_loss: 75.5410\n",
      "Epoch 3460/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9251 - val_loss: 68.1715\n",
      "Epoch 3461/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5128 - val_loss: 75.7014\n",
      "Epoch 3462/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.3956 - val_loss: 71.9390\n",
      "Epoch 3463/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.4382 - val_loss: 70.3575\n",
      "Epoch 3464/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.5160 - val_loss: 71.8156\n",
      "Epoch 3465/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.4891 - val_loss: 76.9751\n",
      "Epoch 3466/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.2897 - val_loss: 69.3157\n",
      "Epoch 3467/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3443 - val_loss: 74.7092\n",
      "Epoch 3468/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5433 - val_loss: 75.0243\n",
      "Epoch 3469/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3886 - val_loss: 73.1424\n",
      "Epoch 3470/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6568 - val_loss: 75.2821\n",
      "Epoch 3471/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.3962 - val_loss: 65.6344\n",
      "Epoch 3472/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.8210 - val_loss: 66.2412\n",
      "Epoch 3473/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.2056 - val_loss: 71.8566\n",
      "Epoch 3474/5000\n",
      "1063/1063 [==============================] - 0s 117us/step - loss: 4.3700 - val_loss: 71.7854\n",
      "Epoch 3475/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.6467 - val_loss: 81.3719\n",
      "Epoch 3476/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.5820 - val_loss: 72.7959\n",
      "Epoch 3477/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.2906 - val_loss: 73.8413\n",
      "Epoch 3478/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.9749 - val_loss: 75.9845\n",
      "Epoch 3479/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.3984 - val_loss: 71.2046\n",
      "Epoch 3480/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6160 - val_loss: 74.9372\n",
      "Epoch 3481/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6749 - val_loss: 69.8449\n",
      "Epoch 3482/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.3574 - val_loss: 75.0063\n",
      "Epoch 3483/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.3325 - val_loss: 72.1285\n",
      "Epoch 3484/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.2277 - val_loss: 78.8227\n",
      "Epoch 3485/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.3011 - val_loss: 69.0768\n",
      "Epoch 3486/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.4302 - val_loss: 73.3060\n",
      "Epoch 3487/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.4906 - val_loss: 73.4617\n",
      "Epoch 3488/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.8198 - val_loss: 66.5851\n",
      "Epoch 3489/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.9892 - val_loss: 68.8780\n",
      "Epoch 3490/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5863 - val_loss: 72.3750\n",
      "Epoch 3491/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5995 - val_loss: 68.4670\n",
      "Epoch 3492/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5766 - val_loss: 75.0764\n",
      "Epoch 3493/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.5582 - val_loss: 75.7484\n",
      "Epoch 3494/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4214 - val_loss: 79.0583\n",
      "Epoch 3495/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8636 - val_loss: 77.3442\n",
      "Epoch 3496/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8118 - val_loss: 69.2616\n",
      "Epoch 3497/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.4970 - val_loss: 75.6425\n",
      "Epoch 3498/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.3536 - val_loss: 74.4637\n",
      "Epoch 3499/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5989 - val_loss: 73.2787\n",
      "Epoch 3500/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5763 - val_loss: 71.2819\n",
      "Epoch 3501/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5446 - val_loss: 70.3713\n",
      "Epoch 3502/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.3287 - val_loss: 70.2519\n",
      "Epoch 3503/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.6185 - val_loss: 75.5991\n",
      "Epoch 3504/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4800 - val_loss: 75.7917\n",
      "Epoch 3505/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.0277 - val_loss: 84.2369\n",
      "Epoch 3506/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5916 - val_loss: 68.2711\n",
      "Epoch 3507/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4457 - val_loss: 72.3850\n",
      "Epoch 3508/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4279 - val_loss: 72.0771\n",
      "Epoch 3509/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.5058 - val_loss: 78.6236\n",
      "Epoch 3510/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.4450 - val_loss: 75.9643\n",
      "Epoch 3511/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.5221 - val_loss: 63.1886\n",
      "Epoch 3512/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5463 - val_loss: 73.6231\n",
      "Epoch 3513/5000\n",
      "1063/1063 [==============================] - 0s 124us/step - loss: 4.6537 - val_loss: 68.9833\n",
      "Epoch 3514/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.5195 - val_loss: 67.8851\n",
      "Epoch 3515/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4302 - val_loss: 71.9607\n",
      "Epoch 3516/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.6140 - val_loss: 73.4521\n",
      "Epoch 3517/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.5787 - val_loss: 70.7187\n",
      "Epoch 3518/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.9197 - val_loss: 66.9133\n",
      "Epoch 3519/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.4711 - val_loss: 72.9836\n",
      "Epoch 3520/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.5794 - val_loss: 74.4197\n",
      "Epoch 3521/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.6874 - val_loss: 79.2316\n",
      "Epoch 3522/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 120us/step - loss: 4.5022 - val_loss: 68.8166\n",
      "Epoch 3523/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.3556 - val_loss: 66.9670\n",
      "Epoch 3524/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6907 - val_loss: 76.2159\n",
      "Epoch 3525/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.3926 - val_loss: 75.8356\n",
      "Epoch 3526/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6721 - val_loss: 71.4602\n",
      "Epoch 3527/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6192 - val_loss: 65.9238\n",
      "Epoch 3528/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6481 - val_loss: 75.9851\n",
      "Epoch 3529/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.1150 - val_loss: 71.9974\n",
      "Epoch 3530/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4103 - val_loss: 73.0410\n",
      "Epoch 3531/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.3969 - val_loss: 76.4981\n",
      "Epoch 3532/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.3584 - val_loss: 76.8234\n",
      "Epoch 3533/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.3460 - val_loss: 72.0013\n",
      "Epoch 3534/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4038 - val_loss: 75.2512\n",
      "Epoch 3535/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3827 - val_loss: 72.4088\n",
      "Epoch 3536/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.3459 - val_loss: 69.2029\n",
      "Epoch 3537/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4717 - val_loss: 71.5122\n",
      "Epoch 3538/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7692 - val_loss: 70.5459\n",
      "Epoch 3539/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6248 - val_loss: 69.3628\n",
      "Epoch 3540/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.3311 - val_loss: 77.6949\n",
      "Epoch 3541/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.4933 - val_loss: 76.2654\n",
      "Epoch 3542/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.4836 - val_loss: 73.2229\n",
      "Epoch 3543/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.8764 - val_loss: 75.8258\n",
      "Epoch 3544/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.5305 - val_loss: 77.7603\n",
      "Epoch 3545/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.4756 - val_loss: 74.9555\n",
      "Epoch 3546/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.7686 - val_loss: 72.7194\n",
      "Epoch 3547/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.4316 - val_loss: 77.4237\n",
      "Epoch 3548/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.4624 - val_loss: 72.0330\n",
      "Epoch 3549/5000\n",
      "1063/1063 [==============================] - 0s 117us/step - loss: 4.5937 - val_loss: 61.8161\n",
      "Epoch 3550/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 5.1442 - val_loss: 82.7766\n",
      "Epoch 3551/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.6995 - val_loss: 75.1446\n",
      "Epoch 3552/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.4650 - val_loss: 73.7356\n",
      "Epoch 3553/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.4594 - val_loss: 70.9826\n",
      "Epoch 3554/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.3986 - val_loss: 69.4712\n",
      "Epoch 3555/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.4559 - val_loss: 65.5437\n",
      "Epoch 3556/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.8930 - val_loss: 65.4955\n",
      "Epoch 3557/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.9680 - val_loss: 73.2338\n",
      "Epoch 3558/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.4431 - val_loss: 72.6896\n",
      "Epoch 3559/5000\n",
      "1063/1063 [==============================] - 0s 134us/step - loss: 4.3933 - val_loss: 79.8516\n",
      "Epoch 3560/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.7484 - val_loss: 71.4536\n",
      "Epoch 3561/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.5640 - val_loss: 69.1207\n",
      "Epoch 3562/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.8363 - val_loss: 65.9218\n",
      "Epoch 3563/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.6612 - val_loss: 79.7221\n",
      "Epoch 3564/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.8330 - val_loss: 67.1063\n",
      "Epoch 3565/5000\n",
      "1063/1063 [==============================] - 0s 124us/step - loss: 4.4858 - val_loss: 78.4751\n",
      "Epoch 3566/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.9645 - val_loss: 73.2740\n",
      "Epoch 3567/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.8505 - val_loss: 73.9180\n",
      "Epoch 3568/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.8005 - val_loss: 74.2136\n",
      "Epoch 3569/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.3757 - val_loss: 71.9286\n",
      "Epoch 3570/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.4586 - val_loss: 68.9575\n",
      "Epoch 3571/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.7043 - val_loss: 70.9433\n",
      "Epoch 3572/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4637 - val_loss: 71.9056\n",
      "Epoch 3573/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.4131 - val_loss: 72.6880\n",
      "Epoch 3574/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5884 - val_loss: 72.2938\n",
      "Epoch 3575/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4866 - val_loss: 72.8138\n",
      "Epoch 3576/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5230 - val_loss: 68.8953\n",
      "Epoch 3577/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.6654 - val_loss: 77.3232\n",
      "Epoch 3578/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5741 - val_loss: 68.4963\n",
      "Epoch 3579/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.3237 - val_loss: 70.6053\n",
      "Epoch 3580/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.9744 - val_loss: 65.2944\n",
      "Epoch 3581/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6454 - val_loss: 72.1642\n",
      "Epoch 3582/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.2714 - val_loss: 74.8050\n",
      "Epoch 3583/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.9694 - val_loss: 73.4560\n",
      "Epoch 3584/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.9481 - val_loss: 67.2642\n",
      "Epoch 3585/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7773 - val_loss: 68.9240\n",
      "Epoch 3586/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.4701 - val_loss: 72.4556\n",
      "Epoch 3587/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.3381 - val_loss: 70.6458\n",
      "Epoch 3588/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.3912 - val_loss: 68.3689\n",
      "Epoch 3589/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.3065 - val_loss: 64.1839\n",
      "Epoch 3590/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5518 - val_loss: 68.8166\n",
      "Epoch 3591/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.3251 - val_loss: 68.7522\n",
      "Epoch 3592/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.3231 - val_loss: 71.9027\n",
      "Epoch 3593/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.8305 - val_loss: 75.0648\n",
      "Epoch 3594/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4285 - val_loss: 68.1990\n",
      "Epoch 3595/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.3640 - val_loss: 71.8177\n",
      "Epoch 3596/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5238 - val_loss: 77.0721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3597/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.6723 - val_loss: 80.6384\n",
      "Epoch 3598/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5107 - val_loss: 67.8909\n",
      "Epoch 3599/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5618 - val_loss: 69.8112\n",
      "Epoch 3600/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7670 - val_loss: 75.1773\n",
      "Epoch 3601/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4109 - val_loss: 71.5723\n",
      "Epoch 3602/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.6529 - val_loss: 64.5728\n",
      "Epoch 3603/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.8267 - val_loss: 67.6379\n",
      "Epoch 3604/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.3911 - val_loss: 76.7565\n",
      "Epoch 3605/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5634 - val_loss: 75.9988\n",
      "Epoch 3606/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.4428 - val_loss: 66.2376\n",
      "Epoch 3607/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.6563 - val_loss: 71.7029\n",
      "Epoch 3608/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.5351 - val_loss: 75.1172\n",
      "Epoch 3609/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.2906 - val_loss: 65.5096\n",
      "Epoch 3610/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.5082 - val_loss: 72.5181\n",
      "Epoch 3611/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.2252 - val_loss: 68.3824\n",
      "Epoch 3612/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.4560 - val_loss: 69.0035\n",
      "Epoch 3613/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.6687 - val_loss: 69.7092\n",
      "Epoch 3614/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.5098 - val_loss: 74.3158\n",
      "Epoch 3615/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.8692 - val_loss: 69.6760\n",
      "Epoch 3616/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.4411 - val_loss: 75.9969\n",
      "Epoch 3617/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.4982 - val_loss: 72.3575\n",
      "Epoch 3618/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3068 - val_loss: 69.5701\n",
      "Epoch 3619/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4198 - val_loss: 64.1864\n",
      "Epoch 3620/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.9389 - val_loss: 72.2077\n",
      "Epoch 3621/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.3786 - val_loss: 67.1911\n",
      "Epoch 3622/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.0365 - val_loss: 72.8693\n",
      "Epoch 3623/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3739 - val_loss: 66.1762\n",
      "Epoch 3624/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4442 - val_loss: 72.4781\n",
      "Epoch 3625/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.0745 - val_loss: 71.3578\n",
      "Epoch 3626/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5642 - val_loss: 67.2101\n",
      "Epoch 3627/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.3301 - val_loss: 71.6269\n",
      "Epoch 3628/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5999 - val_loss: 65.7158\n",
      "Epoch 3629/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4571 - val_loss: 69.5874\n",
      "Epoch 3630/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4801 - val_loss: 72.6390\n",
      "Epoch 3631/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4981 - val_loss: 75.7190\n",
      "Epoch 3632/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.3284 - val_loss: 76.3404\n",
      "Epoch 3633/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.2549 - val_loss: 71.2242\n",
      "Epoch 3634/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6257 - val_loss: 65.7722\n",
      "Epoch 3635/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4685 - val_loss: 71.7495\n",
      "Epoch 3636/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.4715 - val_loss: 69.4242\n",
      "Epoch 3637/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4096 - val_loss: 71.0949\n",
      "Epoch 3638/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4697 - val_loss: 66.3801\n",
      "Epoch 3639/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.3981 - val_loss: 70.5127\n",
      "Epoch 3640/5000\n",
      "1063/1063 [==============================] - 0s 119us/step - loss: 4.4484 - val_loss: 74.5067\n",
      "Epoch 3641/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.3225 - val_loss: 76.1576\n",
      "Epoch 3642/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7128 - val_loss: 75.5690\n",
      "Epoch 3643/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.7256 - val_loss: 77.7846\n",
      "Epoch 3644/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6507 - val_loss: 72.4338\n",
      "Epoch 3645/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.3448 - val_loss: 70.1898\n",
      "Epoch 3646/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5957 - val_loss: 71.0019\n",
      "Epoch 3647/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5172 - val_loss: 73.2569\n",
      "Epoch 3648/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6167 - val_loss: 78.9114\n",
      "Epoch 3649/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8223 - val_loss: 70.1548\n",
      "Epoch 3650/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.6367 - val_loss: 83.3392\n",
      "Epoch 3651/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.7075 - val_loss: 69.7116\n",
      "Epoch 3652/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5949 - val_loss: 81.1057\n",
      "Epoch 3653/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.7756 - val_loss: 73.5876\n",
      "Epoch 3654/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7460 - val_loss: 70.2864\n",
      "Epoch 3655/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.8299 - val_loss: 77.1756\n",
      "Epoch 3656/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.5366 - val_loss: 76.3764\n",
      "Epoch 3657/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.5253 - val_loss: 74.4173\n",
      "Epoch 3658/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.0844 - val_loss: 71.2943\n",
      "Epoch 3659/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.9718 - val_loss: 69.3102\n",
      "Epoch 3660/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.3923 - val_loss: 74.0790\n",
      "Epoch 3661/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.1238 - val_loss: 69.9651\n",
      "Epoch 3662/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.2485 - val_loss: 66.1551\n",
      "Epoch 3663/5000\n",
      "1063/1063 [==============================] - 0s 122us/step - loss: 5.2526 - val_loss: 78.9173\n",
      "Epoch 3664/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.5732 - val_loss: 74.6495\n",
      "Epoch 3665/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4017 - val_loss: 69.9745\n",
      "Epoch 3666/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.2939 - val_loss: 75.9237\n",
      "Epoch 3667/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4976 - val_loss: 74.2059\n",
      "Epoch 3668/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4562 - val_loss: 75.3289\n",
      "Epoch 3669/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7714 - val_loss: 66.6278\n",
      "Epoch 3670/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.9663 - val_loss: 72.6100\n",
      "Epoch 3671/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8902 - val_loss: 76.2084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3672/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4363 - val_loss: 75.0093\n",
      "Epoch 3673/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.3293 - val_loss: 70.3374\n",
      "Epoch 3674/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.3341 - val_loss: 67.8637\n",
      "Epoch 3675/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4327 - val_loss: 69.9117\n",
      "Epoch 3676/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.6624 - val_loss: 83.2752\n",
      "Epoch 3677/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.6317 - val_loss: 69.6604\n",
      "Epoch 3678/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5827 - val_loss: 75.5422\n",
      "Epoch 3679/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.3963 - val_loss: 69.2575\n",
      "Epoch 3680/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9859 - val_loss: 82.1391\n",
      "Epoch 3681/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7501 - val_loss: 72.6813\n",
      "Epoch 3682/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.3970 - val_loss: 76.5324\n",
      "Epoch 3683/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4227 - val_loss: 73.9168\n",
      "Epoch 3684/5000\n",
      "1063/1063 [==============================] - 0s 124us/step - loss: 4.6413 - val_loss: 76.9484\n",
      "Epoch 3685/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.5416 - val_loss: 74.9156\n",
      "Epoch 3686/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.6671 - val_loss: 64.1185\n",
      "Epoch 3687/5000\n",
      "1063/1063 [==============================] - 0s 121us/step - loss: 5.0677 - val_loss: 72.1479\n",
      "Epoch 3688/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5403 - val_loss: 78.4416\n",
      "Epoch 3689/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5183 - val_loss: 75.6142\n",
      "Epoch 3690/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.5177 - val_loss: 72.9838\n",
      "Epoch 3691/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.6944 - val_loss: 72.7053\n",
      "Epoch 3692/5000\n",
      "1063/1063 [==============================] - 0s 121us/step - loss: 4.3797 - val_loss: 68.8047\n",
      "Epoch 3693/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.8581 - val_loss: 74.2918\n",
      "Epoch 3694/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.7755 - val_loss: 77.2983\n",
      "Epoch 3695/5000\n",
      "1063/1063 [==============================] - 0s 123us/step - loss: 4.4218 - val_loss: 67.1762\n",
      "Epoch 3696/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.6252 - val_loss: 69.6326\n",
      "Epoch 3697/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 4.6501 - val_loss: 76.6196\n",
      "Epoch 3698/5000\n",
      "1063/1063 [==============================] - 0s 117us/step - loss: 4.5591 - val_loss: 75.9044\n",
      "Epoch 3699/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.2259 - val_loss: 70.3255\n",
      "Epoch 3700/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.7640 - val_loss: 70.4968\n",
      "Epoch 3701/5000\n",
      "1063/1063 [==============================] - 0s 122us/step - loss: 4.6686 - val_loss: 71.3147\n",
      "Epoch 3702/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.6191 - val_loss: 75.9429\n",
      "Epoch 3703/5000\n",
      "1063/1063 [==============================] - 0s 129us/step - loss: 4.2939 - val_loss: 73.7384\n",
      "Epoch 3704/5000\n",
      "1063/1063 [==============================] - 0s 117us/step - loss: 4.4193 - val_loss: 69.8253\n",
      "Epoch 3705/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.3486 - val_loss: 65.6559\n",
      "Epoch 3706/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.4435 - val_loss: 74.8778\n",
      "Epoch 3707/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.6950 - val_loss: 82.9210\n",
      "Epoch 3708/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5219 - val_loss: 71.9523\n",
      "Epoch 3709/5000\n",
      "1063/1063 [==============================] - 0s 122us/step - loss: 4.4466 - val_loss: 73.6435\n",
      "Epoch 3710/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.9629 - val_loss: 71.4888\n",
      "Epoch 3711/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.6104 - val_loss: 63.6826\n",
      "Epoch 3712/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.8657 - val_loss: 70.5247\n",
      "Epoch 3713/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.2995 - val_loss: 72.0641\n",
      "Epoch 3714/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5611 - val_loss: 72.4677\n",
      "Epoch 3715/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4406 - val_loss: 71.0382\n",
      "Epoch 3716/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.8178 - val_loss: 73.2519\n",
      "Epoch 3717/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6375 - val_loss: 66.9426\n",
      "Epoch 3718/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.9882 - val_loss: 79.6692\n",
      "Epoch 3719/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.7812 - val_loss: 68.3212\n",
      "Epoch 3720/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5074 - val_loss: 73.1573\n",
      "Epoch 3721/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.6393 - val_loss: 73.5335\n",
      "Epoch 3722/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4793 - val_loss: 75.3744\n",
      "Epoch 3723/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.4845 - val_loss: 73.2923\n",
      "Epoch 3724/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6965 - val_loss: 72.8803\n",
      "Epoch 3725/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.4848 - val_loss: 70.8158\n",
      "Epoch 3726/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.4831 - val_loss: 66.0362\n",
      "Epoch 3727/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.4057 - val_loss: 71.1203\n",
      "Epoch 3728/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.3907 - val_loss: 72.1400\n",
      "Epoch 3729/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.3375 - val_loss: 69.7521\n",
      "Epoch 3730/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4358 - val_loss: 70.6180\n",
      "Epoch 3731/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.2544 - val_loss: 70.9602\n",
      "Epoch 3732/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.9542 - val_loss: 68.3437\n",
      "Epoch 3733/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3555 - val_loss: 70.1730\n",
      "Epoch 3734/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5000 - val_loss: 66.2998\n",
      "Epoch 3735/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.4857 - val_loss: 72.7569\n",
      "Epoch 3736/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4029 - val_loss: 83.1758\n",
      "Epoch 3737/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5330 - val_loss: 74.0923\n",
      "Epoch 3738/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.2698 - val_loss: 70.8996\n",
      "Epoch 3739/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.3564 - val_loss: 79.3629\n",
      "Epoch 3740/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.3593 - val_loss: 62.6546\n",
      "Epoch 3741/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.0093 - val_loss: 68.7592\n",
      "Epoch 3742/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4160 - val_loss: 69.5765\n",
      "Epoch 3743/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.4711 - val_loss: 73.5298\n",
      "Epoch 3744/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.5703 - val_loss: 76.6730\n",
      "Epoch 3745/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.5385 - val_loss: 82.8305\n",
      "Epoch 3746/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.4235 - val_loss: 73.2969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3747/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.3341 - val_loss: 79.0640\n",
      "Epoch 3748/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.5249 - val_loss: 76.2247\n",
      "Epoch 3749/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.8811 - val_loss: 68.8856\n",
      "Epoch 3750/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.2469 - val_loss: 75.2716\n",
      "Epoch 3751/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.4341 - val_loss: 78.8508\n",
      "Epoch 3752/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.5253 - val_loss: 75.5941\n",
      "Epoch 3753/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4845 - val_loss: 70.0075\n",
      "Epoch 3754/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.8457 - val_loss: 79.7171\n",
      "Epoch 3755/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.7220 - val_loss: 66.0964\n",
      "Epoch 3756/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5393 - val_loss: 70.5251\n",
      "Epoch 3757/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.8690 - val_loss: 74.8585\n",
      "Epoch 3758/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 5.1882 - val_loss: 72.9588\n",
      "Epoch 3759/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.0167 - val_loss: 74.3960\n",
      "Epoch 3760/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4523 - val_loss: 66.3285\n",
      "Epoch 3761/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6033 - val_loss: 77.8936\n",
      "Epoch 3762/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.9367 - val_loss: 77.6406\n",
      "Epoch 3763/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.5616 - val_loss: 73.4164\n",
      "Epoch 3764/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.4650 - val_loss: 70.8644\n",
      "Epoch 3765/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.4837 - val_loss: 70.3875\n",
      "Epoch 3766/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.7866 - val_loss: 75.0984\n",
      "Epoch 3767/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.6760 - val_loss: 76.8184\n",
      "Epoch 3768/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.5681 - val_loss: 65.3256\n",
      "Epoch 3769/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5913 - val_loss: 67.9174\n",
      "Epoch 3770/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3230 - val_loss: 70.0567\n",
      "Epoch 3771/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.3887 - val_loss: 73.7303\n",
      "Epoch 3772/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.2813 - val_loss: 71.1408\n",
      "Epoch 3773/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.5894 - val_loss: 66.8879\n",
      "Epoch 3774/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5238 - val_loss: 82.4588\n",
      "Epoch 3775/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.6896 - val_loss: 72.8690\n",
      "Epoch 3776/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4030 - val_loss: 75.9626\n",
      "Epoch 3777/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4292 - val_loss: 65.3502\n",
      "Epoch 3778/5000\n",
      "1063/1063 [==============================] - 0s 126us/step - loss: 4.8202 - val_loss: 79.0614\n",
      "Epoch 3779/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6058 - val_loss: 75.9584\n",
      "Epoch 3780/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 5.1137 - val_loss: 83.1850\n",
      "Epoch 3781/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.6608 - val_loss: 84.7489\n",
      "Epoch 3782/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5982 - val_loss: 85.6787\n",
      "Epoch 3783/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.7562 - val_loss: 64.9807\n",
      "Epoch 3784/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.3610 - val_loss: 67.2718\n",
      "Epoch 3785/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4813 - val_loss: 70.3937\n",
      "Epoch 3786/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.3194 - val_loss: 66.8219\n",
      "Epoch 3787/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.4996 - val_loss: 76.2430\n",
      "Epoch 3788/5000\n",
      "1063/1063 [==============================] - ETA: 0s - loss: 3.978 - 0s 100us/step - loss: 4.3844 - val_loss: 68.6176\n",
      "Epoch 3789/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7007 - val_loss: 81.1058\n",
      "Epoch 3790/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9177 - val_loss: 67.2272\n",
      "Epoch 3791/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.7856 - val_loss: 74.8562\n",
      "Epoch 3792/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.4622 - val_loss: 73.7292\n",
      "Epoch 3793/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4620 - val_loss: 76.0256\n",
      "Epoch 3794/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5650 - val_loss: 77.0318\n",
      "Epoch 3795/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 5.0517 - val_loss: 69.6016\n",
      "Epoch 3796/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.6979 - val_loss: 75.5682\n",
      "Epoch 3797/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4679 - val_loss: 81.0392\n",
      "Epoch 3798/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6203 - val_loss: 69.7671\n",
      "Epoch 3799/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5844 - val_loss: 63.5058\n",
      "Epoch 3800/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.4212 - val_loss: 70.2468\n",
      "Epoch 3801/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5582 - val_loss: 65.2027\n",
      "Epoch 3802/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5932 - val_loss: 72.9477\n",
      "Epoch 3803/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.5408 - val_loss: 68.3793\n",
      "Epoch 3804/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.3351 - val_loss: 72.7652\n",
      "Epoch 3805/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.2887 - val_loss: 66.5932\n",
      "Epoch 3806/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4450 - val_loss: 70.4695\n",
      "Epoch 3807/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.4549 - val_loss: 72.8373\n",
      "Epoch 3808/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 5.1362 - val_loss: 66.1993\n",
      "Epoch 3809/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.6080 - val_loss: 76.4775\n",
      "Epoch 3810/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5359 - val_loss: 67.7963\n",
      "Epoch 3811/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.6192 - val_loss: 69.7382\n",
      "Epoch 3812/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6805 - val_loss: 72.0496\n",
      "Epoch 3813/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6769 - val_loss: 73.0217\n",
      "Epoch 3814/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4402 - val_loss: 69.3776\n",
      "Epoch 3815/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.2303 - val_loss: 74.4980\n",
      "Epoch 3816/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.3277 - val_loss: 72.1604\n",
      "Epoch 3817/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.8626 - val_loss: 70.6057\n",
      "Epoch 3818/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.6598 - val_loss: 67.6338\n",
      "Epoch 3819/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5742 - val_loss: 70.3027\n",
      "Epoch 3820/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5201 - val_loss: 64.7727\n",
      "Epoch 3821/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.3534 - val_loss: 84.2874\n",
      "Epoch 3822/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6910 - val_loss: 68.0218\n",
      "Epoch 3823/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4527 - val_loss: 69.2180\n",
      "Epoch 3824/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5287 - val_loss: 69.1304\n",
      "Epoch 3825/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5880 - val_loss: 79.1826\n",
      "Epoch 3826/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6078 - val_loss: 89.7422\n",
      "Epoch 3827/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.4422 - val_loss: 71.9585\n",
      "Epoch 3828/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9522 - val_loss: 75.0843\n",
      "Epoch 3829/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.9156 - val_loss: 68.2235\n",
      "Epoch 3830/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.4883 - val_loss: 68.1168\n",
      "Epoch 3831/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.3267 - val_loss: 77.9851\n",
      "Epoch 3832/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.0247 - val_loss: 73.0005\n",
      "Epoch 3833/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5108 - val_loss: 73.1287\n",
      "Epoch 3834/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.2888 - val_loss: 68.8674\n",
      "Epoch 3835/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5629 - val_loss: 67.8031\n",
      "Epoch 3836/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5338 - val_loss: 70.4307\n",
      "Epoch 3837/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5174 - val_loss: 71.3012\n",
      "Epoch 3838/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4941 - val_loss: 70.5368\n",
      "Epoch 3839/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.2296 - val_loss: 74.5106\n",
      "Epoch 3840/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.4656 - val_loss: 68.9474\n",
      "Epoch 3841/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.3883 - val_loss: 77.2473\n",
      "Epoch 3842/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.3111 - val_loss: 76.6185\n",
      "Epoch 3843/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.3524 - val_loss: 67.3656\n",
      "Epoch 3844/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5634 - val_loss: 72.5140\n",
      "Epoch 3845/5000\n",
      "1063/1063 [==============================] - 0s 122us/step - loss: 4.5430 - val_loss: 72.8453\n",
      "Epoch 3846/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.9144 - val_loss: 64.8939\n",
      "Epoch 3847/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.9260 - val_loss: 78.0072\n",
      "Epoch 3848/5000\n",
      "1063/1063 [==============================] - 0s 121us/step - loss: 4.4248 - val_loss: 70.8656\n",
      "Epoch 3849/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.5739 - val_loss: 80.2620\n",
      "Epoch 3850/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.8857 - val_loss: 72.3215\n",
      "Epoch 3851/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7156 - val_loss: 67.3214\n",
      "Epoch 3852/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.8206 - val_loss: 69.0693\n",
      "Epoch 3853/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.5686 - val_loss: 72.2543\n",
      "Epoch 3854/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.6198 - val_loss: 75.4707\n",
      "Epoch 3855/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.8000 - val_loss: 69.6115\n",
      "Epoch 3856/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.4297 - val_loss: 73.0741\n",
      "Epoch 3857/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.5890 - val_loss: 71.3497\n",
      "Epoch 3858/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5707 - val_loss: 69.4532\n",
      "Epoch 3859/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6923 - val_loss: 79.1860\n",
      "Epoch 3860/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6045 - val_loss: 67.1402\n",
      "Epoch 3861/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6529 - val_loss: 68.8967\n",
      "Epoch 3862/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5715 - val_loss: 67.1519\n",
      "Epoch 3863/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6351 - val_loss: 75.2394\n",
      "Epoch 3864/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4869 - val_loss: 72.1043\n",
      "Epoch 3865/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8743 - val_loss: 75.4069\n",
      "Epoch 3866/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5086 - val_loss: 67.2303\n",
      "Epoch 3867/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8971 - val_loss: 75.6327\n",
      "Epoch 3868/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5931 - val_loss: 67.8611\n",
      "Epoch 3869/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5628 - val_loss: 77.7888\n",
      "Epoch 3870/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4084 - val_loss: 69.0878\n",
      "Epoch 3871/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5355 - val_loss: 72.2863\n",
      "Epoch 3872/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5933 - val_loss: 72.0103\n",
      "Epoch 3873/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.9581 - val_loss: 67.6698\n",
      "Epoch 3874/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4158 - val_loss: 68.2286\n",
      "Epoch 3875/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6098 - val_loss: 71.8183\n",
      "Epoch 3876/5000\n",
      "1063/1063 [==============================] - 0s 86us/step - loss: 4.5195 - val_loss: 72.5688\n",
      "Epoch 3877/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5463 - val_loss: 76.1128\n",
      "Epoch 3878/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5708 - val_loss: 71.1530\n",
      "Epoch 3879/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.2546 - val_loss: 67.6092\n",
      "Epoch 3880/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.5016 - val_loss: 70.8520\n",
      "Epoch 3881/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6254 - val_loss: 69.8237\n",
      "Epoch 3882/5000\n",
      "1063/1063 [==============================] - 0s 86us/step - loss: 4.5966 - val_loss: 70.4576\n",
      "Epoch 3883/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5948 - val_loss: 75.4743\n",
      "Epoch 3884/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.7200 - val_loss: 79.3520\n",
      "Epoch 3885/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6246 - val_loss: 81.6173\n",
      "Epoch 3886/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9124 - val_loss: 77.8679\n",
      "Epoch 3887/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.8003 - val_loss: 69.0743\n",
      "Epoch 3888/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.6651 - val_loss: 74.2118\n",
      "Epoch 3889/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.4763 - val_loss: 71.1539\n",
      "Epoch 3890/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4304 - val_loss: 71.9510\n",
      "Epoch 3891/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4834 - val_loss: 73.8927\n",
      "Epoch 3892/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5534 - val_loss: 70.1065\n",
      "Epoch 3893/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.2709 - val_loss: 77.4608\n",
      "Epoch 3894/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3270 - val_loss: 74.2366\n",
      "Epoch 3895/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.3405 - val_loss: 74.6692\n",
      "Epoch 3896/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3712 - val_loss: 68.1269\n",
      "Epoch 3897/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.3618 - val_loss: 62.8452\n",
      "Epoch 3898/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6747 - val_loss: 71.7783\n",
      "Epoch 3899/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.3044 - val_loss: 75.1563\n",
      "Epoch 3900/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.7160 - val_loss: 71.8838\n",
      "Epoch 3901/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 5.0662 - val_loss: 71.4182\n",
      "Epoch 3902/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5178 - val_loss: 75.7166\n",
      "Epoch 3903/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.6386 - val_loss: 69.2172\n",
      "Epoch 3904/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5725 - val_loss: 69.7047\n",
      "Epoch 3905/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.7056 - val_loss: 72.0614\n",
      "Epoch 3906/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.3524 - val_loss: 75.2112\n",
      "Epoch 3907/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.5714 - val_loss: 61.6489\n",
      "Epoch 3908/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.9653 - val_loss: 70.4840\n",
      "Epoch 3909/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.3519 - val_loss: 67.7349\n",
      "Epoch 3910/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 5.0628 - val_loss: 61.7562\n",
      "Epoch 3911/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4669 - val_loss: 73.3863\n",
      "Epoch 3912/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.7359 - val_loss: 77.1451\n",
      "Epoch 3913/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 5.2118 - val_loss: 77.5378\n",
      "Epoch 3914/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5323 - val_loss: 72.8499\n",
      "Epoch 3915/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5937 - val_loss: 65.6930\n",
      "Epoch 3916/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4422 - val_loss: 68.0036\n",
      "Epoch 3917/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.3805 - val_loss: 79.2298\n",
      "Epoch 3918/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 5.2016 - val_loss: 72.2862\n",
      "Epoch 3919/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4930 - val_loss: 72.0305\n",
      "Epoch 3920/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4800 - val_loss: 71.4607\n",
      "Epoch 3921/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.9585 - val_loss: 81.2097\n",
      "Epoch 3922/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.7196 - val_loss: 84.5037\n",
      "Epoch 3923/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 5.1052 - val_loss: 70.6266\n",
      "Epoch 3924/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.5183 - val_loss: 73.8891\n",
      "Epoch 3925/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3474 - val_loss: 84.3439\n",
      "Epoch 3926/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5482 - val_loss: 70.6820\n",
      "Epoch 3927/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5383 - val_loss: 70.7747\n",
      "Epoch 3928/5000\n",
      "1063/1063 [==============================] - 0s 86us/step - loss: 4.5210 - val_loss: 64.7856\n",
      "Epoch 3929/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.9799 - val_loss: 69.3352\n",
      "Epoch 3930/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5998 - val_loss: 75.3630\n",
      "Epoch 3931/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.1872 - val_loss: 65.5812\n",
      "Epoch 3932/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.4003 - val_loss: 71.2417\n",
      "Epoch 3933/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.6273 - val_loss: 79.0323\n",
      "Epoch 3934/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.9023 - val_loss: 73.5543\n",
      "Epoch 3935/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 5.5156 - val_loss: 67.0784\n",
      "Epoch 3936/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5552 - val_loss: 71.3294\n",
      "Epoch 3937/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6468 - val_loss: 67.9803\n",
      "Epoch 3938/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.6484 - val_loss: 68.4916\n",
      "Epoch 3939/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3531 - val_loss: 74.3464\n",
      "Epoch 3940/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.3344 - val_loss: 72.0997\n",
      "Epoch 3941/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.1932 - val_loss: 72.6023\n",
      "Epoch 3942/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.3047 - val_loss: 68.9377\n",
      "Epoch 3943/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3552 - val_loss: 73.8315\n",
      "Epoch 3944/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3638 - val_loss: 67.9494\n",
      "Epoch 3945/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.7840 - val_loss: 73.6864\n",
      "Epoch 3946/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4989 - val_loss: 81.5735\n",
      "Epoch 3947/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5405 - val_loss: 75.1094\n",
      "Epoch 3948/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.2380 - val_loss: 80.4801\n",
      "Epoch 3949/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.6655 - val_loss: 73.2768\n",
      "Epoch 3950/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3585 - val_loss: 81.1102\n",
      "Epoch 3951/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.5940 - val_loss: 77.4964\n",
      "Epoch 3952/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6334 - val_loss: 66.6760\n",
      "Epoch 3953/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.6183 - val_loss: 70.7005\n",
      "Epoch 3954/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5309 - val_loss: 65.0836\n",
      "Epoch 3955/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.6410 - val_loss: 68.8042\n",
      "Epoch 3956/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.7216 - val_loss: 64.5923\n",
      "Epoch 3957/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.9446 - val_loss: 71.8206\n",
      "Epoch 3958/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.4938 - val_loss: 68.9406\n",
      "Epoch 3959/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4215 - val_loss: 68.3374\n",
      "Epoch 3960/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4344 - val_loss: 67.7964\n",
      "Epoch 3961/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5183 - val_loss: 73.4376\n",
      "Epoch 3962/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.2542 - val_loss: 65.8379\n",
      "Epoch 3963/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.4819 - val_loss: 69.3369\n",
      "Epoch 3964/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4886 - val_loss: 70.8901\n",
      "Epoch 3965/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4573 - val_loss: 65.2819\n",
      "Epoch 3966/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.7981 - val_loss: 74.4982\n",
      "Epoch 3967/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.5780 - val_loss: 70.8803\n",
      "Epoch 3968/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.5690 - val_loss: 70.4337\n",
      "Epoch 3969/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5217 - val_loss: 70.2822\n",
      "Epoch 3970/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4804 - val_loss: 76.2641\n",
      "Epoch 3971/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4313 - val_loss: 72.1108\n",
      "Epoch 3972/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4126 - val_loss: 67.1531\n",
      "Epoch 3973/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.2373 - val_loss: 66.7364\n",
      "Epoch 3974/5000\n",
      "1063/1063 [==============================] - 0s 86us/step - loss: 4.4946 - val_loss: 72.2131\n",
      "Epoch 3975/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.2825 - val_loss: 66.1453\n",
      "Epoch 3976/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5811 - val_loss: 76.6833\n",
      "Epoch 3977/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7752 - val_loss: 70.6689\n",
      "Epoch 3978/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4047 - val_loss: 71.0391\n",
      "Epoch 3979/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.7449 - val_loss: 71.7565\n",
      "Epoch 3980/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5099 - val_loss: 75.4455\n",
      "Epoch 3981/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 5.2155 - val_loss: 69.7930\n",
      "Epoch 3982/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5243 - val_loss: 67.6497\n",
      "Epoch 3983/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4911 - val_loss: 68.8914\n",
      "Epoch 3984/5000\n",
      "1063/1063 [==============================] - 0s 85us/step - loss: 4.4544 - val_loss: 74.1876\n",
      "Epoch 3985/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6065 - val_loss: 69.3041\n",
      "Epoch 3986/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4104 - val_loss: 75.6705\n",
      "Epoch 3987/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5327 - val_loss: 70.8853\n",
      "Epoch 3988/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4447 - val_loss: 84.4584\n",
      "Epoch 3989/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.0301 - val_loss: 89.8394\n",
      "Epoch 3990/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.0158 - val_loss: 69.9327\n",
      "Epoch 3991/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6208 - val_loss: 68.3740\n",
      "Epoch 3992/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4154 - val_loss: 66.0726\n",
      "Epoch 3993/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.8481 - val_loss: 74.2388\n",
      "Epoch 3994/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.4277 - val_loss: 67.5449\n",
      "Epoch 3995/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6331 - val_loss: 68.2945\n",
      "Epoch 3996/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5094 - val_loss: 71.2813\n",
      "Epoch 3997/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5058 - val_loss: 75.9229\n",
      "Epoch 3998/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4854 - val_loss: 70.7937\n",
      "Epoch 3999/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.0824 - val_loss: 64.0764\n",
      "Epoch 4000/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 5.0772 - val_loss: 74.3993\n",
      "Epoch 4001/5000\n",
      "1063/1063 [==============================] - 0s 119us/step - loss: 4.9968 - val_loss: 76.0991\n",
      "Epoch 4002/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7106 - val_loss: 73.1476\n",
      "Epoch 4003/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.4333 - val_loss: 67.9803\n",
      "Epoch 4004/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5163 - val_loss: 80.0317\n",
      "Epoch 4005/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.6905 - val_loss: 72.6096\n",
      "Epoch 4006/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4809 - val_loss: 69.8220\n",
      "Epoch 4007/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.1937 - val_loss: 70.5282\n",
      "Epoch 4008/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5296 - val_loss: 70.4972\n",
      "Epoch 4009/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5809 - val_loss: 73.6923\n",
      "Epoch 4010/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5579 - val_loss: 66.7974\n",
      "Epoch 4011/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.9336 - val_loss: 68.9677\n",
      "Epoch 4012/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4196 - val_loss: 71.4108\n",
      "Epoch 4013/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.4663 - val_loss: 75.9309\n",
      "Epoch 4014/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.4172 - val_loss: 72.2296\n",
      "Epoch 4015/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4679 - val_loss: 73.4760\n",
      "Epoch 4016/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4220 - val_loss: 65.3942\n",
      "Epoch 4017/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8531 - val_loss: 69.4070\n",
      "Epoch 4018/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6536 - val_loss: 73.0642\n",
      "Epoch 4019/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5827 - val_loss: 78.7564\n",
      "Epoch 4020/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.8386 - val_loss: 74.8176\n",
      "Epoch 4021/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5067 - val_loss: 68.7220\n",
      "Epoch 4022/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.3997 - val_loss: 68.2500\n",
      "Epoch 4023/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.4035 - val_loss: 70.9738\n",
      "Epoch 4024/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.6667 - val_loss: 68.1798\n",
      "Epoch 4025/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.7098 - val_loss: 70.8869\n",
      "Epoch 4026/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.2966 - val_loss: 70.7540\n",
      "Epoch 4027/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.6484 - val_loss: 74.6563\n",
      "Epoch 4028/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6478 - val_loss: 65.0188\n",
      "Epoch 4029/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 5.0670 - val_loss: 79.4174\n",
      "Epoch 4030/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5607 - val_loss: 78.0856\n",
      "Epoch 4031/5000\n",
      "1063/1063 [==============================] - 0s 86us/step - loss: 4.6012 - val_loss: 75.2171\n",
      "Epoch 4032/5000\n",
      "1063/1063 [==============================] - 0s 86us/step - loss: 4.6486 - val_loss: 76.7940\n",
      "Epoch 4033/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5902 - val_loss: 68.1701\n",
      "Epoch 4034/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.2738 - val_loss: 72.3108\n",
      "Epoch 4035/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.3588 - val_loss: 74.5193\n",
      "Epoch 4036/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.3598 - val_loss: 72.4571\n",
      "Epoch 4037/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.3647 - val_loss: 78.3433\n",
      "Epoch 4038/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.3621 - val_loss: 68.9185\n",
      "Epoch 4039/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5155 - val_loss: 73.0234\n",
      "Epoch 4040/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5217 - val_loss: 71.3419\n",
      "Epoch 4041/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.3117 - val_loss: 80.2902\n",
      "Epoch 4042/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6617 - val_loss: 77.0121\n",
      "Epoch 4043/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8353 - val_loss: 72.1111\n",
      "Epoch 4044/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8496 - val_loss: 77.6081\n",
      "Epoch 4045/5000\n",
      "1063/1063 [==============================] - 0s 123us/step - loss: 4.4775 - val_loss: 68.9144\n",
      "Epoch 4046/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 86us/step - loss: 4.3073 - val_loss: 69.1980\n",
      "Epoch 4047/5000\n",
      "1063/1063 [==============================] - 0s 84us/step - loss: 4.7578 - val_loss: 77.9862\n",
      "Epoch 4048/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.8297 - val_loss: 71.0373\n",
      "Epoch 4049/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.8238 - val_loss: 64.7418\n",
      "Epoch 4050/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.0571 - val_loss: 71.3482\n",
      "Epoch 4051/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.7946 - val_loss: 71.3179\n",
      "Epoch 4052/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.5292 - val_loss: 74.2282\n",
      "Epoch 4053/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.8432 - val_loss: 80.4008\n",
      "Epoch 4054/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5055 - val_loss: 72.1690\n",
      "Epoch 4055/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6506 - val_loss: 68.8762\n",
      "Epoch 4056/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.3901 - val_loss: 76.2349\n",
      "Epoch 4057/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4852 - val_loss: 69.2689\n",
      "Epoch 4058/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.3507 - val_loss: 75.0318\n",
      "Epoch 4059/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.3220 - val_loss: 68.0727\n",
      "Epoch 4060/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.2716 - val_loss: 70.6184\n",
      "Epoch 4061/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6917 - val_loss: 75.1727\n",
      "Epoch 4062/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.6877 - val_loss: 70.0365\n",
      "Epoch 4063/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.7360 - val_loss: 66.2500\n",
      "Epoch 4064/5000\n",
      "1063/1063 [==============================] - 0s 84us/step - loss: 4.7181 - val_loss: 62.8173\n",
      "Epoch 4065/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 5.1030 - val_loss: 76.3246\n",
      "Epoch 4066/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.0067 - val_loss: 78.1652\n",
      "Epoch 4067/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5151 - val_loss: 71.6499\n",
      "Epoch 4068/5000\n",
      "1063/1063 [==============================] - 0s 86us/step - loss: 5.0092 - val_loss: 73.8671\n",
      "Epoch 4069/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.8652 - val_loss: 73.4725\n",
      "Epoch 4070/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5760 - val_loss: 67.6078\n",
      "Epoch 4071/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4560 - val_loss: 71.9353\n",
      "Epoch 4072/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.4102 - val_loss: 76.3188\n",
      "Epoch 4073/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.2779 - val_loss: 75.6951\n",
      "Epoch 4074/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.3569 - val_loss: 79.0427\n",
      "Epoch 4075/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4241 - val_loss: 79.8329\n",
      "Epoch 4076/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.2096 - val_loss: 70.5382\n",
      "Epoch 4077/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.2277 - val_loss: 65.9570\n",
      "Epoch 4078/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.9762 - val_loss: 89.2430\n",
      "Epoch 4079/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.8449 - val_loss: 68.9571\n",
      "Epoch 4080/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4981 - val_loss: 62.6714\n",
      "Epoch 4081/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.0011 - val_loss: 69.8863\n",
      "Epoch 4082/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6968 - val_loss: 73.5462\n",
      "Epoch 4083/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4788 - val_loss: 70.2118\n",
      "Epoch 4084/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5758 - val_loss: 67.2835\n",
      "Epoch 4085/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.3616 - val_loss: 75.6457\n",
      "Epoch 4086/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3251 - val_loss: 73.1933\n",
      "Epoch 4087/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.3587 - val_loss: 72.0974\n",
      "Epoch 4088/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.2748 - val_loss: 73.4303\n",
      "Epoch 4089/5000\n",
      "1063/1063 [==============================] - 0s 86us/step - loss: 4.6484 - val_loss: 77.9754\n",
      "Epoch 4090/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6085 - val_loss: 79.5818\n",
      "Epoch 4091/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5208 - val_loss: 72.9059\n",
      "Epoch 4092/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.0275 - val_loss: 68.3423\n",
      "Epoch 4093/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.7611 - val_loss: 69.6927\n",
      "Epoch 4094/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.2689 - val_loss: 77.1331\n",
      "Epoch 4095/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6270 - val_loss: 64.1165\n",
      "Epoch 4096/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5535 - val_loss: 77.4059\n",
      "Epoch 4097/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.2827 - val_loss: 75.7155\n",
      "Epoch 4098/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.8306 - val_loss: 71.3643\n",
      "Epoch 4099/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9822 - val_loss: 68.3004\n",
      "Epoch 4100/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.4695 - val_loss: 72.8207\n",
      "Epoch 4101/5000\n",
      "1063/1063 [==============================] - 0s 86us/step - loss: 4.4311 - val_loss: 69.3462\n",
      "Epoch 4102/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.2490 - val_loss: 71.4127\n",
      "Epoch 4103/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.4268 - val_loss: 72.8473\n",
      "Epoch 4104/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.3023 - val_loss: 69.3429\n",
      "Epoch 4105/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.6242 - val_loss: 68.2047\n",
      "Epoch 4106/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5216 - val_loss: 75.0522\n",
      "Epoch 4107/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6377 - val_loss: 70.9511\n",
      "Epoch 4108/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5416 - val_loss: 68.1388\n",
      "Epoch 4109/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.3742 - val_loss: 73.3762\n",
      "Epoch 4110/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5916 - val_loss: 68.9975\n",
      "Epoch 4111/5000\n",
      "1063/1063 [==============================] - 0s 86us/step - loss: 4.2187 - val_loss: 76.0051\n",
      "Epoch 4112/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3163 - val_loss: 73.8598\n",
      "Epoch 4113/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3593 - val_loss: 72.4519\n",
      "Epoch 4114/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6133 - val_loss: 61.1530\n",
      "Epoch 4115/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.7351 - val_loss: 74.3085\n",
      "Epoch 4116/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.6040 - val_loss: 67.5296\n",
      "Epoch 4117/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3092 - val_loss: 66.0334\n",
      "Epoch 4118/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4560 - val_loss: 75.9319\n",
      "Epoch 4119/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4553 - val_loss: 65.8786\n",
      "Epoch 4120/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.3753 - val_loss: 73.4893\n",
      "Epoch 4121/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6156 - val_loss: 80.7510\n",
      "Epoch 4122/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5262 - val_loss: 80.6311\n",
      "Epoch 4123/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.9586 - val_loss: 75.2201\n",
      "Epoch 4124/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.7095 - val_loss: 74.4393\n",
      "Epoch 4125/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.8165 - val_loss: 69.5489\n",
      "Epoch 4126/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 5.5149 - val_loss: 66.9236\n",
      "Epoch 4127/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.8006 - val_loss: 67.6878\n",
      "Epoch 4128/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4021 - val_loss: 68.5016\n",
      "Epoch 4129/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.7419 - val_loss: 67.4235\n",
      "Epoch 4130/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.9692 - val_loss: 73.5853\n",
      "Epoch 4131/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.1194 - val_loss: 69.5177\n",
      "Epoch 4132/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.2720 - val_loss: 80.3540\n",
      "Epoch 4133/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6405 - val_loss: 64.2603\n",
      "Epoch 4134/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.7913 - val_loss: 74.8026\n",
      "Epoch 4135/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.3590 - val_loss: 76.3794\n",
      "Epoch 4136/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6544 - val_loss: 67.8339\n",
      "Epoch 4137/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.8972 - val_loss: 69.2105\n",
      "Epoch 4138/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.3632 - val_loss: 68.8909\n",
      "Epoch 4139/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.3567 - val_loss: 69.7252\n",
      "Epoch 4140/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.4783 - val_loss: 72.3526\n",
      "Epoch 4141/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.5042 - val_loss: 77.8050\n",
      "Epoch 4142/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.6929 - val_loss: 71.8238\n",
      "Epoch 4143/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5858 - val_loss: 76.7654\n",
      "Epoch 4144/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.3562 - val_loss: 76.4558\n",
      "Epoch 4145/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.3060 - val_loss: 63.2463\n",
      "Epoch 4146/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.4964 - val_loss: 74.6536\n",
      "Epoch 4147/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3140 - val_loss: 69.5977\n",
      "Epoch 4148/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.3593 - val_loss: 69.7749\n",
      "Epoch 4149/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5349 - val_loss: 74.0050\n",
      "Epoch 4150/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3663 - val_loss: 71.7236\n",
      "Epoch 4151/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.4589 - val_loss: 74.6241\n",
      "Epoch 4152/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5361 - val_loss: 72.6571\n",
      "Epoch 4153/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3233 - val_loss: 73.8621\n",
      "Epoch 4154/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5313 - val_loss: 75.9589\n",
      "Epoch 4155/5000\n",
      "1063/1063 [==============================] - 0s 86us/step - loss: 4.7050 - val_loss: 74.6858\n",
      "Epoch 4156/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.4582 - val_loss: 70.6736\n",
      "Epoch 4157/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4451 - val_loss: 69.2854\n",
      "Epoch 4158/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.7518 - val_loss: 72.9951\n",
      "Epoch 4159/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5978 - val_loss: 75.7758\n",
      "Epoch 4160/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5783 - val_loss: 72.3936\n",
      "Epoch 4161/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.4663 - val_loss: 70.6104\n",
      "Epoch 4162/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5910 - val_loss: 65.4614\n",
      "Epoch 4163/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.4563 - val_loss: 66.3640\n",
      "Epoch 4164/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.7012 - val_loss: 72.4002\n",
      "Epoch 4165/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.6657 - val_loss: 66.5100\n",
      "Epoch 4166/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5898 - val_loss: 69.5532\n",
      "Epoch 4167/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.7236 - val_loss: 75.1881\n",
      "Epoch 4168/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.7869 - val_loss: 77.0326\n",
      "Epoch 4169/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6793 - val_loss: 75.1793\n",
      "Epoch 4170/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6182 - val_loss: 66.4228\n",
      "Epoch 4171/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 5.2703 - val_loss: 80.6962\n",
      "Epoch 4172/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4364 - val_loss: 75.9995\n",
      "Epoch 4173/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4711 - val_loss: 65.8102\n",
      "Epoch 4174/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4953 - val_loss: 70.7569\n",
      "Epoch 4175/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.3579 - val_loss: 75.0477\n",
      "Epoch 4176/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.2435 - val_loss: 74.9293\n",
      "Epoch 4177/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.8753 - val_loss: 71.8132\n",
      "Epoch 4178/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3908 - val_loss: 75.7130\n",
      "Epoch 4179/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.3595 - val_loss: 70.2255\n",
      "Epoch 4180/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5312 - val_loss: 67.2703\n",
      "Epoch 4181/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.6988 - val_loss: 69.5367\n",
      "Epoch 4182/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.3708 - val_loss: 71.6346\n",
      "Epoch 4183/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5239 - val_loss: 74.5564\n",
      "Epoch 4184/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4045 - val_loss: 77.5152\n",
      "Epoch 4185/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 5.1969 - val_loss: 69.9384\n",
      "Epoch 4186/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.3063 - val_loss: 82.5039\n",
      "Epoch 4187/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5303 - val_loss: 74.6231\n",
      "Epoch 4188/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5353 - val_loss: 71.3461\n",
      "Epoch 4189/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4704 - val_loss: 69.9369\n",
      "Epoch 4190/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7260 - val_loss: 80.4883\n",
      "Epoch 4191/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.4805 - val_loss: 73.2473\n",
      "Epoch 4192/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 5.0228 - val_loss: 86.9980\n",
      "Epoch 4193/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.7204 - val_loss: 73.4967\n",
      "Epoch 4194/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.3435 - val_loss: 76.0516\n",
      "Epoch 4195/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5870 - val_loss: 69.5466\n",
      "Epoch 4196/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5173 - val_loss: 82.6480\n",
      "Epoch 4197/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.6689 - val_loss: 81.4313\n",
      "Epoch 4198/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3367 - val_loss: 70.1428\n",
      "Epoch 4199/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4793 - val_loss: 63.8042\n",
      "Epoch 4200/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7049 - val_loss: 70.6139\n",
      "Epoch 4201/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.2678 - val_loss: 66.7728\n",
      "Epoch 4202/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4336 - val_loss: 64.2208\n",
      "Epoch 4203/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 5.0947 - val_loss: 77.5502\n",
      "Epoch 4204/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.4027 - val_loss: 76.2396\n",
      "Epoch 4205/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 5.0448 - val_loss: 75.3638\n",
      "Epoch 4206/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4993 - val_loss: 70.1678\n",
      "Epoch 4207/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.3771 - val_loss: 74.5372\n",
      "Epoch 4208/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6481 - val_loss: 72.5429\n",
      "Epoch 4209/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.3342 - val_loss: 81.4229\n",
      "Epoch 4210/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4781 - val_loss: 70.5158\n",
      "Epoch 4211/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8750 - val_loss: 63.7997\n",
      "Epoch 4212/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.7782 - val_loss: 66.1559\n",
      "Epoch 4213/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6410 - val_loss: 73.7006\n",
      "Epoch 4214/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.2913 - val_loss: 71.7231\n",
      "Epoch 4215/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.3201 - val_loss: 68.4090\n",
      "Epoch 4216/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.6555 - val_loss: 76.2780\n",
      "Epoch 4217/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5949 - val_loss: 69.1890\n",
      "Epoch 4218/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6509 - val_loss: 70.6809\n",
      "Epoch 4219/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4407 - val_loss: 66.8140\n",
      "Epoch 4220/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.5268 - val_loss: 71.4622\n",
      "Epoch 4221/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8573 - val_loss: 66.9349\n",
      "Epoch 4222/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4592 - val_loss: 68.0577\n",
      "Epoch 4223/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5258 - val_loss: 70.4241\n",
      "Epoch 4224/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.3432 - val_loss: 79.0272\n",
      "Epoch 4225/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5198 - val_loss: 70.3962\n",
      "Epoch 4226/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.2499 - val_loss: 63.3581\n",
      "Epoch 4227/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4197 - val_loss: 70.1451\n",
      "Epoch 4228/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5082 - val_loss: 73.8586\n",
      "Epoch 4229/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6772 - val_loss: 72.4129\n",
      "Epoch 4230/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5232 - val_loss: 71.5891\n",
      "Epoch 4231/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7272 - val_loss: 80.2515\n",
      "Epoch 4232/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4628 - val_loss: 70.1173\n",
      "Epoch 4233/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.5171 - val_loss: 68.9378\n",
      "Epoch 4234/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4514 - val_loss: 71.3676\n",
      "Epoch 4235/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5257 - val_loss: 72.8344\n",
      "Epoch 4236/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.7765 - val_loss: 73.5883\n",
      "Epoch 4237/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.7387 - val_loss: 74.6661\n",
      "Epoch 4238/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9344 - val_loss: 64.8733\n",
      "Epoch 4239/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7576 - val_loss: 72.3519\n",
      "Epoch 4240/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 5.0780 - val_loss: 71.5342\n",
      "Epoch 4241/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4071 - val_loss: 71.0341\n",
      "Epoch 4242/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.6373 - val_loss: 61.3709\n",
      "Epoch 4243/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 5.8397 - val_loss: 72.6338\n",
      "Epoch 4244/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9992 - val_loss: 68.7498\n",
      "Epoch 4245/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6690 - val_loss: 71.7240\n",
      "Epoch 4246/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.2496 - val_loss: 71.8762\n",
      "Epoch 4247/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4199 - val_loss: 70.1453\n",
      "Epoch 4248/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.2585 - val_loss: 72.3860\n",
      "Epoch 4249/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6381 - val_loss: 75.4679\n",
      "Epoch 4250/5000\n",
      "1063/1063 [==============================] - 0s 85us/step - loss: 4.5308 - val_loss: 78.0727\n",
      "Epoch 4251/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5229 - val_loss: 70.4136\n",
      "Epoch 4252/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.2630 - val_loss: 74.2072\n",
      "Epoch 4253/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4302 - val_loss: 70.4366\n",
      "Epoch 4254/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4861 - val_loss: 82.8251\n",
      "Epoch 4255/5000\n",
      "1063/1063 [==============================] - 0s 86us/step - loss: 4.9502 - val_loss: 74.5513\n",
      "Epoch 4256/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.3552 - val_loss: 70.4514\n",
      "Epoch 4257/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.5928 - val_loss: 69.1188\n",
      "Epoch 4258/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 5.3730 - val_loss: 68.0123\n",
      "Epoch 4259/5000\n",
      "1063/1063 [==============================] - 0s 86us/step - loss: 4.8004 - val_loss: 73.4010\n",
      "Epoch 4260/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.1489 - val_loss: 68.4937\n",
      "Epoch 4261/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5113 - val_loss: 73.7881\n",
      "Epoch 4262/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5667 - val_loss: 67.5849\n",
      "Epoch 4263/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.7508 - val_loss: 76.8198\n",
      "Epoch 4264/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.6755 - val_loss: 71.6525\n",
      "Epoch 4265/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.4200 - val_loss: 67.5089\n",
      "Epoch 4266/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.7351 - val_loss: 75.6424\n",
      "Epoch 4267/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.7649 - val_loss: 68.8105\n",
      "Epoch 4268/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.6159 - val_loss: 75.9774\n",
      "Epoch 4269/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4659 - val_loss: 70.3261\n",
      "Epoch 4270/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.7536 - val_loss: 68.5103\n",
      "Epoch 4271/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.2303 - val_loss: 72.4042\n",
      "Epoch 4272/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4099 - val_loss: 76.1256\n",
      "Epoch 4273/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5656 - val_loss: 72.1335\n",
      "Epoch 4274/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.4706 - val_loss: 68.0208\n",
      "Epoch 4275/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.0934 - val_loss: 67.6292\n",
      "Epoch 4276/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4240 - val_loss: 68.2649\n",
      "Epoch 4277/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3887 - val_loss: 79.5234\n",
      "Epoch 4278/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.3802 - val_loss: 68.9439\n",
      "Epoch 4279/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.3571 - val_loss: 72.3859\n",
      "Epoch 4280/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.1516 - val_loss: 71.8915\n",
      "Epoch 4281/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.2725 - val_loss: 68.9404\n",
      "Epoch 4282/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3345 - val_loss: 66.9695\n",
      "Epoch 4283/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5154 - val_loss: 71.2719\n",
      "Epoch 4284/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.7585 - val_loss: 72.1456\n",
      "Epoch 4285/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.3413 - val_loss: 67.6042\n",
      "Epoch 4286/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.3780 - val_loss: 66.8854\n",
      "Epoch 4287/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.2669 - val_loss: 67.1744\n",
      "Epoch 4288/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3713 - val_loss: 83.5982\n",
      "Epoch 4289/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.6280 - val_loss: 73.4244\n",
      "Epoch 4290/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 5.1877 - val_loss: 81.3157\n",
      "Epoch 4291/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5436 - val_loss: 77.0689\n",
      "Epoch 4292/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6886 - val_loss: 66.0171\n",
      "Epoch 4293/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.8967 - val_loss: 73.6988\n",
      "Epoch 4294/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.3029 - val_loss: 72.6396\n",
      "Epoch 4295/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.8175 - val_loss: 72.6726\n",
      "Epoch 4296/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.5093 - val_loss: 64.0264\n",
      "Epoch 4297/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.6057 - val_loss: 78.5184\n",
      "Epoch 4298/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.1728 - val_loss: 69.5407\n",
      "Epoch 4299/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3463 - val_loss: 76.7341\n",
      "Epoch 4300/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7976 - val_loss: 72.6196\n",
      "Epoch 4301/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7287 - val_loss: 69.9427\n",
      "Epoch 4302/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5812 - val_loss: 66.6974\n",
      "Epoch 4303/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6985 - val_loss: 67.5844\n",
      "Epoch 4304/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 5.2383 - val_loss: 74.0259\n",
      "Epoch 4305/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.9581 - val_loss: 78.4408\n",
      "Epoch 4306/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7638 - val_loss: 81.9323\n",
      "Epoch 4307/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.9746 - val_loss: 71.9287\n",
      "Epoch 4308/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.0683 - val_loss: 76.9167\n",
      "Epoch 4309/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.3049 - val_loss: 67.5540\n",
      "Epoch 4310/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.7613 - val_loss: 69.8168\n",
      "Epoch 4311/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4871 - val_loss: 69.0905\n",
      "Epoch 4312/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5261 - val_loss: 74.7917\n",
      "Epoch 4313/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4133 - val_loss: 72.4710\n",
      "Epoch 4314/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.3176 - val_loss: 67.3258\n",
      "Epoch 4315/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5267 - val_loss: 77.8939\n",
      "Epoch 4316/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6280 - val_loss: 68.9049\n",
      "Epoch 4317/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.7350 - val_loss: 70.9390\n",
      "Epoch 4318/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.2591 - val_loss: 84.7595\n",
      "Epoch 4319/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5322 - val_loss: 75.7496\n",
      "Epoch 4320/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5797 - val_loss: 76.2367\n",
      "Epoch 4321/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.2258 - val_loss: 70.6527\n",
      "Epoch 4322/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.3975 - val_loss: 75.2741\n",
      "Epoch 4323/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.6335 - val_loss: 73.8729\n",
      "Epoch 4324/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4980 - val_loss: 65.3368\n",
      "Epoch 4325/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.8315 - val_loss: 70.4728\n",
      "Epoch 4326/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 5.4574 - val_loss: 74.6255\n",
      "Epoch 4327/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.4363 - val_loss: 75.2995\n",
      "Epoch 4328/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.3323 - val_loss: 72.4420\n",
      "Epoch 4329/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.3172 - val_loss: 76.3696\n",
      "Epoch 4330/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5766 - val_loss: 77.2684\n",
      "Epoch 4331/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5255 - val_loss: 70.4818\n",
      "Epoch 4332/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3033 - val_loss: 71.0039\n",
      "Epoch 4333/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 5.1031 - val_loss: 71.9821\n",
      "Epoch 4334/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.2851 - val_loss: 65.1297\n",
      "Epoch 4335/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.1543 - val_loss: 75.6176\n",
      "Epoch 4336/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8272 - val_loss: 65.1091\n",
      "Epoch 4337/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.6469 - val_loss: 77.1796\n",
      "Epoch 4338/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7148 - val_loss: 77.0585\n",
      "Epoch 4339/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.3684 - val_loss: 72.1931\n",
      "Epoch 4340/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.4700 - val_loss: 64.8096\n",
      "Epoch 4341/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5959 - val_loss: 76.4306\n",
      "Epoch 4342/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.3264 - val_loss: 69.0066\n",
      "Epoch 4343/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4564 - val_loss: 74.4378\n",
      "Epoch 4344/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5462 - val_loss: 70.5556\n",
      "Epoch 4345/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3896 - val_loss: 68.6237\n",
      "Epoch 4346/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4365 - val_loss: 79.5040\n",
      "Epoch 4347/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.1916 - val_loss: 69.0946\n",
      "Epoch 4348/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5474 - val_loss: 76.7598\n",
      "Epoch 4349/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3535 - val_loss: 70.4042\n",
      "Epoch 4350/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5156 - val_loss: 77.3870\n",
      "Epoch 4351/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9351 - val_loss: 71.5350\n",
      "Epoch 4352/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7269 - val_loss: 65.9730\n",
      "Epoch 4353/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.2938 - val_loss: 73.5048\n",
      "Epoch 4354/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.1942 - val_loss: 86.9043\n",
      "Epoch 4355/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8676 - val_loss: 68.8968\n",
      "Epoch 4356/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.8936 - val_loss: 70.5963\n",
      "Epoch 4357/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.2321 - val_loss: 77.8459\n",
      "Epoch 4358/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.3081 - val_loss: 70.0011\n",
      "Epoch 4359/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5023 - val_loss: 69.5268\n",
      "Epoch 4360/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6891 - val_loss: 77.7532\n",
      "Epoch 4361/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.8213 - val_loss: 77.8296\n",
      "Epoch 4362/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.2925 - val_loss: 77.9428\n",
      "Epoch 4363/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.9297 - val_loss: 67.1790\n",
      "Epoch 4364/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.3319 - val_loss: 66.5397\n",
      "Epoch 4365/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.6163 - val_loss: 70.7988\n",
      "Epoch 4366/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.6036 - val_loss: 74.4078\n",
      "Epoch 4367/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.8844 - val_loss: 66.7679\n",
      "Epoch 4368/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.7738 - val_loss: 73.9307\n",
      "Epoch 4369/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5011 - val_loss: 69.2714\n",
      "Epoch 4370/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.3430 - val_loss: 68.8321\n",
      "Epoch 4371/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.2000 - val_loss: 76.5206\n",
      "Epoch 4372/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.2139 - val_loss: 69.2956\n",
      "Epoch 4373/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5492 - val_loss: 72.6144\n",
      "Epoch 4374/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6355 - val_loss: 76.2459\n",
      "Epoch 4375/5000\n",
      "1063/1063 [==============================] - 0s 86us/step - loss: 5.1624 - val_loss: 72.0466\n",
      "Epoch 4376/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.6974 - val_loss: 71.4316\n",
      "Epoch 4377/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4497 - val_loss: 66.3246\n",
      "Epoch 4378/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.9668 - val_loss: 74.2783\n",
      "Epoch 4379/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.7023 - val_loss: 68.4356\n",
      "Epoch 4380/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.5589 - val_loss: 76.6320\n",
      "Epoch 4381/5000\n",
      "1063/1063 [==============================] - 0s 86us/step - loss: 4.4456 - val_loss: 67.8786\n",
      "Epoch 4382/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4064 - val_loss: 73.8227\n",
      "Epoch 4383/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.1543 - val_loss: 66.3601\n",
      "Epoch 4384/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.6297 - val_loss: 69.1048\n",
      "Epoch 4385/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.2199 - val_loss: 64.0845\n",
      "Epoch 4386/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.4910 - val_loss: 73.1655\n",
      "Epoch 4387/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.2560 - val_loss: 72.3079\n",
      "Epoch 4388/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6526 - val_loss: 74.6538\n",
      "Epoch 4389/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4434 - val_loss: 68.2603\n",
      "Epoch 4390/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.2495 - val_loss: 77.0387\n",
      "Epoch 4391/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3869 - val_loss: 73.3189\n",
      "Epoch 4392/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5303 - val_loss: 73.1509\n",
      "Epoch 4393/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4691 - val_loss: 70.3790\n",
      "Epoch 4394/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7086 - val_loss: 68.5813\n",
      "Epoch 4395/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7315 - val_loss: 69.8420\n",
      "Epoch 4396/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5853 - val_loss: 78.7065\n",
      "Epoch 4397/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5031 - val_loss: 70.8076\n",
      "Epoch 4398/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.8576 - val_loss: 72.4945\n",
      "Epoch 4399/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3738 - val_loss: 64.4813\n",
      "Epoch 4400/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5396 - val_loss: 63.3200\n",
      "Epoch 4401/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6443 - val_loss: 70.8282\n",
      "Epoch 4402/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.1940 - val_loss: 69.5972\n",
      "Epoch 4403/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4465 - val_loss: 72.5734\n",
      "Epoch 4404/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5921 - val_loss: 72.0214\n",
      "Epoch 4405/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.3030 - val_loss: 65.9256\n",
      "Epoch 4406/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4665 - val_loss: 77.3340\n",
      "Epoch 4407/5000\n",
      "1063/1063 [==============================] - 0s 86us/step - loss: 4.5274 - val_loss: 68.2852\n",
      "Epoch 4408/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.3785 - val_loss: 73.5441\n",
      "Epoch 4409/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5404 - val_loss: 77.9566\n",
      "Epoch 4410/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.4551 - val_loss: 70.1946\n",
      "Epoch 4411/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6116 - val_loss: 68.0029\n",
      "Epoch 4412/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.4251 - val_loss: 67.2449\n",
      "Epoch 4413/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6157 - val_loss: 73.3948\n",
      "Epoch 4414/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.1735 - val_loss: 71.9511\n",
      "Epoch 4415/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6007 - val_loss: 75.0172\n",
      "Epoch 4416/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6226 - val_loss: 70.0269\n",
      "Epoch 4417/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.3617 - val_loss: 66.5493\n",
      "Epoch 4418/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5634 - val_loss: 74.8070\n",
      "Epoch 4419/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4146 - val_loss: 68.8827\n",
      "Epoch 4420/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.3018 - val_loss: 67.2208\n",
      "Epoch 4421/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5697 - val_loss: 67.2406\n",
      "Epoch 4422/5000\n",
      "1063/1063 [==============================] - 0s 86us/step - loss: 4.4352 - val_loss: 73.7304\n",
      "Epoch 4423/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.2611 - val_loss: 67.7409\n",
      "Epoch 4424/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.7588 - val_loss: 74.2776\n",
      "Epoch 4425/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.9832 - val_loss: 72.2322\n",
      "Epoch 4426/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4606 - val_loss: 70.2358\n",
      "Epoch 4427/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.6708 - val_loss: 75.8992\n",
      "Epoch 4428/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.8357 - val_loss: 73.8588\n",
      "Epoch 4429/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4103 - val_loss: 72.1575\n",
      "Epoch 4430/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5771 - val_loss: 74.8499\n",
      "Epoch 4431/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.6586 - val_loss: 74.2519\n",
      "Epoch 4432/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.3294 - val_loss: 76.8194\n",
      "Epoch 4433/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.3606 - val_loss: 70.7490\n",
      "Epoch 4434/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4247 - val_loss: 70.4063\n",
      "Epoch 4435/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5454 - val_loss: 84.7510\n",
      "Epoch 4436/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.8551 - val_loss: 70.6120\n",
      "Epoch 4437/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.1864 - val_loss: 69.4105\n",
      "Epoch 4438/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5889 - val_loss: 72.4881\n",
      "Epoch 4439/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4025 - val_loss: 78.6502\n",
      "Epoch 4440/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3677 - val_loss: 66.6228\n",
      "Epoch 4441/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.4341 - val_loss: 67.7425\n",
      "Epoch 4442/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.5746 - val_loss: 71.8640\n",
      "Epoch 4443/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5635 - val_loss: 74.6077\n",
      "Epoch 4444/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.2205 - val_loss: 79.5867\n",
      "Epoch 4445/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3451 - val_loss: 65.1166\n",
      "Epoch 4446/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6196 - val_loss: 67.2127\n",
      "Epoch 4447/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.3676 - val_loss: 73.9013\n",
      "Epoch 4448/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5786 - val_loss: 73.7400\n",
      "Epoch 4449/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.4452 - val_loss: 80.2778\n",
      "Epoch 4450/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3294 - val_loss: 66.0583\n",
      "Epoch 4451/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.4909 - val_loss: 76.0700\n",
      "Epoch 4452/5000\n",
      "1063/1063 [==============================] - 0s 86us/step - loss: 4.3958 - val_loss: 73.8956\n",
      "Epoch 4453/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.2492 - val_loss: 74.4855\n",
      "Epoch 4454/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5242 - val_loss: 77.3639\n",
      "Epoch 4455/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.9160 - val_loss: 69.8638\n",
      "Epoch 4456/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.2570 - val_loss: 73.0466\n",
      "Epoch 4457/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5144 - val_loss: 68.2130\n",
      "Epoch 4458/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5550 - val_loss: 77.7636\n",
      "Epoch 4459/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.6315 - val_loss: 77.3822\n",
      "Epoch 4460/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.8688 - val_loss: 71.4458\n",
      "Epoch 4461/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5376 - val_loss: 74.5202\n",
      "Epoch 4462/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5074 - val_loss: 75.1645\n",
      "Epoch 4463/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4856 - val_loss: 68.1011\n",
      "Epoch 4464/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5086 - val_loss: 69.6727\n",
      "Epoch 4465/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.8713 - val_loss: 76.4280\n",
      "Epoch 4466/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.2893 - val_loss: 72.7127\n",
      "Epoch 4467/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.3740 - val_loss: 68.9601\n",
      "Epoch 4468/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4811 - val_loss: 78.7312\n",
      "Epoch 4469/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.3226 - val_loss: 74.0425\n",
      "Epoch 4470/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 5.2877 - val_loss: 70.3845\n",
      "Epoch 4471/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5262 - val_loss: 74.3759\n",
      "Epoch 4472/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5577 - val_loss: 69.2162\n",
      "Epoch 4473/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.2505 - val_loss: 69.2655\n",
      "Epoch 4474/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4678 - val_loss: 68.9529\n",
      "Epoch 4475/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5275 - val_loss: 71.3937\n",
      "Epoch 4476/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.4109 - val_loss: 79.0968\n",
      "Epoch 4477/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7305 - val_loss: 74.4031\n",
      "Epoch 4478/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.7811 - val_loss: 69.4405\n",
      "Epoch 4479/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.3482 - val_loss: 74.8840\n",
      "Epoch 4480/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4082 - val_loss: 66.6843\n",
      "Epoch 4481/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3889 - val_loss: 68.6862\n",
      "Epoch 4482/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3166 - val_loss: 76.6949\n",
      "Epoch 4483/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6461 - val_loss: 73.1671\n",
      "Epoch 4484/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.6398 - val_loss: 70.7445\n",
      "Epoch 4485/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.5422 - val_loss: 65.7996\n",
      "Epoch 4486/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.3058 - val_loss: 72.5174\n",
      "Epoch 4487/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5058 - val_loss: 75.5226\n",
      "Epoch 4488/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.7034 - val_loss: 73.7490\n",
      "Epoch 4489/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.8218 - val_loss: 68.3789\n",
      "Epoch 4490/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5490 - val_loss: 75.9872\n",
      "Epoch 4491/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.7442 - val_loss: 67.7283\n",
      "Epoch 4492/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.5960 - val_loss: 71.0592\n",
      "Epoch 4493/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5979 - val_loss: 69.7228\n",
      "Epoch 4494/5000\n",
      "1063/1063 [==============================] - 0s 124us/step - loss: 4.4033 - val_loss: 69.1891\n",
      "Epoch 4495/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.5108 - val_loss: 70.0957\n",
      "Epoch 4496/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 114us/step - loss: 5.2182 - val_loss: 74.6725\n",
      "Epoch 4497/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.4142 - val_loss: 68.7963\n",
      "Epoch 4498/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.7352 - val_loss: 75.0742\n",
      "Epoch 4499/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.7237 - val_loss: 81.9728\n",
      "Epoch 4500/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7740 - val_loss: 74.3234\n",
      "Epoch 4501/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4778 - val_loss: 70.7405\n",
      "Epoch 4502/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.2202 - val_loss: 73.5010\n",
      "Epoch 4503/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5287 - val_loss: 67.2784\n",
      "Epoch 4504/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.6795 - val_loss: 82.1255\n",
      "Epoch 4505/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.8347 - val_loss: 75.5810\n",
      "Epoch 4506/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3890 - val_loss: 77.7918\n",
      "Epoch 4507/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5358 - val_loss: 67.5725\n",
      "Epoch 4508/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5044 - val_loss: 69.0553\n",
      "Epoch 4509/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5334 - val_loss: 75.0815\n",
      "Epoch 4510/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.7039 - val_loss: 81.1468\n",
      "Epoch 4511/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.6880 - val_loss: 77.7684\n",
      "Epoch 4512/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5392 - val_loss: 72.7627\n",
      "Epoch 4513/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3970 - val_loss: 67.9910\n",
      "Epoch 4514/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.7449 - val_loss: 70.3611\n",
      "Epoch 4515/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.3511 - val_loss: 71.0208\n",
      "Epoch 4516/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.5872 - val_loss: 71.5397\n",
      "Epoch 4517/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.7365 - val_loss: 77.0905\n",
      "Epoch 4518/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4559 - val_loss: 70.4608\n",
      "Epoch 4519/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.3248 - val_loss: 79.1210\n",
      "Epoch 4520/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.9996 - val_loss: 62.4657\n",
      "Epoch 4521/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6684 - val_loss: 73.0876\n",
      "Epoch 4522/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5151 - val_loss: 78.9837\n",
      "Epoch 4523/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4418 - val_loss: 72.1551\n",
      "Epoch 4524/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4317 - val_loss: 72.9531\n",
      "Epoch 4525/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 5.0479 - val_loss: 69.5264\n",
      "Epoch 4526/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.4622 - val_loss: 69.5730\n",
      "Epoch 4527/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3605 - val_loss: 74.6465\n",
      "Epoch 4528/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.2871 - val_loss: 68.7505\n",
      "Epoch 4529/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6649 - val_loss: 73.4381\n",
      "Epoch 4530/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6933 - val_loss: 73.5445\n",
      "Epoch 4531/5000\n",
      "1063/1063 [==============================] - 0s 86us/step - loss: 4.9248 - val_loss: 83.2002\n",
      "Epoch 4532/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.7873 - val_loss: 68.2260\n",
      "Epoch 4533/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5205 - val_loss: 73.7392\n",
      "Epoch 4534/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.3150 - val_loss: 71.3292\n",
      "Epoch 4535/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5209 - val_loss: 67.3667\n",
      "Epoch 4536/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4347 - val_loss: 75.8813\n",
      "Epoch 4537/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.2216 - val_loss: 70.3160\n",
      "Epoch 4538/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.2975 - val_loss: 79.5493\n",
      "Epoch 4539/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4102 - val_loss: 71.1002\n",
      "Epoch 4540/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.2911 - val_loss: 68.7653\n",
      "Epoch 4541/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6994 - val_loss: 66.3816\n",
      "Epoch 4542/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.2877 - val_loss: 75.4509\n",
      "Epoch 4543/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.4581 - val_loss: 71.2823\n",
      "Epoch 4544/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.2679 - val_loss: 64.3551\n",
      "Epoch 4545/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 5.2958 - val_loss: 76.6657\n",
      "Epoch 4546/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6290 - val_loss: 79.4162\n",
      "Epoch 4547/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.8445 - val_loss: 66.2717\n",
      "Epoch 4548/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8494 - val_loss: 73.1215\n",
      "Epoch 4549/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.8430 - val_loss: 72.3401\n",
      "Epoch 4550/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6539 - val_loss: 72.3031\n",
      "Epoch 4551/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.4584 - val_loss: 73.3013\n",
      "Epoch 4552/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.3451 - val_loss: 77.7873\n",
      "Epoch 4553/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4829 - val_loss: 69.6966\n",
      "Epoch 4554/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7204 - val_loss: 68.9630\n",
      "Epoch 4555/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6028 - val_loss: 66.6032\n",
      "Epoch 4556/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.9814 - val_loss: 68.2332\n",
      "Epoch 4557/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.3479 - val_loss: 77.3508\n",
      "Epoch 4558/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4605 - val_loss: 81.9494\n",
      "Epoch 4559/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.3638 - val_loss: 74.4369\n",
      "Epoch 4560/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3458 - val_loss: 69.4243\n",
      "Epoch 4561/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 5.3132 - val_loss: 64.3164\n",
      "Epoch 4562/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5795 - val_loss: 70.0876\n",
      "Epoch 4563/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.8325 - val_loss: 69.8369\n",
      "Epoch 4564/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6236 - val_loss: 75.2487\n",
      "Epoch 4565/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5793 - val_loss: 73.0454\n",
      "Epoch 4566/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.4116 - val_loss: 65.8185\n",
      "Epoch 4567/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.6089 - val_loss: 69.3204\n",
      "Epoch 4568/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3190 - val_loss: 68.4101\n",
      "Epoch 4569/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4782 - val_loss: 70.4617\n",
      "Epoch 4570/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.2394 - val_loss: 79.2264\n",
      "Epoch 4571/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.2607 - val_loss: 74.7058\n",
      "Epoch 4572/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.5303 - val_loss: 74.4730\n",
      "Epoch 4573/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3436 - val_loss: 67.8817\n",
      "Epoch 4574/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4627 - val_loss: 73.7130\n",
      "Epoch 4575/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.1855 - val_loss: 83.4009\n",
      "Epoch 4576/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.7594 - val_loss: 76.9398\n",
      "Epoch 4577/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.3757 - val_loss: 76.8811\n",
      "Epoch 4578/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4649 - val_loss: 70.1597\n",
      "Epoch 4579/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4807 - val_loss: 73.8137\n",
      "Epoch 4580/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4615 - val_loss: 72.6613\n",
      "Epoch 4581/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4634 - val_loss: 70.5635\n",
      "Epoch 4582/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.4176 - val_loss: 69.9018\n",
      "Epoch 4583/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4428 - val_loss: 71.0087\n",
      "Epoch 4584/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.3530 - val_loss: 68.0786\n",
      "Epoch 4585/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.5904 - val_loss: 67.3124\n",
      "Epoch 4586/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.5034 - val_loss: 69.1572\n",
      "Epoch 4587/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.3191 - val_loss: 69.8257\n",
      "Epoch 4588/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.2864 - val_loss: 68.5784\n",
      "Epoch 4589/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5499 - val_loss: 83.4002\n",
      "Epoch 4590/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4954 - val_loss: 72.7110\n",
      "Epoch 4591/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5939 - val_loss: 74.9939\n",
      "Epoch 4592/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.8515 - val_loss: 70.9015\n",
      "Epoch 4593/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4344 - val_loss: 73.5397\n",
      "Epoch 4594/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7345 - val_loss: 73.2066\n",
      "Epoch 4595/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 5.0214 - val_loss: 71.3700\n",
      "Epoch 4596/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7117 - val_loss: 71.1673\n",
      "Epoch 4597/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6252 - val_loss: 64.9569\n",
      "Epoch 4598/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.1724 - val_loss: 71.1010\n",
      "Epoch 4599/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.7302 - val_loss: 76.4353\n",
      "Epoch 4600/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.4187 - val_loss: 72.4739\n",
      "Epoch 4601/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3153 - val_loss: 70.6032\n",
      "Epoch 4602/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4653 - val_loss: 72.7245\n",
      "Epoch 4603/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4741 - val_loss: 67.3448\n",
      "Epoch 4604/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4546 - val_loss: 72.0900\n",
      "Epoch 4605/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.8167 - val_loss: 89.0579\n",
      "Epoch 4606/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.8763 - val_loss: 74.0248\n",
      "Epoch 4607/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.3971 - val_loss: 78.4702\n",
      "Epoch 4608/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.3792 - val_loss: 78.0318\n",
      "Epoch 4609/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5070 - val_loss: 74.9365\n",
      "Epoch 4610/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4543 - val_loss: 68.0198\n",
      "Epoch 4611/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5482 - val_loss: 84.6096\n",
      "Epoch 4612/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6492 - val_loss: 75.0562\n",
      "Epoch 4613/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.2391 - val_loss: 75.5883\n",
      "Epoch 4614/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7492 - val_loss: 68.4527\n",
      "Epoch 4615/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6596 - val_loss: 69.6995\n",
      "Epoch 4616/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5590 - val_loss: 80.1755\n",
      "Epoch 4617/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7794 - val_loss: 67.9890\n",
      "Epoch 4618/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.3109 - val_loss: 80.6366\n",
      "Epoch 4619/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.7702 - val_loss: 72.5224\n",
      "Epoch 4620/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6119 - val_loss: 70.2620\n",
      "Epoch 4621/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5242 - val_loss: 83.5110\n",
      "Epoch 4622/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.8207 - val_loss: 70.5128\n",
      "Epoch 4623/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5162 - val_loss: 71.1754\n",
      "Epoch 4624/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.3094 - val_loss: 73.9104\n",
      "Epoch 4625/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.2866 - val_loss: 75.9295\n",
      "Epoch 4626/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.2620 - val_loss: 76.7289\n",
      "Epoch 4627/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.3264 - val_loss: 73.3462\n",
      "Epoch 4628/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3233 - val_loss: 69.5026\n",
      "Epoch 4629/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.5566 - val_loss: 74.2562\n",
      "Epoch 4630/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6235 - val_loss: 65.7084\n",
      "Epoch 4631/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.3247 - val_loss: 68.4146\n",
      "Epoch 4632/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7301 - val_loss: 70.9948\n",
      "Epoch 4633/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.2615 - val_loss: 72.2272\n",
      "Epoch 4634/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.3757 - val_loss: 69.7358\n",
      "Epoch 4635/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3677 - val_loss: 71.3680\n",
      "Epoch 4636/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.2348 - val_loss: 67.9051\n",
      "Epoch 4637/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5233 - val_loss: 77.2588\n",
      "Epoch 4638/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.3578 - val_loss: 78.6036\n",
      "Epoch 4639/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.6502 - val_loss: 72.6182\n",
      "Epoch 4640/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5273 - val_loss: 70.6404\n",
      "Epoch 4641/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.3203 - val_loss: 69.1760\n",
      "Epoch 4642/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.5361 - val_loss: 78.3865\n",
      "Epoch 4643/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.9734 - val_loss: 74.8861\n",
      "Epoch 4644/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.6330 - val_loss: 72.7727\n",
      "Epoch 4645/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.3861 - val_loss: 75.2549\n",
      "Epoch 4646/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.4933 - val_loss: 69.4388\n",
      "Epoch 4647/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.5571 - val_loss: 72.0624\n",
      "Epoch 4648/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.8084 - val_loss: 75.8888\n",
      "Epoch 4649/5000\n",
      "1063/1063 [==============================] - 0s 119us/step - loss: 4.7174 - val_loss: 73.0958\n",
      "Epoch 4650/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.6397 - val_loss: 76.3136\n",
      "Epoch 4651/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.3609 - val_loss: 66.9530\n",
      "Epoch 4652/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5679 - val_loss: 71.1719\n",
      "Epoch 4653/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.5751 - val_loss: 70.5386\n",
      "Epoch 4654/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.8099 - val_loss: 76.2539\n",
      "Epoch 4655/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.6610 - val_loss: 66.1436\n",
      "Epoch 4656/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4448 - val_loss: 68.0149\n",
      "Epoch 4657/5000\n",
      "1063/1063 [==============================] - 0s 124us/step - loss: 4.8244 - val_loss: 77.1908\n",
      "Epoch 4658/5000\n",
      "1063/1063 [==============================] - 0s 124us/step - loss: 4.8754 - val_loss: 75.7362\n",
      "Epoch 4659/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.3360 - val_loss: 71.6146\n",
      "Epoch 4660/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.2897 - val_loss: 67.7220\n",
      "Epoch 4661/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.5662 - val_loss: 72.8677\n",
      "Epoch 4662/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4242 - val_loss: 68.9447\n",
      "Epoch 4663/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5691 - val_loss: 69.0218\n",
      "Epoch 4664/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4263 - val_loss: 75.7851\n",
      "Epoch 4665/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6611 - val_loss: 71.2851\n",
      "Epoch 4666/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.2874 - val_loss: 75.2898\n",
      "Epoch 4667/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5762 - val_loss: 73.6238\n",
      "Epoch 4668/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.3817 - val_loss: 76.4945\n",
      "Epoch 4669/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5330 - val_loss: 76.2898\n",
      "Epoch 4670/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.3347 - val_loss: 72.6782\n",
      "Epoch 4671/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.9349 - val_loss: 73.8870\n",
      "Epoch 4672/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6047 - val_loss: 70.9763\n",
      "Epoch 4673/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.2566 - val_loss: 72.9463\n",
      "Epoch 4674/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5005 - val_loss: 69.1365\n",
      "Epoch 4675/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5159 - val_loss: 72.7025\n",
      "Epoch 4676/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.7323 - val_loss: 64.8859\n",
      "Epoch 4677/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9489 - val_loss: 68.6583\n",
      "Epoch 4678/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5584 - val_loss: 69.2031\n",
      "Epoch 4679/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.7399 - val_loss: 80.4939\n",
      "Epoch 4680/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 5.4134 - val_loss: 75.7373\n",
      "Epoch 4681/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.3542 - val_loss: 78.2698\n",
      "Epoch 4682/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.2849 - val_loss: 73.4550\n",
      "Epoch 4683/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.6593 - val_loss: 80.9258\n",
      "Epoch 4684/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.7425 - val_loss: 73.8744\n",
      "Epoch 4685/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.3016 - val_loss: 73.5667\n",
      "Epoch 4686/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.2653 - val_loss: 66.5304\n",
      "Epoch 4687/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.7231 - val_loss: 64.2361\n",
      "Epoch 4688/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.3859 - val_loss: 65.7457\n",
      "Epoch 4689/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.7475 - val_loss: 79.7539\n",
      "Epoch 4690/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.7598 - val_loss: 75.0521\n",
      "Epoch 4691/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.7640 - val_loss: 75.0346\n",
      "Epoch 4692/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4177 - val_loss: 76.8783\n",
      "Epoch 4693/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3440 - val_loss: 69.0038\n",
      "Epoch 4694/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4266 - val_loss: 81.5419\n",
      "Epoch 4695/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8217 - val_loss: 75.5002\n",
      "Epoch 4696/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6069 - val_loss: 70.8220\n",
      "Epoch 4697/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8276 - val_loss: 81.8615\n",
      "Epoch 4698/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.6319 - val_loss: 70.2852\n",
      "Epoch 4699/5000\n",
      "1063/1063 [==============================] - 0s 120us/step - loss: 4.8278 - val_loss: 69.9248\n",
      "Epoch 4700/5000\n",
      "1063/1063 [==============================] - 0s 121us/step - loss: 4.6580 - val_loss: 75.6633\n",
      "Epoch 4701/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.6005 - val_loss: 92.8302\n",
      "Epoch 4702/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.0665 - val_loss: 70.8225\n",
      "Epoch 4703/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.6092 - val_loss: 76.0151\n",
      "Epoch 4704/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5907 - val_loss: 68.8011\n",
      "Epoch 4705/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.8261 - val_loss: 73.3689\n",
      "Epoch 4706/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4447 - val_loss: 75.0383\n",
      "Epoch 4707/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4552 - val_loss: 77.8657\n",
      "Epoch 4708/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.3859 - val_loss: 64.8461\n",
      "Epoch 4709/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6346 - val_loss: 75.2927\n",
      "Epoch 4710/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.2320 - val_loss: 71.1693\n",
      "Epoch 4711/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.3654 - val_loss: 86.1914\n",
      "Epoch 4712/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.8710 - val_loss: 69.3732\n",
      "Epoch 4713/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4860 - val_loss: 72.2720\n",
      "Epoch 4714/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4385 - val_loss: 67.7677\n",
      "Epoch 4715/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.4985 - val_loss: 69.2563\n",
      "Epoch 4716/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.5913 - val_loss: 71.1493\n",
      "Epoch 4717/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.1993 - val_loss: 78.4146\n",
      "Epoch 4718/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.2772 - val_loss: 82.9134\n",
      "Epoch 4719/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.6126 - val_loss: 68.1803\n",
      "Epoch 4720/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.6528 - val_loss: 65.9343\n",
      "Epoch 4721/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9410 - val_loss: 69.7444\n",
      "Epoch 4722/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5000 - val_loss: 66.8538\n",
      "Epoch 4723/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5757 - val_loss: 77.0168\n",
      "Epoch 4724/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5753 - val_loss: 68.6341\n",
      "Epoch 4725/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5186 - val_loss: 75.7427\n",
      "Epoch 4726/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5692 - val_loss: 83.5724\n",
      "Epoch 4727/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7915 - val_loss: 62.0955\n",
      "Epoch 4728/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.9743 - val_loss: 73.0285\n",
      "Epoch 4729/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.6953 - val_loss: 65.3799\n",
      "Epoch 4730/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6058 - val_loss: 72.3583\n",
      "Epoch 4731/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5130 - val_loss: 75.1869\n",
      "Epoch 4732/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5656 - val_loss: 74.1279\n",
      "Epoch 4733/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4603 - val_loss: 81.1459\n",
      "Epoch 4734/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 5.1103 - val_loss: 73.3486\n",
      "Epoch 4735/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3096 - val_loss: 69.8761\n",
      "Epoch 4736/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.2658 - val_loss: 79.6128\n",
      "Epoch 4737/5000\n",
      "1063/1063 [==============================] - 0s 84us/step - loss: 4.3707 - val_loss: 72.8906\n",
      "Epoch 4738/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.6567 - val_loss: 69.7787\n",
      "Epoch 4739/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.2932 - val_loss: 77.1418\n",
      "Epoch 4740/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.4436 - val_loss: 70.2147\n",
      "Epoch 4741/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4149 - val_loss: 72.9216\n",
      "Epoch 4742/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.4983 - val_loss: 70.7646\n",
      "Epoch 4743/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.5135 - val_loss: 70.3164\n",
      "Epoch 4744/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.5507 - val_loss: 67.7689\n",
      "Epoch 4745/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.5285 - val_loss: 67.8460\n",
      "Epoch 4746/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.4362 - val_loss: 67.6304\n",
      "Epoch 4747/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.4983 - val_loss: 69.3814\n",
      "Epoch 4748/5000\n",
      "1063/1063 [==============================] - 0s 122us/step - loss: 4.6324 - val_loss: 70.2536\n",
      "Epoch 4749/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.5226 - val_loss: 79.5601\n",
      "Epoch 4750/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.7430 - val_loss: 69.0662\n",
      "Epoch 4751/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3372 - val_loss: 71.4529\n",
      "Epoch 4752/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.3175 - val_loss: 65.3482\n",
      "Epoch 4753/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.2862 - val_loss: 74.5929\n",
      "Epoch 4754/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5619 - val_loss: 72.6933\n",
      "Epoch 4755/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.2277 - val_loss: 68.5521\n",
      "Epoch 4756/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.4118 - val_loss: 81.6230\n",
      "Epoch 4757/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.6496 - val_loss: 68.6550\n",
      "Epoch 4758/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.5701 - val_loss: 83.3680\n",
      "Epoch 4759/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9774 - val_loss: 74.2711\n",
      "Epoch 4760/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3826 - val_loss: 68.7312\n",
      "Epoch 4761/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5176 - val_loss: 68.0640\n",
      "Epoch 4762/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4595 - val_loss: 75.2902\n",
      "Epoch 4763/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.2795 - val_loss: 75.7571\n",
      "Epoch 4764/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.1419 - val_loss: 75.0936\n",
      "Epoch 4765/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5994 - val_loss: 66.1629\n",
      "Epoch 4766/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.7330 - val_loss: 67.5782\n",
      "Epoch 4767/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4326 - val_loss: 71.9011\n",
      "Epoch 4768/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.2491 - val_loss: 68.4764\n",
      "Epoch 4769/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.6612 - val_loss: 72.7012\n",
      "Epoch 4770/5000\n",
      "1063/1063 [==============================] - 0s 86us/step - loss: 4.4816 - val_loss: 70.1305\n",
      "Epoch 4771/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.7437 - val_loss: 76.1585\n",
      "Epoch 4772/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6182 - val_loss: 69.8397\n",
      "Epoch 4773/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6092 - val_loss: 73.7469\n",
      "Epoch 4774/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5293 - val_loss: 69.8273\n",
      "Epoch 4775/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.6992 - val_loss: 72.1891\n",
      "Epoch 4776/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.7442 - val_loss: 75.6234\n",
      "Epoch 4777/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5469 - val_loss: 72.6023\n",
      "Epoch 4778/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.7529 - val_loss: 78.7458\n",
      "Epoch 4779/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.7559 - val_loss: 69.7985\n",
      "Epoch 4780/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.4685 - val_loss: 70.7549\n",
      "Epoch 4781/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5858 - val_loss: 74.9051\n",
      "Epoch 4782/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5767 - val_loss: 75.9564\n",
      "Epoch 4783/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3816 - val_loss: 67.1370\n",
      "Epoch 4784/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6323 - val_loss: 75.6637\n",
      "Epoch 4785/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6567 - val_loss: 80.7090\n",
      "Epoch 4786/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4953 - val_loss: 74.6293\n",
      "Epoch 4787/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7885 - val_loss: 74.9455\n",
      "Epoch 4788/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.2805 - val_loss: 72.2475\n",
      "Epoch 4789/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5342 - val_loss: 64.7175\n",
      "Epoch 4790/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.5835 - val_loss: 67.1849\n",
      "Epoch 4791/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.7260 - val_loss: 74.2709\n",
      "Epoch 4792/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.2679 - val_loss: 71.7961\n",
      "Epoch 4793/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.2899 - val_loss: 71.6791\n",
      "Epoch 4794/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.4794 - val_loss: 69.6001\n",
      "Epoch 4795/5000\n",
      "1063/1063 [==============================] - 0s 86us/step - loss: 4.2257 - val_loss: 68.5838\n",
      "Epoch 4796/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.3956 - val_loss: 72.7585\n",
      "Epoch 4797/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.2395 - val_loss: 75.3176\n",
      "Epoch 4798/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.7110 - val_loss: 69.3669\n",
      "Epoch 4799/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5604 - val_loss: 68.2501\n",
      "Epoch 4800/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.3891 - val_loss: 70.8671\n",
      "Epoch 4801/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.2408 - val_loss: 67.0297\n",
      "Epoch 4802/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4926 - val_loss: 72.3221\n",
      "Epoch 4803/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.2709 - val_loss: 79.0105\n",
      "Epoch 4804/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4861 - val_loss: 72.1959\n",
      "Epoch 4805/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.4334 - val_loss: 77.7363\n",
      "Epoch 4806/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4422 - val_loss: 66.1237\n",
      "Epoch 4807/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.3368 - val_loss: 67.8208\n",
      "Epoch 4808/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.2867 - val_loss: 70.8545\n",
      "Epoch 4809/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.3714 - val_loss: 77.2232\n",
      "Epoch 4810/5000\n",
      "1063/1063 [==============================] - 0s 126us/step - loss: 4.6351 - val_loss: 73.6433\n",
      "Epoch 4811/5000\n",
      "1063/1063 [==============================] - 0s 113us/step - loss: 4.8743 - val_loss: 67.4183\n",
      "Epoch 4812/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.4196 - val_loss: 76.1856\n",
      "Epoch 4813/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.4244 - val_loss: 77.3461\n",
      "Epoch 4814/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.3320 - val_loss: 71.8030\n",
      "Epoch 4815/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.4160 - val_loss: 74.4458\n",
      "Epoch 4816/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5857 - val_loss: 64.0282\n",
      "Epoch 4817/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.8239 - val_loss: 74.4985\n",
      "Epoch 4818/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.9673 - val_loss: 69.3616\n",
      "Epoch 4819/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4399 - val_loss: 72.0632\n",
      "Epoch 4820/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.5423 - val_loss: 77.3697\n",
      "Epoch 4821/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 5.1908 - val_loss: 77.5147\n",
      "Epoch 4822/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.9075 - val_loss: 72.1246\n",
      "Epoch 4823/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6638 - val_loss: 73.7503\n",
      "Epoch 4824/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.9880 - val_loss: 70.8518\n",
      "Epoch 4825/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 5.8214 - val_loss: 76.7929\n",
      "Epoch 4826/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6620 - val_loss: 72.4646\n",
      "Epoch 4827/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.2514 - val_loss: 75.6867\n",
      "Epoch 4828/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.2851 - val_loss: 74.6571\n",
      "Epoch 4829/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.2854 - val_loss: 64.7917\n",
      "Epoch 4830/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.5398 - val_loss: 68.3080\n",
      "Epoch 4831/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6668 - val_loss: 66.8630\n",
      "Epoch 4832/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3736 - val_loss: 73.1092\n",
      "Epoch 4833/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3719 - val_loss: 70.9005\n",
      "Epoch 4834/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.8008 - val_loss: 75.1036\n",
      "Epoch 4835/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5098 - val_loss: 73.7192\n",
      "Epoch 4836/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5396 - val_loss: 68.6826\n",
      "Epoch 4837/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4718 - val_loss: 72.8900\n",
      "Epoch 4838/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.4589 - val_loss: 66.0200\n",
      "Epoch 4839/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.4598 - val_loss: 68.1663\n",
      "Epoch 4840/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4994 - val_loss: 68.5001\n",
      "Epoch 4841/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.2902 - val_loss: 75.9686\n",
      "Epoch 4842/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4213 - val_loss: 71.9558\n",
      "Epoch 4843/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3456 - val_loss: 74.2327\n",
      "Epoch 4844/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.5163 - val_loss: 78.4505\n",
      "Epoch 4845/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.1911 - val_loss: 68.4878\n",
      "Epoch 4846/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4015 - val_loss: 73.6518\n",
      "Epoch 4847/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.3711 - val_loss: 67.2402\n",
      "Epoch 4848/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.2279 - val_loss: 71.0911\n",
      "Epoch 4849/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.2108 - val_loss: 78.0807\n",
      "Epoch 4850/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.6941 - val_loss: 76.4915\n",
      "Epoch 4851/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.8245 - val_loss: 85.9626\n",
      "Epoch 4852/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.8574 - val_loss: 72.7745\n",
      "Epoch 4853/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.4401 - val_loss: 73.6446\n",
      "Epoch 4854/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.3957 - val_loss: 70.8092\n",
      "Epoch 4855/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.4163 - val_loss: 68.5289\n",
      "Epoch 4856/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.4229 - val_loss: 65.7765\n",
      "Epoch 4857/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5555 - val_loss: 67.7795\n",
      "Epoch 4858/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.8750 - val_loss: 81.6609\n",
      "Epoch 4859/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 5.2318 - val_loss: 71.6259\n",
      "Epoch 4860/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.3459 - val_loss: 67.0183\n",
      "Epoch 4861/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.4004 - val_loss: 66.9716\n",
      "Epoch 4862/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4728 - val_loss: 72.5478\n",
      "Epoch 4863/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.3501 - val_loss: 72.6728\n",
      "Epoch 4864/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.2776 - val_loss: 71.3978\n",
      "Epoch 4865/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.3890 - val_loss: 71.7255\n",
      "Epoch 4866/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.2436 - val_loss: 75.7159\n",
      "Epoch 4867/5000\n",
      "1063/1063 [==============================] - 0s 94us/step - loss: 4.9953 - val_loss: 71.8233\n",
      "Epoch 4868/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3386 - val_loss: 71.7032\n",
      "Epoch 4869/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.2280 - val_loss: 71.2274\n",
      "Epoch 4870/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.4133 - val_loss: 68.7951\n",
      "Epoch 4871/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3512 - val_loss: 72.0507\n",
      "Epoch 4872/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6658 - val_loss: 66.2888\n",
      "Epoch 4873/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.3989 - val_loss: 65.1769\n",
      "Epoch 4874/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6203 - val_loss: 67.3421\n",
      "Epoch 4875/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6560 - val_loss: 73.1898\n",
      "Epoch 4876/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.8535 - val_loss: 70.8178\n",
      "Epoch 4877/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5205 - val_loss: 78.0103\n",
      "Epoch 4878/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5571 - val_loss: 75.1860\n",
      "Epoch 4879/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3194 - val_loss: 79.8113\n",
      "Epoch 4880/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.2932 - val_loss: 69.6770\n",
      "Epoch 4881/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.3876 - val_loss: 68.8299\n",
      "Epoch 4882/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.6364 - val_loss: 78.8007\n",
      "Epoch 4883/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.3302 - val_loss: 72.0616\n",
      "Epoch 4884/5000\n",
      "1063/1063 [==============================] - 0s 86us/step - loss: 5.1623 - val_loss: 73.4783\n",
      "Epoch 4885/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.5999 - val_loss: 66.1058\n",
      "Epoch 4886/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.8748 - val_loss: 73.5975\n",
      "Epoch 4887/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6253 - val_loss: 77.5145\n",
      "Epoch 4888/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3370 - val_loss: 70.5445\n",
      "Epoch 4889/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.5811 - val_loss: 69.4659\n",
      "Epoch 4890/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.4425 - val_loss: 74.6437\n",
      "Epoch 4891/5000\n",
      "1063/1063 [==============================] - 0s 86us/step - loss: 4.2568 - val_loss: 73.0534\n",
      "Epoch 4892/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.4187 - val_loss: 63.7552\n",
      "Epoch 4893/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4226 - val_loss: 69.6184\n",
      "Epoch 4894/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.4103 - val_loss: 79.7186\n",
      "Epoch 4895/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.6726 - val_loss: 68.4220\n",
      "Epoch 4896/5000\n",
      "1063/1063 [==============================] - 0s 129us/step - loss: 4.4512 - val_loss: 75.4136\n",
      "Epoch 4897/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.4536 - val_loss: 80.5290\n",
      "Epoch 4898/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.8445 - val_loss: 69.9835\n",
      "Epoch 4899/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.6425 - val_loss: 65.6686\n",
      "Epoch 4900/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.3263 - val_loss: 73.1048\n",
      "Epoch 4901/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.2253 - val_loss: 67.6667\n",
      "Epoch 4902/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.8402 - val_loss: 75.2760\n",
      "Epoch 4903/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.4929 - val_loss: 73.5007\n",
      "Epoch 4904/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.5055 - val_loss: 79.2228\n",
      "Epoch 4905/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.8465 - val_loss: 76.0858\n",
      "Epoch 4906/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.7049 - val_loss: 71.6320\n",
      "Epoch 4907/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.3604 - val_loss: 71.6806\n",
      "Epoch 4908/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.5901 - val_loss: 75.1465\n",
      "Epoch 4909/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.7298 - val_loss: 75.6963\n",
      "Epoch 4910/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.3488 - val_loss: 70.7001\n",
      "Epoch 4911/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.5238 - val_loss: 64.1031\n",
      "Epoch 4912/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.7100 - val_loss: 60.6094\n",
      "Epoch 4913/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 5.6634 - val_loss: 77.5199\n",
      "Epoch 4914/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6040 - val_loss: 67.9766\n",
      "Epoch 4915/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4121 - val_loss: 74.7275\n",
      "Epoch 4916/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 6.1206 - val_loss: 67.3372\n",
      "Epoch 4917/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.9189 - val_loss: 70.9039\n",
      "Epoch 4918/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.9917 - val_loss: 70.9581\n",
      "Epoch 4919/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.6220 - val_loss: 78.8130\n",
      "Epoch 4920/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.6189 - val_loss: 73.7002\n",
      "Epoch 4921/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.4118 - val_loss: 73.2981\n",
      "Epoch 4922/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.7822 - val_loss: 76.6206\n",
      "Epoch 4923/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.5241 - val_loss: 82.6101\n",
      "Epoch 4924/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.7615 - val_loss: 72.1014\n",
      "Epoch 4925/5000\n",
      "1063/1063 [==============================] - 0s 92us/step - loss: 4.3322 - val_loss: 80.7480\n",
      "Epoch 4926/5000\n",
      "1063/1063 [==============================] - 0s 85us/step - loss: 4.5438 - val_loss: 72.9562\n",
      "Epoch 4927/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.2243 - val_loss: 70.9234\n",
      "Epoch 4928/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.3822 - val_loss: 68.5574\n",
      "Epoch 4929/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.4196 - val_loss: 63.6513\n",
      "Epoch 4930/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.9770 - val_loss: 75.2389\n",
      "Epoch 4931/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.4773 - val_loss: 74.7633\n",
      "Epoch 4932/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4399 - val_loss: 69.2489\n",
      "Epoch 4933/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5754 - val_loss: 72.2703\n",
      "Epoch 4934/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.4032 - val_loss: 78.8463\n",
      "Epoch 4935/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 5.1654 - val_loss: 76.1261\n",
      "Epoch 4936/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.6221 - val_loss: 76.1006\n",
      "Epoch 4937/5000\n",
      "1063/1063 [==============================] - 0s 99us/step - loss: 4.9888 - val_loss: 67.1839\n",
      "Epoch 4938/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.4663 - val_loss: 79.7603\n",
      "Epoch 4939/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.4821 - val_loss: 76.2751\n",
      "Epoch 4940/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.3667 - val_loss: 74.0999\n",
      "Epoch 4941/5000\n",
      "1063/1063 [==============================] - 0s 95us/step - loss: 4.5967 - val_loss: 70.1809\n",
      "Epoch 4942/5000\n",
      "1063/1063 [==============================] - 0s 96us/step - loss: 4.4892 - val_loss: 70.1698\n",
      "Epoch 4943/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.1513 - val_loss: 72.1321\n",
      "Epoch 4944/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.3629 - val_loss: 77.8162\n",
      "Epoch 4945/5000\n",
      "1063/1063 [==============================] - 0s 93us/step - loss: 4.3278 - val_loss: 73.0213\n",
      "Epoch 4946/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.4715 - val_loss: 67.4779\n",
      "Epoch 4947/5000\n",
      "1063/1063 [==============================] - 0s 105us/step - loss: 4.2914 - val_loss: 75.8631\n",
      "Epoch 4948/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5483 - val_loss: 75.0867\n",
      "Epoch 4949/5000\n",
      "1063/1063 [==============================] - 0s 91us/step - loss: 4.3246 - val_loss: 76.3941\n",
      "Epoch 4950/5000\n",
      "1063/1063 [==============================] - 0s 88us/step - loss: 4.4795 - val_loss: 67.4955\n",
      "Epoch 4951/5000\n",
      "1063/1063 [==============================] - 0s 87us/step - loss: 4.4478 - val_loss: 73.1956\n",
      "Epoch 4952/5000\n",
      "1063/1063 [==============================] - 0s 89us/step - loss: 4.3727 - val_loss: 68.4870\n",
      "Epoch 4953/5000\n",
      "1063/1063 [==============================] - 0s 90us/step - loss: 4.4282 - val_loss: 68.2390\n",
      "Epoch 4954/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.2997 - val_loss: 72.9559\n",
      "Epoch 4955/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.3773 - val_loss: 68.5930\n",
      "Epoch 4956/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.4707 - val_loss: 70.1223\n",
      "Epoch 4957/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.5507 - val_loss: 73.4246\n",
      "Epoch 4958/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.2526 - val_loss: 77.8039\n",
      "Epoch 4959/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.3144 - val_loss: 66.6611\n",
      "Epoch 4960/5000\n",
      "1063/1063 [==============================] - 0s 97us/step - loss: 4.3726 - val_loss: 73.3826\n",
      "Epoch 4961/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.3252 - val_loss: 78.0811\n",
      "Epoch 4962/5000\n",
      "1063/1063 [==============================] - 0s 108us/step - loss: 4.9511 - val_loss: 70.7102\n",
      "Epoch 4963/5000\n",
      "1063/1063 [==============================] - 0s 124us/step - loss: 4.3589 - val_loss: 74.6280\n",
      "Epoch 4964/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 5.1238 - val_loss: 71.2337\n",
      "Epoch 4965/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5349 - val_loss: 73.3505\n",
      "Epoch 4966/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.5017 - val_loss: 66.9942\n",
      "Epoch 4967/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.6394 - val_loss: 69.8007\n",
      "Epoch 4968/5000\n",
      "1063/1063 [==============================] - 0s 112us/step - loss: 4.5570 - val_loss: 74.5530\n",
      "Epoch 4969/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.3897 - val_loss: 77.3654\n",
      "Epoch 4970/5000\n",
      "1063/1063 [==============================] - 0s 132us/step - loss: 4.5300 - val_loss: 74.6261\n",
      "Epoch 4971/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.6917 - val_loss: 69.3408\n",
      "Epoch 4972/5000\n",
      "1063/1063 [==============================] - 0s 116us/step - loss: 4.6725 - val_loss: 67.6679\n",
      "Epoch 4973/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.8804 - val_loss: 76.6260\n",
      "Epoch 4974/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.2466 - val_loss: 70.4964\n",
      "Epoch 4975/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.3626 - val_loss: 77.2013\n",
      "Epoch 4976/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.3569 - val_loss: 82.0904\n",
      "Epoch 4977/5000\n",
      "1063/1063 [==============================] - 0s 110us/step - loss: 4.3499 - val_loss: 74.9629\n",
      "Epoch 4978/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.6789 - val_loss: 73.3854\n",
      "Epoch 4979/5000\n",
      "1063/1063 [==============================] - 0s 101us/step - loss: 4.6353 - val_loss: 71.8635\n",
      "Epoch 4980/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.2887 - val_loss: 69.3279\n",
      "Epoch 4981/5000\n",
      "1063/1063 [==============================] - 0s 135us/step - loss: 4.5665 - val_loss: 73.0263\n",
      "Epoch 4982/5000\n",
      "1063/1063 [==============================] - 0s 119us/step - loss: 4.3418 - val_loss: 73.5826\n",
      "Epoch 4983/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.1729 - val_loss: 74.6113\n",
      "Epoch 4984/5000\n",
      "1063/1063 [==============================] - 0s 118us/step - loss: 4.2721 - val_loss: 69.5811\n",
      "Epoch 4985/5000\n",
      "1063/1063 [==============================] - 0s 111us/step - loss: 4.4759 - val_loss: 67.2909\n",
      "Epoch 4986/5000\n",
      "1063/1063 [==============================] - 0s 126us/step - loss: 4.6513 - val_loss: 77.9843\n",
      "Epoch 4987/5000\n",
      "1063/1063 [==============================] - 0s 106us/step - loss: 4.2818 - val_loss: 68.7707\n",
      "Epoch 4988/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.8239 - val_loss: 68.8026\n",
      "Epoch 4989/5000\n",
      "1063/1063 [==============================] - 0s 103us/step - loss: 4.3451 - val_loss: 69.1512\n",
      "Epoch 4990/5000\n",
      "1063/1063 [==============================] - 0s 114us/step - loss: 4.1080 - val_loss: 68.2751\n",
      "Epoch 4991/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.3124 - val_loss: 69.4398\n",
      "Epoch 4992/5000\n",
      "1063/1063 [==============================] - 0s 100us/step - loss: 4.7799 - val_loss: 67.2330\n",
      "Epoch 4993/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.4895 - val_loss: 76.6291\n",
      "Epoch 4994/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.5145 - val_loss: 69.1330\n",
      "Epoch 4995/5000\n",
      "1063/1063 [==============================] - 0s 107us/step - loss: 4.5087 - val_loss: 68.2920\n",
      "Epoch 4996/5000\n",
      "1063/1063 [==============================] - 0s 98us/step - loss: 4.5068 - val_loss: 68.3083\n",
      "Epoch 4997/5000\n",
      "1063/1063 [==============================] - 0s 102us/step - loss: 4.3294 - val_loss: 70.1164\n",
      "Epoch 4998/5000\n",
      "1063/1063 [==============================] - 0s 104us/step - loss: 4.5199 - val_loss: 74.1687\n",
      "Epoch 4999/5000\n",
      "1063/1063 [==============================] - 0s 115us/step - loss: 4.2255 - val_loss: 68.0593\n",
      "Epoch 5000/5000\n",
      "1063/1063 [==============================] - 0s 109us/step - loss: 4.5557 - val_loss: 76.2890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27ef9eb5470>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X_train,y_train,epochs=5000,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = model.predict(scaled_X_train)\n",
    "test_pred = model.predict(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on the training set is : 11.874\n",
      "Error on the test set is : 55.643\n"
     ]
    }
   ],
   "source": [
    "print('Error on the training set is : {:.3f}'.format(mean_squared_error(train_pred,y_train)))\n",
    "print('Error on the test set is : {:.3f}'.format(mean_squared_error(test_pred,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score on the training set is : 98.847\n",
      "R2_score on the test set is : 94.310\n"
     ]
    }
   ],
   "source": [
    "print('R2_score on the training set is : {:.3f}'.format(r2_score(train_pred,y_train)*100))\n",
    "print('R2_score on the test set is : {:.3f}'.format(r2_score(test_pred,y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
